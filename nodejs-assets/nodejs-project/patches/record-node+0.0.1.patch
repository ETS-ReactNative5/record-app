patch-package
--- a/node_modules/record-node/components/contacts.js
+++ b/node_modules/record-node/components/contacts.js
@@ -37,7 +37,7 @@ module.exports = function contacts (self) {
       const entry = await self.contacts.getEntry(logId, contactId)
       const relations = await self.contacts.getRelations(entry)
       const profile = await self.profile.getEntry(entry.content.address)
-      return { ...profile, ...relations, ...entry }
+      return Object.assign({}, profile, relations, entry)
     },
 
     getRelations: async (contact, opts = {}) => {
@@ -75,7 +75,7 @@ module.exports = function contacts (self) {
       for (const entry of entries) {
         const profile = await self.profile.getEntry(entry.payload.value.content.address)
         const relations = await self.contacts.getRelations(entry.payload.value)
-        contacts.push({ ...profile, ...relations, ...entry.payload.value })
+        contacts.push(Object.assign({}, profile, relations, entry.payload.value))
       }
       return contacts
     }
--- a/node_modules/record-node/components/feed.js
+++ b/node_modules/record-node/components/feed.js
@@ -33,11 +33,10 @@ module.exports = function feed (self) {
         const { type } = feedEntry.payload
         // TODO: make this readable and less suspect :(
         const entry = await self[`${type}s`].get(address, feedEntry.payload.entryId)
-        entries.push({
-          ...feedEntry.payload,
-          contact: contact,
-          content: entry
-        })
+        entries.push(Object.assign({},
+          feedEntry.payload,
+          { contact: contact, content: entry }
+        ))
       }
       return entries
     }
--- a/node_modules/record-node/components/profile.js
+++ b/node_modules/record-node/components/profile.js
@@ -28,13 +28,13 @@ module.exports = function profile (self) {
 
       if (self.isMe(logId)) {
         entry.content.address = self.address
-        return { ...entry, isMe: true, haveContact: false }
+        return Object.assign({}, entry, { isMe: true }, { haveContact: false }, { content: { address: self.address }})
       }
 
       const contact = await self.contacts.get(self.address, entry._id)
       const relations = await self.contacts.getRelations(contact)
 
-      return { ...entry, ...relations, ...contact }
+      return Object.assign({}, entry, relations, contact)
     }
   }
 }
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ansi-regex/index.js
+++ /dev/null
@@ -1,10 +0,0 @@
-'use strict';
-
-module.exports = () => {
-	const pattern = [
-		'[\\u001B\\u009B][[\\]()#;?]*(?:(?:(?:[a-zA-Z\\d]*(?:;[a-zA-Z\\d]*)*)?\\u0007)',
-		'(?:(?:\\d{1,4}(?:;\\d{0,4})*)?[\\dA-PRZcf-ntqry=><~]))'
-	].join('|');
-
-	return new RegExp(pattern, 'g');
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ansi-regex/license
+++ /dev/null
@@ -1,9 +0,0 @@
-MIT License
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ansi-regex/readme.md
+++ /dev/null
@@ -1,46 +0,0 @@
-# ansi-regex [![Build Status](https://travis-ci.org/chalk/ansi-regex.svg?branch=master)](https://travis-ci.org/chalk/ansi-regex)
-
-> Regular expression for matching [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code)
-
-
-## Install
-
-```
-$ npm install ansi-regex
-```
-
-
-## Usage
-
-```js
-const ansiRegex = require('ansi-regex');
-
-ansiRegex().test('\u001B[4mcake\u001B[0m');
-//=> true
-
-ansiRegex().test('cake');
-//=> false
-
-'\u001B[4mcake\u001B[0m'.match(ansiRegex());
-//=> ['\u001B[4m', '\u001B[0m']
-```
-
-
-## FAQ
-
-### Why do you test for codes not in the ECMA 48 standard?
-
-Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them.
-
-On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of "interrupts" that can mean different things on certain brands of processors, most of which have been phased out.
-
-
-## Maintainers
-
-- [Sindre Sorhus](https://github.com/sindresorhus)
-- [Josh Junon](https://github.com/qix-)
-
-
-## License
-
-MIT
deleted file mode 100644
--- a/node_modules/record-node/node_modules/decamelize/index.js
+++ /dev/null
@@ -1,13 +0,0 @@
-'use strict';
-module.exports = function (str, sep) {
-	if (typeof str !== 'string') {
-		throw new TypeError('Expected a string');
-	}
-
-	sep = typeof sep === 'undefined' ? '_' : sep;
-
-	return str
-		.replace(/([a-z\d])([A-Z])/g, '$1' + sep + '$2')
-		.replace(/([A-Z]+)([A-Z][a-z\d]+)/g, '$1' + sep + '$2')
-		.toLowerCase();
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/decamelize/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/decamelize/readme.md
+++ /dev/null
@@ -1,48 +0,0 @@
-# decamelize [![Build Status](https://travis-ci.org/sindresorhus/decamelize.svg?branch=master)](https://travis-ci.org/sindresorhus/decamelize)
-
-> Convert a camelized string into a lowercased one with a custom separator<br>
-> Example: `unicornRainbow` → `unicorn_rainbow`
-
-
-## Install
-
-```
-$ npm install --save decamelize
-```
-
-
-## Usage
-
-```js
-const decamelize = require('decamelize');
-
-decamelize('unicornRainbow');
-//=> 'unicorn_rainbow'
-
-decamelize('unicornRainbow', '-');
-//=> 'unicorn-rainbow'
-```
-
-
-## API
-
-### decamelize(input, [separator])
-
-#### input
-
-Type: `string`
-
-#### separator
-
-Type: `string`<br>
-Default: `_`
-
-
-## Related
-
-See [`camelcase`](https://github.com/sindresorhus/camelcase) for the inverse.
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/find-up/index.js
+++ /dev/null
@@ -1,48 +0,0 @@
-'use strict';
-const path = require('path');
-const locatePath = require('locate-path');
-
-module.exports = (filename, opts) => {
-	opts = opts || {};
-
-	const startDir = path.resolve(opts.cwd || '');
-	const root = path.parse(startDir).root;
-
-	const filenames = [].concat(filename);
-
-	return new Promise(resolve => {
-		(function find(dir) {
-			locatePath(filenames, {cwd: dir}).then(file => {
-				if (file) {
-					resolve(path.join(dir, file));
-				} else if (dir === root) {
-					resolve(null);
-				} else {
-					find(path.dirname(dir));
-				}
-			});
-		})(startDir);
-	});
-};
-
-module.exports.sync = (filename, opts) => {
-	opts = opts || {};
-
-	let dir = path.resolve(opts.cwd || '');
-	const root = path.parse(dir).root;
-
-	const filenames = [].concat(filename);
-
-	// eslint-disable-next-line no-constant-condition
-	while (true) {
-		const file = locatePath.sync(filenames, {cwd: dir});
-
-		if (file) {
-			return path.join(dir, file);
-		} else if (dir === root) {
-			return null;
-		}
-
-		dir = path.dirname(dir);
-	}
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/find-up/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/find-up/readme.md
+++ /dev/null
@@ -1,85 +0,0 @@
-# find-up [![Build Status: Linux and macOS](https://travis-ci.org/sindresorhus/find-up.svg?branch=master)](https://travis-ci.org/sindresorhus/find-up) [![Build Status: Windows](https://ci.appveyor.com/api/projects/status/l0cyjmvh5lq72vq2/branch/master?svg=true)](https://ci.appveyor.com/project/sindresorhus/find-up/branch/master)
-
-> Find a file by walking up parent directories
-
-
-## Install
-
-```
-$ npm install --save find-up
-```
-
-
-## Usage
-
-```
-/
-└── Users
-		└── sindresorhus
-				├── unicorn.png
-				└── foo
-						└── bar
-								├── baz
-								└── example.js
-```
-
-```js
-// example.js
-const findUp = require('find-up');
-
-findUp('unicorn.png').then(filepath => {
-	console.log(filepath);
-	//=> '/Users/sindresorhus/unicorn.png'
-});
-
-findUp(['rainbow.png', 'unicorn.png']).then(filepath => {
-	console.log(filepath);
-	//=> '/Users/sindresorhus/unicorn.png'
-});
-```
-
-
-## API
-
-### findUp(filename, [options])
-
-Returns a `Promise` for the filepath or `null`.
-
-### findUp([filenameA, filenameB], [options])
-
-Returns a `Promise` for the first filepath found (by respecting the order) or `null`.
-
-### findUp.sync(filename, [options])
-
-Returns a filepath or `null`.
-
-### findUp.sync([filenameA, filenameB], [options])
-
-Returns the first filepath found (by respecting the order) or `null`.
-
-#### filename
-
-Type: `string`
-
-Filename of the file to find.
-
-#### options
-
-##### cwd
-
-Type: `string`<br>
-Default: `process.cwd()`
-
-Directory to start from.
-
-
-## Related
-
-- [find-up-cli](https://github.com/sindresorhus/find-up-cli) - CLI for this module
-- [pkg-up](https://github.com/sindresorhus/pkg-up) - Find the closest package.json file
-- [pkg-dir](https://github.com/sindresorhus/pkg-dir) - Find the root directory of an npm package
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/API.md
+++ /dev/null
@@ -1,184 +0,0 @@
-# ipfs-log - API Documentation
-
-# Log
-
-To use `ipfs-log`, require the module in your project:
-
-```javascript
-const Log = require('ipfs-log')
-```
-
-### Constructor
-
-#### new Log(ipfs, [id])
-
-Create a log. Each log gets a unique ID passed as an argument. Returns a `Log` instance.
-
-```javascript
-const log = new Log(ipfs, 'logid')
-```
-
-`ipfs` is an instance of IPFS. `id` is a unique log identifier. Usually this should be a user id or similar.
-
-### Properties
-
-#### id
-
-Returns the ID of the log.
-
-#### values
-
-Returns an `Array` of [entries](https://github.com/haadcode/ipfs-log/blob/master/src/entry.js) in the log. The values are in linearized order according to their [Lamport clocks](https://en.wikipedia.org/wiki/Lamport_timestamps).
-
-```javascript
-const values = log.values
-// TODO: output example
-```
-
-#### length
-
-Returns the number of entries in the log.
-
-#### clock
-
-Returns the current timestamp of the log.
-
-#### heads
-
-Returns the heads of the log. Heads are the entries that are not referenced by other entries in the log.
-
-```javascript
-const tails = log.tails
-// TODO: output example
-```
-
-#### tails
-
-Return the tails of the log. Tails are the entries that reference other entries that are not in the log.
-
-```javascript
-const tails = log.tails
-// TODO: output example
-```
-
-### Methods
-
-#### append(data)
-
-Append an entry to the log. Returns a *Promise* that resolves to the updated `Log`.
-
-`ipfs` IPFS instance.
-
-`log` Log to append to.
-
-`data` can be any type of data: Number, String, Object, etc. It can also be an instance of [Entry](https://github.com/haadcode/ipfs-log/blob/master/src/entry.js).
-
-```javascript
-log.append({ some: 'data' })
-  .then(log => log.append('text'))
-  .then(log => console.log(log.values))
-
-// [ 
-//   { 
-//     hash: 'QmV1KFxZnaguPFp57PMXz5Dd1tf6z9U8csJQoy4xWDzzts',
-//     id: 'A',
-//     payload: { some: 'data' },
-//     next: [],
-//     v: 0,
-//     clock: LamportClock { id: 'A', time: 0 } 
-//   },
-//   { hash: 'QmSxe4Shd7jt4ExyoBjtvgi1UabNKrZfRJKptwUmSa843u',
-//     id: 'A',
-//     payload: 'text',
-//     next: [ 'QmV1KFxZnaguPFp57PMXz5Dd1tf6z9U8csJQoy4xWDzzts' ],
-//     v: 0,
-//     clock: LamportClock { id: 'A', time: 1 } 
-//   } 
-// ]
-```
-
-#### join(log, [length], [id])
-
-Join the log with another log. Returns a Promise that resolves to a `Log` instance. The size of the joined log can be specified by giving `length` argument. 
-
-```javascript
-// log1.values ==> ['A', 'B', 'C']
-// log2.values ==> ['C', 'D', 'E']
-
-log1.join(log2)
-  .then(() => console.log(log1.values))
-// ['A', 'B', 'C', 'D', 'E']
-```
-
-### toMultihash()
-
-Writes the log to IPFS and returns the Multihash of the log. Returns a `Promise` that resolves to a Base58 encoded `string`.
-
-```javascript
-log1.toMultihash()
-  .then(hash => console.log(hash))
-
-// QmSUrxz12UDsuuQMjzBQ4NDGyYprhFJbQefgeRiomQ5j6T
-```
-
-### toBuffer()
-
-Converts the log to a `Buffer` that contains the log as JSON.stringified `string`. Returns a `Buffer`.
-
-```javascript
-const buffer = log1.toBuffer()
-```
-
-### toString
-
-Returns the log values as a nicely formatted string.
-
-```javascript
-console.log(log.toString())
-// two
-// └─one
-//   └─three
-```
-
-## Static methods
-
-#### Log.isLog(log)
-
-Check if an object is a `Log` instance.
-
-```javascript
-Log.isLog(log1)
-// true
-Log.isLog('hello')
-// false
-```
-
-#### Log.expand(ipfs, log, [amount=-1])
-
-Expands a `log` by `amount` by retreiving more entries from the tails of the log. Returns a new `Log` instance. 
-
-Expanding a log will retrieve new entries from IPFS, thus causing side effects.
-
-#### Log.expandFrom(ipfs, log, entries, [amount=-1])
-
-Expand a `log` by `amount` by retrieving more entries starting from `entries`. `entries` is an `Array` of `Entry` instances. Returns a new `Log` instance. 
-
-Expanding a log will retrieve new entries from IPFS, thus causing side effects.
-
-#### Log.fromEntry(ipfs, entry, [length=-1])
-
-Create a `Log` from an `Entry`.
-
-Creating a log from an entry will retrieve entries from IPFS, thus causing side effects.
-
-#### Log.toMultihash(ipfs, log)
-
-Returns the multihash of the log.
-
-Converting the log to a multihash will persist the log to IPFS, thus causing side effects.
-
-#### Log.fromMultihash(ipfs, multihash, [length=-1])
-
-Create a `Log` from a multihash.
-
-Creating a log from a multihash will retrieve entries from IPFS, thus causing side effects.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/LICENSE
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) 2016 Haad
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/Makefile
+++ /dev/null
@@ -1,21 +0,0 @@
-all: build
-
-deps:
-	npm install
-
-test: deps
-	npm run test
-
-build: test
-	npm run build
-	@echo "Build success!"
-	@echo "Built: 'dist/', 'examples/browser/'"
-
-clean:
-	rm -rf ipfs/
-	rm -rf ipfs-log-benchmarks/
-	rm -rf node_modules/
-	rm -rf coverage/
-	rm -rf test/keystore/
-
-.PHONY: test
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/README.md
+++ /dev/null
@@ -1,182 +0,0 @@
-# ipfs-log
-
-[![npm](https://img.shields.io/npm/v/ipfs-log.svg)](https://www.npmjs.com/package/ipfs-log)
-[![CircleCI Status](https://circleci.com/gh/orbitdb/ipfs-log.svg?style=shield)](https://circleci.com/gh/orbitdb/ipfs-log)
-
-> An append-only log on IPFS.
-
-`ipfs-log` is an immutable, operation-based conflict-free replicated data structure ([CRDT](https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type)) for distributed systems. It's an append-only log that can be used to model a mutable, shared state between peers in p2p applications.
-
-Every entry in the log is saved in IPFS and each points to a hash of previous entry(ies) forming a graph. Logs can be forked and joined back together.
-
-The module works in **Node.js** and **Browsers**.
-
-```
-           Log A                Log B
-             |                    |
-     logA.append("one")   logB.append("hello")
-             |                    |
-             v                    v
-          +-----+             +-------+
-          |"one"|             |"hello"|
-          +-----+             +-------+
-             |                    |
-     logA.append("two")   logB.append("world")
-             |                    |
-             v                    v
-       +-----------+       +---------------+
-       |"one","two"|       |"hello","world"|
-       +-----------+       +---------------+
-             |                    |
-             |                    |
-       logA.join(logB) <----------+
-             |
-             v
-+---------------------------+
-|"one","hello","two","world"|
-+---------------------------+
-```
-
-
-## Table of Contents
-
-- [Background](#background)
-- [Install](#install)
-- [Usage](#usage)
-- [API](#api)
-- [Tests](#tests)
-- [Build](#build)
-- [Contribute](#contribute)
-- [License](#license)
-
-## Background
-
-IPFS Log has a few use cases:
-
-- CRDTs
-- Database operations log
-- Feed of data
-- Track a version of a file
-- Messaging
-
-It was originally created for, and currently used in, [orbit-db](https://github.com/orbitdb/orbit-db) - a distributed peer-to-peer database on [IPFS](https://github.com/ipfs/ipfs).
-
-## Requirements
-
-- Node.js v8.0.0 or newer
-
-## Install
-
-```
-npm install ipfs-log
-```
-
-## Usage
-
-See the [API documentation](#api) and [examples](https://github.com/orbitdb/ipfs-log/tree/master/examples) for more details.
-
-### Quick Start
-
-Install dependencies:
-
-```
-npm install ipfs-log ipfs
-```
-
-Run a simple program:
-
-```javascript
-const IPFS = require('ipfs')
-const Log  = require('ipfs-log')
-
-const ipfs = new IPFS()
-const log  = new Log(ipfs)
-
-ipfs.on('ready' , () => {
-  log.append({ some: 'data' })
-    .then(log => log.append('text'))
-    .then(log => console.log(log.values.map(e => e.payload)))
-})
-
-// [ { some: 'data' }, 'text' ]
-```
-
-### Node.js
-
-See [examples](https://github.com/orbitdb/ipfs-log/tree/master/examples) for details.
-
-*If your platforms requires ES5-compatible JavaScript, there's a build in `lib/es5/`.*
-
-### Browser
-
-See [examples/browser](https://github.com/orbitdb/ipfs-log/tree/master/examples/browser) for details.
-
-*The distribution package for browsers is located in [dist/ipfslog.min.js](https://github.com/orbitdb/ipfs-log/tree/master/dist)*
-
-*If your platforms requires ES5-compatible JavaScript, there's a build in `lib/es5/`.*
-
-## API
-
-See [API Documentation](https://github.com/orbitdb/ipfs-log/tree/master/API.md) for full details.
-
-- [Log](https://github.com/orbitdb/ipfs-log/tree/master/API.md#log)
-  - [Constructor](https://github.com/orbitdb/ipfs-log/tree/master/API.md##constructor)
-    - [new Log(ipfs, [id])](https://github.com/orbitdb/ipfs-log/tree/master/API.md##new-log-ipfs-id)
-  - [Properties](https://github.com/orbitdb/ipfs-log/tree/master/API.md##properties)
-    - [id](https://github.com/orbitdb/ipfs-log/tree/master/API.md##id)
-    - [values](https://github.com/orbitdb/ipfs-log/tree/master/API.md##values)
-    - [length](https://github.com/orbitdb/ipfs-log/tree/master/API.md##length)
-    - [clock](https://github.com/orbitdb/ipfs-log/tree/master/API.md##length)
-    - [heads](https://github.com/orbitdb/ipfs-log/tree/master/API.md##heads)
-    - [tails](https://github.com/orbitdb/ipfs-log/tree/master/API.md##tails)
-  - [Methods](https://github.com/orbitdb/ipfs-log/tree/master/API.md##methods)
-    - [append(data)](https://github.com/orbitdb/ipfs-log/tree/master/API.md##appenddata)
-    - [join(log)](https://github.com/orbitdb/ipfs-log/tree/master/API.md##joinlog)
-    - [toMultihash()](https://github.com/orbitdb/ipfs-log/tree/master/API.md##tomultihash)
-    - [toBuffer()](https://github.com/orbitdb/ipfs-log/tree/master/API.md##tobuffer)
-    - [toString()](https://github.com/orbitdb/ipfs-log/tree/master/API.md##toString)
-  - [Static Methods](https://github.com/orbitdb/ipfs-log/tree/master/API.md##static-methods)
-    - [Log.expand()]()
-    - [Log.expandFrom()]()
-    - [Log.fromEntry()]()
-    - [Log.fromEntryHash()]()
-    - [Log.toMultihash()]()
-    - [Log.fromMultihash()]()
-
-## Tests
-
-```
-npm test
-```
-
-## Build
-
-The build script will build the distribution file for browsers.
-
-```
-npm run build
-```
-
-## Benchmarks
-
-There's a benchmark suite in [benchmarks/](https://github.com/orbitdb/ipfs-log/blob/master/benchmarks) that can be run with:
-
-```
-node benchmarks/benchmark-append.js
-node benchmarks/benchmark-join.js
-node benchmarks/benchmark-expand.js
-```
-
-There's `append` and `join` benchmarks for browsers in [benchmarks/browser/](https://github.com/orbitdb/ipfs-log/blob/master/benchmarks/browser) which you can run by opening the `.html` files in your browser.
-
-## Contribute
-
-If you find a bug or something is broken, let us know! PRs and [issues](https://github.com/orbitdb/ipfs-log/issues) are gladly accepted too. Take a look at the open issues, too, to see if there is anything that you could do or someone else has already done. Here are some things I know I need:
-
-### TODO
-
-- Support for payload encryption
-
-## License
-
-[MIT](LICENSE) © 2017 Haadcode
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-append-signed.js
+++ /dev/null
@@ -1,78 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const Keystore = require('orbit-db-keystore')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-const queryLoop = async () => {
-  await log.append(totalQueries.toString())
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', () => {
-    // Use memory store to test without disk IO
-    // const memstore = new MemStore()
-    // ipfs.object.put = memstore.put.bind(memstore)
-    // ipfs.object.get = memstore.get.bind(memstore)
-
-    const keystore = Keystore.create('./test-keys')
-    const key = keystore.createKey('benchmark-append-signed')
-    ipfs.keystore = keystore
-    log = new Log(ipfs, 'A', null, null, null, key, key.getPublic('hex'))
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-append.js
+++ /dev/null
@@ -1,75 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-const queryLoop = async () => {
-  await log.append(totalQueries.toString())
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', () => {
-    // Use memory store to test without disk IO
-    // const memstore = new MemStore()
-    // ipfs.object.put = memstore.put.bind(memstore)
-    // ipfs.object.get = memstore.get.bind(memstore)
-
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-create-with-nexts.js
+++ /dev/null
@@ -1,137 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const EntryIO = require('../src/entry-io')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-let total = 0
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/fromEntryHash/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Use memory store to test without disk IO
-    /* const memstore = new MemStore()
-     * ipfs.object.put = memstore.put.bind(memstore)
-     * ipfs.object.get = memstore.get.bind(memstore)
-     */
-
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    const count = parseInt(process.argv[2]) || 50000
-    const refCount = 64
-    const concurrency = 128
-    const delay = 0
-
-    console.log("Creating a log...")
-
-    const st = new Date().getTime()
-
-    try {
-    for (let i = 1; i < count + 1; i ++) {
-      await log.append('hello' + i)
-      process.stdout.write("\rWriting " + i + " / " + count)
-    }
-    const dt1 = new Date().getTime()
-      process.stdout.write(" (" + (dt1 - st) + " ms)\n")
-    } catch (e) {
-      console.log(e)
-    }
-
-    const onDataUpdated = (hash, entry, resultLength, result, queue) => {
-      // totalQueries = resultLength
-      queriesPerSecond++
-      lastTenSeconds++
-      total = resultLength
-      process.stdout.write("\rLoading " + total + " / " + count)
-    }
-
-    const outputMetrics = () => {
-      // queriesPerSecond = total - queriesPerSecond
-      totalQueries = total - totalQueries
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`\n${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${total})`)
-      queriesPerSecond = 0
-    }
-
-    // Output metrics at 1 second interval
-    setInterval(outputMetrics, 1000)
-
-    const dt2 = new Date().getTime()
-
-    if (global.gc) {
-      global.gc()
-    } else {
-      console.warn('Start benchmark with --expose-gc flag');
-    }
-
-    try {
-      const result = new Log(
-        ipfs,
-        log._id,
-        null, //entries
-        log.heads,
-        log._clock,
-        log._key,
-        log._keys,
-        log._nextsIndex
-      )
-
-      //console.log(log._nextsIndex)
-
-    } catch(e) {
-      console.log(e)
-    }
-
-    // total = result.length
-    // queriesPerSecond = result.length
-    // queriesPerSecond = totalQueries - queriesPerSecond
-    outputMetrics()
-    const et = new Date().getTime()
-    console.log("Loading took:", (et - dt2), "ms")
-    const memory = process.memoryUsage()
-    console.log(`Memory Heap Used: ${memory.heapUsed / 1024 / 1024} MB`)
-    console.log(`Memory Heap Total: ${memory.heapTotal / 1024 / 1024} MB`)
-    process.exit(0)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-fetch.js
+++ /dev/null
@@ -1,117 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const EntryIO = require('../src/entry-io')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-let total = 0
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/fetch/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Use memory store to test without disk IO
-    const memstore = new MemStore()
-    ipfs.object.put = memstore.put.bind(memstore)
-    ipfs.object.get = memstore.get.bind(memstore)
-
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    const count = parseInt(process.argv[2]) || 50000
-    const refCount = 64
-    const concurrency = 128
-    const delay = 0
-
-    console.log("Creating a log...")
-
-    const st = new Date().getTime()
-
-    for (let i = 1; i < count + 1; i ++) {
-      await log.append('hello' + i, refCount)
-      process.stdout.write("\rWriting " + i + " / " + count)
-    }
-    const dt1 = new Date().getTime()
-    process.stdout.write(" (" + (dt1 - st) + " ms)\n")
-
-
-    const onDataUpdated = (hash, entry, resultLength, result, queue) => {
-      // totalQueries = resultLength
-      queriesPerSecond++
-      lastTenSeconds++
-      total = resultLength
-    }
-
-    const outputMetrics = () => {
-      // queriesPerSecond = total - queriesPerSecond
-      totalQueries = total - totalQueries
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${total})`)
-      queriesPerSecond = 0
-    }
-
-    // Output metrics at 1 second interval
-    setInterval(outputMetrics, 1000)
-
-    const dt2 = new Date().getTime()
-
-    const result = await EntryIO.fetchAll(
-      ipfs, 
-      log.heads.map(e => e.hash), 
-      -1, 
-      [], 
-      20000, 
-      onDataUpdated, 
-      null,
-      concurrency,
-      delay
-    )
-
-    // total = result.length
-    // queriesPerSecond = result.length
-    // queriesPerSecond = totalQueries - queriesPerSecond
-    outputMetrics()
-    const et = new Date().getTime()
-    console.log("Loading took:", (et - dt2), "ms")
-    process.exit(0)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-from-entry-hash.js
+++ /dev/null
@@ -1,124 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const EntryIO = require('../src/entry-io')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-let total = 0
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/fromEntryHash/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    const count = parseInt(process.argv[2]) || 50000
-    const refCount = 64
-    const concurrency = 128
-    const delay = 0
-
-    console.log("Creating a log...")
-
-    const st = new Date().getTime()
-
-    try {
-    for (let i = 1; i < count + 1; i ++) {
-      await log.append('hello' + i, refCount)
-      process.stdout.write("\rWriting " + i + " / " + count)
-    }
-    const dt1 = new Date().getTime()
-      process.stdout.write(" (" + (dt1 - st) + " ms)\n")
-    } catch (e) {
-      console.log(e)
-    }
-
-
-    const onDataUpdated = (hash, entry, resultLength, result, queue) => {
-      // totalQueries = resultLength
-      queriesPerSecond++
-      lastTenSeconds++
-      total = resultLength
-      process.stdout.write("\rLoading " + total + " / " + count)
-    }
-
-    const outputMetrics = () => {
-      // queriesPerSecond = total - queriesPerSecond
-      totalQueries = total - totalQueries
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`\n${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${total})`)
-      queriesPerSecond = 0
-    }
-
-    // Output metrics at 1 second interval
-    setInterval(outputMetrics, 1000)
-
-    const dt2 = new Date().getTime()
-
-    if (global.gc) {
-      global.gc()
-    } else {
-      console.warn('Start benchmark with --expose-gc flag');
-    }
-
-    const result = await Log.fromEntryHash(
-      ipfs,
-      log.heads.map(e => e.hash),
-      log._id,
-      -1,
-      [],
-      log._key,
-      log._keys,
-      onDataUpdated
-    )
-
-    // total = result.length
-    // queriesPerSecond = result.length
-    // queriesPerSecond = totalQueries - queriesPerSecond
-    outputMetrics()
-    const et = new Date().getTime()
-    console.log("Loading took:", (et - dt2), "ms")
-    const memory = process.memoryUsage()
-    console.log(`Memory Heap Used: ${memory.heapUsed / 1024 / 1024} MB`)
-    console.log(`Memory Heap Total: ${memory.heapTotal / 1024 / 1024} MB`)
-    process.exit(0)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-get-disk.js
+++ /dev/null
@@ -1,75 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-
-const queryLoop = async () => {
-  await log.get(entry.hash)
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    const appendLog = new Log(ipfs, 'A')
-
-    entry = await appendLog.append('Hello World')
-
-    log = new Log(ipfs, 'A')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-get-plus.js
+++ /dev/null
@@ -1,108 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-let immediate
-
-let waveCount = 0
-let waveLength = 10 // seconds
-
-let addEntries = async () => {
-  for (let i=0; i<10000; i++) {
-    await log.append(`Hello World: ${i}`)
-  }
-
-  // choose random entry
-  entry = log.values[Math.floor(Math.random() * log.values.length)]
-
-  console.log(`=== Running wave #${waveCount} for ${waveLength} seconds  with ${log.values.length} entries ===`)
-}
-
-const queryLoop = async () => {
-  log.get(entry.hash)
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  immediate = setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    await addEntries()
-
-    const nextWave = async () => {
-      //reset counters
-      totalQueries = 0
-      seconds = 0
-      queriesPerSecond = 0
-      lastTenSeconds = 0
-
-      waveCount++
-      await addEntries()
-
-      interval = setInterval(outputMetrics, 1000)
-      immediate = setImmediate(queryLoop)
-    }
-
-    const outputMetrics = () => {
-      seconds++
-
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-
-      if (seconds % waveLength === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in this wave`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-        clearImmediate(immediate)
-        clearInterval(interval)
-        nextWave()
-      }
-    }
-
-    // Output metrics at 1 second interval
-    let interval = setInterval(outputMetrics, 1000)
-    immediate = setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-get.js
+++ /dev/null
@@ -1,73 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-
-const queryLoop = async () => {
-  log.get(entry.hash)
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    entry = await log.append('Hello World')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-has-plus.js
+++ /dev/null
@@ -1,108 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-let immediate
-
-let waveCount = 0
-let waveLength = 10 // seconds
-
-let addEntries = async () => {
-  for (let i=0; i<10000; i++) {
-    await log.append(`Hello World: ${i}`)
-  }
-
-  // choose random entry
-  entry = log.values[Math.floor(Math.random() * log.values.length)]
-
-  console.log(`=== Running wave #${waveCount} for ${waveLength} seconds  with ${log.values.length} entries ===`)
-}
-
-const queryLoop = async () => {
-  log.has(entry.hash)
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  immediate = setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    await addEntries()
-
-    const nextWave = async () => {
-      //reset counters
-      totalQueries = 0
-      seconds = 0
-      queriesPerSecond = 0
-      lastTenSeconds = 0
-
-      waveCount++
-      await addEntries()
-
-      interval = setInterval(outputMetrics, 1000)
-      immediate = setImmediate(queryLoop)
-    }
-
-    const outputMetrics = () => {
-      seconds++
-
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-
-      if (seconds % waveLength === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in this wave`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-        clearImmediate(immediate)
-        clearInterval(interval)
-        nextWave()
-      }
-    }
-
-    // Output metrics at 1 second interval
-    let interval = setInterval(outputMetrics, 1000)
-    immediate = setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-has.js
+++ /dev/null
@@ -1,73 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-
-const queryLoop = async () => {
-  log.has(entry.hash)
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    entry = await log.append('Hello World')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-join-signed.js
+++ /dev/null
@@ -1,89 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const Keystore = require('orbit-db-keystore')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log1, log2
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-const queryLoop = async () => {
-  try {
-    const add1 = await log1.append('a' + totalQueries)
-    const add2 = await log2.append('b' + totalQueries)
-
-    await Promise.all([add1, add2])
-    log1.join(log2)
-    log2.join(log1)
-    totalQueries++
-    lastTenSeconds++
-    queriesPerSecond++
-    setImmediate(queryLoop)
-  } catch (e) {
-    console.error(e)
-    process.exit(0)
-  }
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: true
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-    process.exit(1)
-  })
-
-  ipfs.on('ready', () => {
-    // Use memory store to test without disk IO
-    // const memstore = new MemStore()
-    // ipfs.object.put = memstore.put.bind(memstore)
-    // ipfs.object.get = memstore.get.bind(memstore)
-
-    const keystore = Keystore.create('./test-keys')
-    const key = keystore.createKey('benchmark-append-signed')
-    ipfs.keystore = keystore
-
-    log1 = new Log(ipfs, 'A', null, null, null, key, key.getPublic('hex'))
-    log2 = new Log(ipfs, 'B', null, null, null, key, key.getPublic('hex'))
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds. log1: ${log1.length}, log2: ${log2.length}`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    queryLoop()
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-join.js
+++ /dev/null
@@ -1,84 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const MemStore = require('../test/utils/mem-store')
-
-// State
-let ipfs
-let log1, log2
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-const queryLoop = async () => {
-  try {
-    const add1 = await log1.append('a' + totalQueries)
-    const add2 = await log2.append('b' + totalQueries)
-
-    await Promise.all([add1, add2])
-    log1.join(log2)
-    log2.join(log1)
-    totalQueries++
-    lastTenSeconds++
-    queriesPerSecond++
-    setImmediate(queryLoop)
-  } catch (e) {
-    console.error(e)
-    process.exit(0)
-  }
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel,
-    },
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: true
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-    process.exit(1)
-  })
-
-  ipfs.on('ready', () => {
-    // Use memory store to test without disk IO
-    // const memstore = new MemStore()
-    // ipfs.object.put = memstore.put.bind(memstore)
-    // ipfs.object.get = memstore.get.bind(memstore)
-
-    log1 = new Log(ipfs, 'A')
-    log2 = new Log(ipfs, 'B')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds. log1: ${log1.length}, log2: ${log2.length}`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    queryLoop()
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-values-plus.js
+++ /dev/null
@@ -1,108 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-let immediate
-
-let waveCount = 0
-let waveLength = 10 // seconds
-
-let addEntries = async () => {
-  for (let i=0; i<10000; i++) {
-    await log.append(`Hello World: ${i}`)
-  }
-
-  // choose random entry
-  entry = log.values[Math.floor(Math.random() * log.values.length)]
-
-  console.log(`=== Running wave #${waveCount} for ${waveLength} seconds  with ${log.values.length} entries ===`)
-}
-
-const queryLoop = async () => {
-  log.values
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  immediate = setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    await addEntries()
-
-    const nextWave = async () => {
-      //reset counters
-      totalQueries = 0
-      seconds = 0
-      queriesPerSecond = 0
-      lastTenSeconds = 0
-
-      waveCount++
-      await addEntries()
-
-      interval = setInterval(outputMetrics, 1000)
-      immediate = setImmediate(queryLoop)
-    }
-
-    const outputMetrics = () => {
-      seconds++
-
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-
-      if (seconds % waveLength === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in this wave`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-        clearImmediate(immediate)
-        clearInterval(interval)
-        nextWave()
-      }
-    }
-
-    // Output metrics at 1 second interval
-    let interval = setInterval(outputMetrics, 1000)
-    immediate = setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/benchmark-values.js
+++ /dev/null
@@ -1,73 +0,0 @@
-'use strict'
-
-const Log = require('../src/log')
-const IPFS = require('ipfs')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-
-// State
-let ipfs
-let log
-
-// Metrics
-let totalQueries = 0
-let seconds = 0
-let queriesPerSecond = 0
-let lastTenSeconds = 0
-
-let entry
-
-const queryLoop = async () => {
-  log.values
-  totalQueries++
-  lastTenSeconds++
-  queriesPerSecond++
-  setImmediate(queryLoop)
-}
-
-let run = (() => {
-  console.log('Starting benchmark...')
-
-  const repoConf = {
-    storageBackends: {
-      blocks: DatastoreLevel
-    }
-  }
-
-  ipfs = new IPFS({
-    repo: new IPFSRepo('./ipfs-log-benchmarks/ipfs', repoConf),
-    start: false,
-    EXPERIMENTAL: {
-      pubsub: false,
-      sharding: false,
-      dht: false,
-    },
-  })
-
-  ipfs.on('error', (err) => {
-    console.error(err)
-  })
-
-  ipfs.on('ready', async () => {
-    // Create a log
-    log = new Log(ipfs, 'A')
-
-    entry = await log.append('Hello World')
-
-    // Output metrics at 1 second interval
-    setInterval(() => {
-      seconds++
-      if (seconds % 10 === 0) {
-        console.log(`--> Average of ${lastTenSeconds / 10} q/s in the last 10 seconds`)
-        if (lastTenSeconds === 0) throw new Error('Problems!')
-        lastTenSeconds = 0
-      }
-      console.log(`${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (Entry count: ${log.values.length})`)
-      queriesPerSecond = 0
-    }, 1000)
-
-    setImmediate(queryLoop)
-  })
-})()
-
-module.exports = run
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/browser/benchmark-append.html
+++ /dev/null
@@ -1,77 +0,0 @@
-<html>
-  <head>
-    <meta charset="utf-8">
-  </head>
-  <body>
-    <h1>ipfs-log - benchmark append()</h1>
-
-    <h2>Description</h2>
-    <div>Add an entry to a log. Measure throughput in operations per second.</div>
-    <pre><i>
-    let log = new Log(ipfs, 'id')
-    await log.append(loopCount)
-    </i></pre>
-
-    <h2>Results</h2>
-    <pre id="output"></pre>
-
-    <script type="text/javascript" src="../../dist/ipfslog.min.js" charset="utf-8"></script>
-    <script type="text/javascript" src="../../node_modules/ipfs/dist/index.min.js" charset="utf-8"></script>
-
-    <script type="text/javascript">
-      let log, ipfs
-
-      // Metrics
-      let totalQueries = 0
-      let seconds = 0
-      let queriesPerSecond = 0
-      let lastTenSeconds = 0
-
-      const queryLoop = () => {
-        return log.append(totalQueries.toString())
-          .then((res) => {
-            totalQueries ++
-            lastTenSeconds ++
-            queriesPerSecond ++
-            setImmediate(queryLoop)
-          })
-          .catch((e) => console.error(e))
-      }
-
-      let run = (() => {
-        ipfs = new Ipfs({ 
-          repo: './ipfs-log/examples/browser/benchmark-append/0.27.0',
-          start: false,
-          EXPERIMENTAL: {
-            pubsub: false,
-            sharding: false,
-            dht: false,
-          },
-        })
-
-        ipfs.on('error', (err) => console.error(err))
-
-        ipfs.on('ready', () => {
-          const outputElm = document.getElementById('output')
-          // Output metrics at 1 second interval
-          setInterval(() => {
-            seconds ++
-            if(seconds % 10 === 0) {
-              outputElm.innerHTML = `--> Average of ${lastTenSeconds/10} q/s in the last 10 seconds<br>` + outputElm.innerHTML
-              console.log(`--> Average of ${lastTenSeconds/10} q/s in the last 10 seconds`)
-              if(lastTenSeconds === 0)
-                throw new Error("Problems!")
-              lastTenSeconds = 0
-            }
-            outputElm.innerHTML = `${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds - Log entries: ${log.length}<br>` + outputElm.innerHTML
-            queriesPerSecond = 0
-          }, 1000)
-
-          log = new Log(ipfs, 'benchmark-append')
-          queryLoop()
-        })
-
-      })()
-    </script>
-  </body>
-</html>
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/benchmarks/browser/benchmark-join.html
+++ /dev/null
@@ -1,93 +0,0 @@
-<html>
-  <head>
-    <meta charset="utf-8">
-  </head>
-  <body>
-    <h1>ipfs-log - benchmark join()</h1>
-
-    <h2>Description</h2>
-    <div>Add an entry to two logs and join them after each update. Measure throughput in operations per second.</div>
-    <pre><i>
-    let log1 = new Log(ipfs, 'A')
-    let log2 = new Log(ipfs, 'B')
-
-    const add1 = await log1.append("a" + loopCount)
-    const add2 = await log2.append("b" + loopCount)
-
-    Promise.all([add1, add2])
-      .then((res) => {
-        log1.join(log2)
-        log2.join(log1)
-      })
-    </i></pre>
-
-    <h2>Results</h2>
-    <pre id="output"></pre>
-
-    <script type="text/javascript" src="../../dist/ipfslog.min.js" charset="utf-8"></script>
-    <script type="text/javascript" src="../../node_modules/ipfs/dist/index.min.js" charset="utf-8"></script>
-
-    <script type="text/javascript">
-      let ipfs
-
-      // Metrics
-      let totalQueries = 0
-      let seconds = 0
-      let queriesPerSecond = 0
-      let lastTenSeconds = 0
-      let log1, log2
-
-      const queryLoop = () => {
-        const add1 = log1.append("a" + totalQueries)
-        const add2 = log2.append("b" + totalQueries)
-
-        Promise.all([add1, add2])
-          .then((res) => {
-            log1.join(log2)
-            log2.join(log1)
-            totalQueries ++
-            lastTenSeconds ++
-            queriesPerSecond ++
-            setImmediate(queryLoop)
-          })
-          .catch((e) => console.error(e))
-      }
-
-      let run = (() => {
-        ipfs = new Ipfs({ 
-          repo: './ipfs-log/examples/browser/benchmark-join/new/0.27.0',
-          start: false,
-          EXPERIMENTAL: {
-            pubsub: false,
-            sharding: false,
-            dht: false,
-          },
-        })
-
-        ipfs.on('error', (err) => console.error(err))
-
-        ipfs.on('ready', () => {
-          const outputElm = document.getElementById('output')
-          // Output metrics at 1 second interval
-          setInterval(() => {
-            seconds ++
-            if(seconds % 10 === 0) {
-              outputElm.innerHTML = `--> Average of ${lastTenSeconds/10} q/s in the last 10 seconds<br>` + outputElm.innerHTML
-              console.log(`--> Average of ${lastTenSeconds/10} q/s in the last 10 seconds`)
-              if(lastTenSeconds === 0)
-                throw new Error("Problems!")
-              lastTenSeconds = 0
-            }
-            outputElm.innerHTML = `${queriesPerSecond} queries per second, ${totalQueries} queries in ${seconds} seconds (log1: ${log1.length}, log2: ${log2.length})<br>` + outputElm.innerHTML
-            queriesPerSecond = 0
-          }, 1000)
-
-          log1 = new Log(ipfs, 'A')
-          log2 = new Log(ipfs, 'B')
-          queryLoop()
-        })
-
-      })()
-    </script>
-  </body>
-</html>
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/circle.yml
+++ /dev/null
@@ -1,3 +0,0 @@
-machine:
-  node:
-    version: 8.2.0
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/dist/ipfslog.min.js
+++ /dev/null
@@ -1,8 +0,0 @@
-var Log=function(t){var r={};function e(n){if(r[n])return r[n].exports;var i=r[n]={i:n,l:!1,exports:{}};return t[n].call(i.exports,i,i.exports,e),i.l=!0,i.exports}return e.m=t,e.c=r,e.d=function(t,r,n){e.o(t,r)||Object.defineProperty(t,r,{configurable:!1,enumerable:!0,get:n})},e.n=function(t){var r=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(r,"a",r),r},e.o=function(t,r){return Object.prototype.hasOwnProperty.call(t,r)},e.p="",e(e.s=7)}([function(t,r,e){"use strict";t.exports=((t,r,e)=>new Promise((n,i)=>{if(e=Object.assign({concurrency:1/0},e),"function"!=typeof r)throw new TypeError("Mapper function is required");const o=e.concurrency;if(!("number"==typeof o&&o>=1))throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${o}\` (${typeof o})`);const s=[],h=t[Symbol.iterator]();let a=!1,u=!1,f=0,c=0;const l=()=>{if(a)return;const t=h.next(),e=c;if(c++,t.done)return u=!0,void(0===f&&n(s));f++,Promise.resolve(t.value).then(t=>r(t,e)).then(t=>{s[e]=t,f--,l()},t=>{a=!0,i(t)})};for(let t=0;t<o&&(l(),!u);t++);}))},function(t,r,e){"use strict";(function(r){const n=e(2),i=e(3),o=()=>new Error("Ipfs instance not defined");class s{static async create(t,r,e,h,a=[],u,f){if(!i(t))throw o();if(!i(e))throw new Error("Entry requires an id");if(!i(h))throw new Error("Entry requires data");if(!i(a)||!Array.isArray(a))throw new Error("'next' argument is not an array");let c=a.filter(i).map(t=>t.hash?t.hash:t);const l=u?u.id:f?f.getPublic("hex"):e,d=u?u.time:null;let p={hash:null,id:e,payload:h,next:c,v:0,clock:new n(l,d)};return r&&f&&(p=await s.signEntry(r,p,f)),p.hash=await s.toMultihash(t,p),p}static async signEntry(t,e,n){const i=await t.sign(n,r.from(JSON.stringify(e)));return e.sig=i,e.key=n.getPublic("hex"),e}static async verifyEntry(t,e){const n=Object.assign({},{hash:null,id:t.id,payload:t.payload,next:t.next,v:t.v,clock:t.clock}),i=await e.importPublicKey(t.key);await e.verify(t.sig,i,r.from(JSON.stringify(n)))}static toMultihash(t,e){if(!t)throw o();const n=r.from(JSON.stringify(e));return t.object.put(n).then(t=>t.toJSON().multihash)}static fromMultihash(t,r){if(!t)throw o();if(!r)throw new Error(`Invalid hash: ${r}`);return t.object.get(r,{enc:"base58"}).then(t=>JSON.parse(t.toJSON().data)).then(t=>{let e={hash:r,id:t.id,payload:t.payload,next:t.next,v:t.v,clock:t.clock};return t.sig&&Object.assign(e,{sig:t.sig}),t.key&&Object.assign(e,{key:t.key}),e})}static isEntry(t){return void 0!==t.id&&void 0!==t.next&&void 0!==t.hash&&void 0!==t.payload&&void 0!==t.v&&void 0!==t.clock}static compare(t,r){var e=n.compare(t.clock,r.clock);return 0===e?t.clock.id<r.clock.id?-1:1:e}static isEqual(t,r){return t.hash===r.hash}static isParent(t,r){return r.next.indexOf(t.hash)>-1}static findChildren(t,r){for(var e=[],n=r.find(r=>s.isParent(t,r)),i=t;n;)e.push(n),i=n,n=r.find(t=>s.isParent(i,t));return e=e.sort((t,r)=>t.clock.time>t.clock.time)}}t.exports=s}).call(r,e(4).Buffer)},function(t,r,e){"use strict";class n{constructor(t,r){this.id=t,this.time=r||0}tick(){return new n(this.id,++this.time)}merge(t){return this.time=Math.max(this.time,t.time),new n(this.id,this.time)}clone(){return new n(this.id,this.time)}static compare(t,r){var e=t.time-r.time;return 0===e&&t.id!==r.id?t.id<r.id?-1:1:e}}t.exports=n},function(t,r,e){"use strict";t.exports=(t=>void 0!==t&&null!==t)},function(t,r,e){"use strict";(function(t){
-/*!
- * The buffer module from node.js, for the browser.
- *
- * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>
- * @license  MIT
- */
-var n=e(9),i=e(10),o=e(11);function s(){return a.TYPED_ARRAY_SUPPORT?2147483647:1073741823}function h(t,r){if(s()<r)throw new RangeError("Invalid typed array length");return a.TYPED_ARRAY_SUPPORT?(t=new Uint8Array(r)).__proto__=a.prototype:(null===t&&(t=new a(r)),t.length=r),t}function a(t,r,e){if(!(a.TYPED_ARRAY_SUPPORT||this instanceof a))return new a(t,r,e);if("number"==typeof t){if("string"==typeof r)throw new Error("If encoding is specified then the first argument must be a string");return c(this,t)}return u(this,t,r,e)}function u(t,r,e,n){if("number"==typeof r)throw new TypeError('"value" argument must not be a number');return"undefined"!=typeof ArrayBuffer&&r instanceof ArrayBuffer?function(t,r,e,n){if(r.byteLength,e<0||r.byteLength<e)throw new RangeError("'offset' is out of bounds");if(r.byteLength<e+(n||0))throw new RangeError("'length' is out of bounds");r=void 0===e&&void 0===n?new Uint8Array(r):void 0===n?new Uint8Array(r,e):new Uint8Array(r,e,n);a.TYPED_ARRAY_SUPPORT?(t=r).__proto__=a.prototype:t=l(t,r);return t}(t,r,e,n):"string"==typeof r?function(t,r,e){"string"==typeof e&&""!==e||(e="utf8");if(!a.isEncoding(e))throw new TypeError('"encoding" must be a valid string encoding');var n=0|p(r,e),i=(t=h(t,n)).write(r,e);i!==n&&(t=t.slice(0,i));return t}(t,r,e):function(t,r){if(a.isBuffer(r)){var e=0|d(r.length);return 0===(t=h(t,e)).length?t:(r.copy(t,0,0,e),t)}if(r){if("undefined"!=typeof ArrayBuffer&&r.buffer instanceof ArrayBuffer||"length"in r)return"number"!=typeof r.length||function(t){return t!=t}(r.length)?h(t,0):l(t,r);if("Buffer"===r.type&&o(r.data))return l(t,r.data)}throw new TypeError("First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.")}(t,r)}function f(t){if("number"!=typeof t)throw new TypeError('"size" argument must be a number');if(t<0)throw new RangeError('"size" argument must not be negative')}function c(t,r){if(f(r),t=h(t,r<0?0:0|d(r)),!a.TYPED_ARRAY_SUPPORT)for(var e=0;e<r;++e)t[e]=0;return t}function l(t,r){var e=r.length<0?0:0|d(r.length);t=h(t,e);for(var n=0;n<e;n+=1)t[n]=255&r[n];return t}function d(t){if(t>=s())throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x"+s().toString(16)+" bytes");return 0|t}function p(t,r){if(a.isBuffer(t))return t.length;if("undefined"!=typeof ArrayBuffer&&"function"==typeof ArrayBuffer.isView&&(ArrayBuffer.isView(t)||t instanceof ArrayBuffer))return t.byteLength;"string"!=typeof t&&(t=""+t);var e=t.length;if(0===e)return 0;for(var n=!1;;)switch(r){case"ascii":case"latin1":case"binary":return e;case"utf8":case"utf-8":case void 0:return j(t).length;case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return 2*e;case"hex":return e>>>1;case"base64":return J(t).length;default:if(n)return j(t).length;r=(""+r).toLowerCase(),n=!0}}function g(t,r,e){var n=t[r];t[r]=t[e],t[e]=n}function y(t,r,e,n,i){if(0===t.length)return-1;if("string"==typeof e?(n=e,e=0):e>2147483647?e=2147483647:e<-2147483648&&(e=-2147483648),e=+e,isNaN(e)&&(e=i?0:t.length-1),e<0&&(e=t.length+e),e>=t.length){if(i)return-1;e=t.length-1}else if(e<0){if(!i)return-1;e=0}if("string"==typeof r&&(r=a.from(r,n)),a.isBuffer(r))return 0===r.length?-1:w(t,r,e,n,i);if("number"==typeof r)return r&=255,a.TYPED_ARRAY_SUPPORT&&"function"==typeof Uint8Array.prototype.indexOf?i?Uint8Array.prototype.indexOf.call(t,r,e):Uint8Array.prototype.lastIndexOf.call(t,r,e):w(t,[r],e,n,i);throw new TypeError("val must be string, number or Buffer")}function w(t,r,e,n,i){var o,s=1,h=t.length,a=r.length;if(void 0!==n&&("ucs2"===(n=String(n).toLowerCase())||"ucs-2"===n||"utf16le"===n||"utf-16le"===n)){if(t.length<2||r.length<2)return-1;s=2,h/=2,a/=2,e/=2}function u(t,r){return 1===s?t[r]:t.readUInt16BE(r*s)}if(i){var f=-1;for(o=e;o<h;o++)if(u(t,o)===u(r,-1===f?0:o-f)){if(-1===f&&(f=o),o-f+1===a)return f*s}else-1!==f&&(o-=o-f),f=-1}else for(e+a>h&&(e=h-a),o=e;o>=0;o--){for(var c=!0,l=0;l<a;l++)if(u(t,o+l)!==u(r,l)){c=!1;break}if(c)return o}return-1}function v(t,r,e,n){e=Number(e)||0;var i=t.length-e;n?(n=Number(n))>i&&(n=i):n=i;var o=r.length;if(o%2!=0)throw new TypeError("Invalid hex string");n>o/2&&(n=o/2);for(var s=0;s<n;++s){var h=parseInt(r.substr(2*s,2),16);if(isNaN(h))return s;t[e+s]=h}return s}function m(t,r,e,n){return H(j(r,t.length-e),t,e,n)}function E(t,r,e,n){return H(function(t){for(var r=[],e=0;e<t.length;++e)r.push(255&t.charCodeAt(e));return r}(r),t,e,n)}function b(t,r,e,n){return E(t,r,e,n)}function _(t,r,e,n){return H(J(r),t,e,n)}function A(t,r,e,n){return H(function(t,r){for(var e,n,i,o=[],s=0;s<t.length&&!((r-=2)<0);++s)e=t.charCodeAt(s),n=e>>8,i=e%256,o.push(i),o.push(n);return o}(r,t.length-e),t,e,n)}function x(t,r,e){return 0===r&&e===t.length?n.fromByteArray(t):n.fromByteArray(t.slice(r,e))}function P(t,r,e){e=Math.min(t.length,e);for(var n=[],i=r;i<e;){var o,s,h,a,u=t[i],f=null,c=u>239?4:u>223?3:u>191?2:1;if(i+c<=e)switch(c){case 1:u<128&&(f=u);break;case 2:128==(192&(o=t[i+1]))&&(a=(31&u)<<6|63&o)>127&&(f=a);break;case 3:o=t[i+1],s=t[i+2],128==(192&o)&&128==(192&s)&&(a=(15&u)<<12|(63&o)<<6|63&s)>2047&&(a<55296||a>57343)&&(f=a);break;case 4:o=t[i+1],s=t[i+2],h=t[i+3],128==(192&o)&&128==(192&s)&&128==(192&h)&&(a=(15&u)<<18|(63&o)<<12|(63&s)<<6|63&h)>65535&&a<1114112&&(f=a)}null===f?(f=65533,c=1):f>65535&&(f-=65536,n.push(f>>>10&1023|55296),f=56320|1023&f),n.push(f),i+=c}return function(t){var r=t.length;if(r<=R)return String.fromCharCode.apply(String,t);var e="",n=0;for(;n<r;)e+=String.fromCharCode.apply(String,t.slice(n,n+=R));return e}(n)}r.Buffer=a,r.SlowBuffer=function(t){+t!=t&&(t=0);return a.alloc(+t)},r.INSPECT_MAX_BYTES=50,a.TYPED_ARRAY_SUPPORT=void 0!==t.TYPED_ARRAY_SUPPORT?t.TYPED_ARRAY_SUPPORT:function(){try{var t=new Uint8Array(1);return t.__proto__={__proto__:Uint8Array.prototype,foo:function(){return 42}},42===t.foo()&&"function"==typeof t.subarray&&0===t.subarray(1,1).byteLength}catch(t){return!1}}(),r.kMaxLength=s(),a.poolSize=8192,a._augment=function(t){return t.__proto__=a.prototype,t},a.from=function(t,r,e){return u(null,t,r,e)},a.TYPED_ARRAY_SUPPORT&&(a.prototype.__proto__=Uint8Array.prototype,a.__proto__=Uint8Array,"undefined"!=typeof Symbol&&Symbol.species&&a[Symbol.species]===a&&Object.defineProperty(a,Symbol.species,{value:null,configurable:!0})),a.alloc=function(t,r,e){return function(t,r,e,n){return f(r),r<=0?h(t,r):void 0!==e?"string"==typeof n?h(t,r).fill(e,n):h(t,r).fill(e):h(t,r)}(null,t,r,e)},a.allocUnsafe=function(t){return c(null,t)},a.allocUnsafeSlow=function(t){return c(null,t)},a.isBuffer=function(t){return!(null==t||!t._isBuffer)},a.compare=function(t,r){if(!a.isBuffer(t)||!a.isBuffer(r))throw new TypeError("Arguments must be Buffers");if(t===r)return 0;for(var e=t.length,n=r.length,i=0,o=Math.min(e,n);i<o;++i)if(t[i]!==r[i]){e=t[i],n=r[i];break}return e<n?-1:n<e?1:0},a.isEncoding=function(t){switch(String(t).toLowerCase()){case"hex":case"utf8":case"utf-8":case"ascii":case"latin1":case"binary":case"base64":case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return!0;default:return!1}},a.concat=function(t,r){if(!o(t))throw new TypeError('"list" argument must be an Array of Buffers');if(0===t.length)return a.alloc(0);var e;if(void 0===r)for(r=0,e=0;e<t.length;++e)r+=t[e].length;var n=a.allocUnsafe(r),i=0;for(e=0;e<t.length;++e){var s=t[e];if(!a.isBuffer(s))throw new TypeError('"list" argument must be an Array of Buffers');s.copy(n,i),i+=s.length}return n},a.byteLength=p,a.prototype._isBuffer=!0,a.prototype.swap16=function(){var t=this.length;if(t%2!=0)throw new RangeError("Buffer size must be a multiple of 16-bits");for(var r=0;r<t;r+=2)g(this,r,r+1);return this},a.prototype.swap32=function(){var t=this.length;if(t%4!=0)throw new RangeError("Buffer size must be a multiple of 32-bits");for(var r=0;r<t;r+=4)g(this,r,r+3),g(this,r+1,r+2);return this},a.prototype.swap64=function(){var t=this.length;if(t%8!=0)throw new RangeError("Buffer size must be a multiple of 64-bits");for(var r=0;r<t;r+=8)g(this,r,r+7),g(this,r+1,r+6),g(this,r+2,r+5),g(this,r+3,r+4);return this},a.prototype.toString=function(){var t=0|this.length;return 0===t?"":0===arguments.length?P(this,0,t):function(t,r,e){var n=!1;if((void 0===r||r<0)&&(r=0),r>this.length)return"";if((void 0===e||e>this.length)&&(e=this.length),e<=0)return"";if((e>>>=0)<=(r>>>=0))return"";for(t||(t="utf8");;)switch(t){case"hex":return B(this,r,e);case"utf8":case"utf-8":return P(this,r,e);case"ascii":return I(this,r,e);case"latin1":case"binary":return k(this,r,e);case"base64":return x(this,r,e);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return T(this,r,e);default:if(n)throw new TypeError("Unknown encoding: "+t);t=(t+"").toLowerCase(),n=!0}}.apply(this,arguments)},a.prototype.equals=function(t){if(!a.isBuffer(t))throw new TypeError("Argument must be a Buffer");return this===t||0===a.compare(this,t)},a.prototype.inspect=function(){var t="",e=r.INSPECT_MAX_BYTES;return this.length>0&&(t=this.toString("hex",0,e).match(/.{2}/g).join(" "),this.length>e&&(t+=" ... ")),"<Buffer "+t+">"},a.prototype.compare=function(t,r,e,n,i){if(!a.isBuffer(t))throw new TypeError("Argument must be a Buffer");if(void 0===r&&(r=0),void 0===e&&(e=t?t.length:0),void 0===n&&(n=0),void 0===i&&(i=this.length),r<0||e>t.length||n<0||i>this.length)throw new RangeError("out of range index");if(n>=i&&r>=e)return 0;if(n>=i)return-1;if(r>=e)return 1;if(r>>>=0,e>>>=0,n>>>=0,i>>>=0,this===t)return 0;for(var o=i-n,s=e-r,h=Math.min(o,s),u=this.slice(n,i),f=t.slice(r,e),c=0;c<h;++c)if(u[c]!==f[c]){o=u[c],s=f[c];break}return o<s?-1:s<o?1:0},a.prototype.includes=function(t,r,e){return-1!==this.indexOf(t,r,e)},a.prototype.indexOf=function(t,r,e){return y(this,t,r,e,!0)},a.prototype.lastIndexOf=function(t,r,e){return y(this,t,r,e,!1)},a.prototype.write=function(t,r,e,n){if(void 0===r)n="utf8",e=this.length,r=0;else if(void 0===e&&"string"==typeof r)n=r,e=this.length,r=0;else{if(!isFinite(r))throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");r|=0,isFinite(e)?(e|=0,void 0===n&&(n="utf8")):(n=e,e=void 0)}var i=this.length-r;if((void 0===e||e>i)&&(e=i),t.length>0&&(e<0||r<0)||r>this.length)throw new RangeError("Attempt to write outside buffer bounds");n||(n="utf8");for(var o=!1;;)switch(n){case"hex":return v(this,t,r,e);case"utf8":case"utf-8":return m(this,t,r,e);case"ascii":return E(this,t,r,e);case"latin1":case"binary":return b(this,t,r,e);case"base64":return _(this,t,r,e);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return A(this,t,r,e);default:if(o)throw new TypeError("Unknown encoding: "+n);n=(""+n).toLowerCase(),o=!0}},a.prototype.toJSON=function(){return{type:"Buffer",data:Array.prototype.slice.call(this._arr||this,0)}};var R=4096;function I(t,r,e){var n="";e=Math.min(t.length,e);for(var i=r;i<e;++i)n+=String.fromCharCode(127&t[i]);return n}function k(t,r,e){var n="";e=Math.min(t.length,e);for(var i=r;i<e;++i)n+=String.fromCharCode(t[i]);return n}function B(t,r,e){var n=t.length;(!r||r<0)&&(r=0),(!e||e<0||e>n)&&(e=n);for(var i="",o=r;o<e;++o)i+=C(t[o]);return i}function T(t,r,e){for(var n=t.slice(r,e),i="",o=0;o<n.length;o+=2)i+=String.fromCharCode(n[o]+256*n[o+1]);return i}function S(t,r,e){if(t%1!=0||t<0)throw new RangeError("offset is not uint");if(t+r>e)throw new RangeError("Trying to access beyond buffer length")}function O(t,r,e,n,i,o){if(!a.isBuffer(t))throw new TypeError('"buffer" argument must be a Buffer instance');if(r>i||r<o)throw new RangeError('"value" argument is out of bounds');if(e+n>t.length)throw new RangeError("Index out of range")}function U(t,r,e,n){r<0&&(r=65535+r+1);for(var i=0,o=Math.min(t.length-e,2);i<o;++i)t[e+i]=(r&255<<8*(n?i:1-i))>>>8*(n?i:1-i)}function D(t,r,e,n){r<0&&(r=4294967295+r+1);for(var i=0,o=Math.min(t.length-e,4);i<o;++i)t[e+i]=r>>>8*(n?i:3-i)&255}function M(t,r,e,n,i,o){if(e+n>t.length)throw new RangeError("Index out of range");if(e<0)throw new RangeError("Index out of range")}function N(t,r,e,n,o){return o||M(t,0,e,4),i.write(t,r,e,n,23,4),e+4}function Y(t,r,e,n,o){return o||M(t,0,e,8),i.write(t,r,e,n,52,8),e+8}a.prototype.slice=function(t,r){var e,n=this.length;if(t=~~t,r=void 0===r?n:~~r,t<0?(t+=n)<0&&(t=0):t>n&&(t=n),r<0?(r+=n)<0&&(r=0):r>n&&(r=n),r<t&&(r=t),a.TYPED_ARRAY_SUPPORT)(e=this.subarray(t,r)).__proto__=a.prototype;else{var i=r-t;e=new a(i,void 0);for(var o=0;o<i;++o)e[o]=this[o+t]}return e},a.prototype.readUIntLE=function(t,r,e){t|=0,r|=0,e||S(t,r,this.length);for(var n=this[t],i=1,o=0;++o<r&&(i*=256);)n+=this[t+o]*i;return n},a.prototype.readUIntBE=function(t,r,e){t|=0,r|=0,e||S(t,r,this.length);for(var n=this[t+--r],i=1;r>0&&(i*=256);)n+=this[t+--r]*i;return n},a.prototype.readUInt8=function(t,r){return r||S(t,1,this.length),this[t]},a.prototype.readUInt16LE=function(t,r){return r||S(t,2,this.length),this[t]|this[t+1]<<8},a.prototype.readUInt16BE=function(t,r){return r||S(t,2,this.length),this[t]<<8|this[t+1]},a.prototype.readUInt32LE=function(t,r){return r||S(t,4,this.length),(this[t]|this[t+1]<<8|this[t+2]<<16)+16777216*this[t+3]},a.prototype.readUInt32BE=function(t,r){return r||S(t,4,this.length),16777216*this[t]+(this[t+1]<<16|this[t+2]<<8|this[t+3])},a.prototype.readIntLE=function(t,r,e){t|=0,r|=0,e||S(t,r,this.length);for(var n=this[t],i=1,o=0;++o<r&&(i*=256);)n+=this[t+o]*i;return n>=(i*=128)&&(n-=Math.pow(2,8*r)),n},a.prototype.readIntBE=function(t,r,e){t|=0,r|=0,e||S(t,r,this.length);for(var n=r,i=1,o=this[t+--n];n>0&&(i*=256);)o+=this[t+--n]*i;return o>=(i*=128)&&(o-=Math.pow(2,8*r)),o},a.prototype.readInt8=function(t,r){return r||S(t,1,this.length),128&this[t]?-1*(255-this[t]+1):this[t]},a.prototype.readInt16LE=function(t,r){r||S(t,2,this.length);var e=this[t]|this[t+1]<<8;return 32768&e?4294901760|e:e},a.prototype.readInt16BE=function(t,r){r||S(t,2,this.length);var e=this[t+1]|this[t]<<8;return 32768&e?4294901760|e:e},a.prototype.readInt32LE=function(t,r){return r||S(t,4,this.length),this[t]|this[t+1]<<8|this[t+2]<<16|this[t+3]<<24},a.prototype.readInt32BE=function(t,r){return r||S(t,4,this.length),this[t]<<24|this[t+1]<<16|this[t+2]<<8|this[t+3]},a.prototype.readFloatLE=function(t,r){return r||S(t,4,this.length),i.read(this,t,!0,23,4)},a.prototype.readFloatBE=function(t,r){return r||S(t,4,this.length),i.read(this,t,!1,23,4)},a.prototype.readDoubleLE=function(t,r){return r||S(t,8,this.length),i.read(this,t,!0,52,8)},a.prototype.readDoubleBE=function(t,r){return r||S(t,8,this.length),i.read(this,t,!1,52,8)},a.prototype.writeUIntLE=function(t,r,e,n){(t=+t,r|=0,e|=0,n)||O(this,t,r,e,Math.pow(2,8*e)-1,0);var i=1,o=0;for(this[r]=255&t;++o<e&&(i*=256);)this[r+o]=t/i&255;return r+e},a.prototype.writeUIntBE=function(t,r,e,n){(t=+t,r|=0,e|=0,n)||O(this,t,r,e,Math.pow(2,8*e)-1,0);var i=e-1,o=1;for(this[r+i]=255&t;--i>=0&&(o*=256);)this[r+i]=t/o&255;return r+e},a.prototype.writeUInt8=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,1,255,0),a.TYPED_ARRAY_SUPPORT||(t=Math.floor(t)),this[r]=255&t,r+1},a.prototype.writeUInt16LE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,2,65535,0),a.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8):U(this,t,r,!0),r+2},a.prototype.writeUInt16BE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,2,65535,0),a.TYPED_ARRAY_SUPPORT?(this[r]=t>>>8,this[r+1]=255&t):U(this,t,r,!1),r+2},a.prototype.writeUInt32LE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,4,4294967295,0),a.TYPED_ARRAY_SUPPORT?(this[r+3]=t>>>24,this[r+2]=t>>>16,this[r+1]=t>>>8,this[r]=255&t):D(this,t,r,!0),r+4},a.prototype.writeUInt32BE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,4,4294967295,0),a.TYPED_ARRAY_SUPPORT?(this[r]=t>>>24,this[r+1]=t>>>16,this[r+2]=t>>>8,this[r+3]=255&t):D(this,t,r,!1),r+4},a.prototype.writeIntLE=function(t,r,e,n){if(t=+t,r|=0,!n){var i=Math.pow(2,8*e-1);O(this,t,r,e,i-1,-i)}var o=0,s=1,h=0;for(this[r]=255&t;++o<e&&(s*=256);)t<0&&0===h&&0!==this[r+o-1]&&(h=1),this[r+o]=(t/s>>0)-h&255;return r+e},a.prototype.writeIntBE=function(t,r,e,n){if(t=+t,r|=0,!n){var i=Math.pow(2,8*e-1);O(this,t,r,e,i-1,-i)}var o=e-1,s=1,h=0;for(this[r+o]=255&t;--o>=0&&(s*=256);)t<0&&0===h&&0!==this[r+o+1]&&(h=1),this[r+o]=(t/s>>0)-h&255;return r+e},a.prototype.writeInt8=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,1,127,-128),a.TYPED_ARRAY_SUPPORT||(t=Math.floor(t)),t<0&&(t=255+t+1),this[r]=255&t,r+1},a.prototype.writeInt16LE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,2,32767,-32768),a.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8):U(this,t,r,!0),r+2},a.prototype.writeInt16BE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,2,32767,-32768),a.TYPED_ARRAY_SUPPORT?(this[r]=t>>>8,this[r+1]=255&t):U(this,t,r,!1),r+2},a.prototype.writeInt32LE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,4,2147483647,-2147483648),a.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8,this[r+2]=t>>>16,this[r+3]=t>>>24):D(this,t,r,!0),r+4},a.prototype.writeInt32BE=function(t,r,e){return t=+t,r|=0,e||O(this,t,r,4,2147483647,-2147483648),t<0&&(t=4294967295+t+1),a.TYPED_ARRAY_SUPPORT?(this[r]=t>>>24,this[r+1]=t>>>16,this[r+2]=t>>>8,this[r+3]=255&t):D(this,t,r,!1),r+4},a.prototype.writeFloatLE=function(t,r,e){return N(this,t,r,!0,e)},a.prototype.writeFloatBE=function(t,r,e){return N(this,t,r,!1,e)},a.prototype.writeDoubleLE=function(t,r,e){return Y(this,t,r,!0,e)},a.prototype.writeDoubleBE=function(t,r,e){return Y(this,t,r,!1,e)},a.prototype.copy=function(t,r,e,n){if(e||(e=0),n||0===n||(n=this.length),r>=t.length&&(r=t.length),r||(r=0),n>0&&n<e&&(n=e),n===e)return 0;if(0===t.length||0===this.length)return 0;if(r<0)throw new RangeError("targetStart out of bounds");if(e<0||e>=this.length)throw new RangeError("sourceStart out of bounds");if(n<0)throw new RangeError("sourceEnd out of bounds");n>this.length&&(n=this.length),t.length-r<n-e&&(n=t.length-r+e);var i,o=n-e;if(this===t&&e<r&&r<n)for(i=o-1;i>=0;--i)t[i+r]=this[i+e];else if(o<1e3||!a.TYPED_ARRAY_SUPPORT)for(i=0;i<o;++i)t[i+r]=this[i+e];else Uint8Array.prototype.set.call(t,this.subarray(e,e+o),r);return o},a.prototype.fill=function(t,r,e,n){if("string"==typeof t){if("string"==typeof r?(n=r,r=0,e=this.length):"string"==typeof e&&(n=e,e=this.length),1===t.length){var i=t.charCodeAt(0);i<256&&(t=i)}if(void 0!==n&&"string"!=typeof n)throw new TypeError("encoding must be a string");if("string"==typeof n&&!a.isEncoding(n))throw new TypeError("Unknown encoding: "+n)}else"number"==typeof t&&(t&=255);if(r<0||this.length<r||this.length<e)throw new RangeError("Out of range index");if(e<=r)return this;var o;if(r>>>=0,e=void 0===e?this.length:e>>>0,t||(t=0),"number"==typeof t)for(o=r;o<e;++o)this[o]=t;else{var s=a.isBuffer(t)?t:j(new a(t,n).toString()),h=s.length;for(o=0;o<e-r;++o)this[o+r]=s[o%h]}return this};var L=/[^+\/0-9A-Za-z-_]/g;function C(t){return t<16?"0"+t.toString(16):t.toString(16)}function j(t,r){var e;r=r||1/0;for(var n=t.length,i=null,o=[],s=0;s<n;++s){if((e=t.charCodeAt(s))>55295&&e<57344){if(!i){if(e>56319){(r-=3)>-1&&o.push(239,191,189);continue}if(s+1===n){(r-=3)>-1&&o.push(239,191,189);continue}i=e;continue}if(e<56320){(r-=3)>-1&&o.push(239,191,189),i=e;continue}e=65536+(i-55296<<10|e-56320)}else i&&(r-=3)>-1&&o.push(239,191,189);if(i=null,e<128){if((r-=1)<0)break;o.push(e)}else if(e<2048){if((r-=2)<0)break;o.push(e>>6|192,63&e|128)}else if(e<65536){if((r-=3)<0)break;o.push(e>>12|224,e>>6&63|128,63&e|128)}else{if(!(e<1114112))throw new Error("Invalid code point");if((r-=4)<0)break;o.push(e>>18|240,e>>12&63|128,e>>6&63|128,63&e|128)}}return o}function J(t){return n.toByteArray(function(t){if((t=function(t){return t.trim?t.trim():t.replace(/^\s+|\s+$/g,"")}(t).replace(L,"")).length<2)return"";for(;t.length%4!=0;)t+="=";return t}(t))}function H(t,r,e,n){for(var i=0;i<n&&!(i+e>=r.length||i>=t.length);++i)r[i+e]=t[i];return i}}).call(r,e(8))},function(t,r,e){"use strict";t.exports={ImmutableDBNotDefinedError:()=>new Error("ImmutableDB instance not defined"),LogNotDefinedError:()=>new Error("Log instance not defined"),NotALogError:()=>new Error("Given argument is not an instance of Log")}},function(t,r,e){"use strict";t.exports=function(t,r){let e={};return t.forEach(t=>e[r?t[r]:t]=t),Object.keys(e).map(t=>e[t])}},function(t,r,e){"use strict";(function(r){const n=e(0),i=e(12),o=e(1),s=e(13),h=e(5),a=e(2),u=e(3),f=e(6),c=()=>(new Date).getTime().toString(),l=t=>t.hash,d=(t,r)=>t.concat(r),p=t=>t.next,g=(t,r)=>Math.max(t,r.clock.time),y=(t,r)=>(t[r.hash]=r,t);class w extends i{constructor(t,r,e,n,i,o,s=[]){if(!u(t))throw h.ImmutableDBNotDefinedError();if(u(e)&&!Array.isArray(e))throw new Error("'entries' argument must be an array of Entry instances");if(u(n)&&!Array.isArray(n))throw new Error("'heads' argument must be an array");super(),this._storage=t,this._id=r||c(),this._keystore=this._storage.keystore,this._key=o,this._keys=Array.isArray(s)?s:[s],e=e||[],this._entryIndex=e.reduce(y,{}),n=n||w.findHeads(e),this._headsIndex=n.reduce(y,{}),this._nextsIndex={},e.forEach(t=>t.next.forEach(r=>this._nextsIndex[r]=t.hash)),this._length=e?e.length:0;const f=Math.max(i?i.time:0,this.heads.reduce(g,0)),l=o&&o.getPublic?o.getPublic("hex"):o||this._id;this._clock=new a(l,f)}get id(){return this._id}get clock(){return this._clock}get length(){return this._length}get values(){return Object.values(this._entryIndex).sort(o.compare)||[]}get heads(){return Object.values(this._headsIndex)||[]}get tails(){return w.findTails(this.values)}get tailHashes(){return w.findTailHashes(this.values)}get(t){return this._entryIndex[t]}has(t){return void 0!==this._entryIndex[t.hash||t]}traverse(t,r){let e=t.map(p).reduce(d,[]),n={},i={},o=0;const s=t=>{i[t]||n[t]||(e.push(t),n[t]=!0)};for(t.forEach(t=>{i[t.hash]=t.hash,n[t.hash]=!0,o++});e.length>0&&o<r;){const t=e.shift(),r=this.get(t);r&&(o++,i[r.hash]=r.hash,n[r.hash]=!0,r.next.forEach(s))}return i}async append(t,r=1){if(this._key&&this._key.getPublic&&!this._keys.includes(this._key.getPublic("hex"))&&!this._keys.includes("*"))throw new Error("Not allowed to write");const e=Math.max(this.clock.time,this.heads.reduce(g,0))+1;this._clock=new a(this.clock.id,e);const n=Object.keys(this.traverse(this.heads,r)),i=await o.create(this._storage,this._keystore,this.id,t,n,this.clock,this._key);return this._entryIndex[i.hash]=i,n.forEach(t=>this._nextsIndex[t]=i.hash),this._headsIndex={},this._headsIndex[i.hash]=i,this._length++,i}async join(t,r=-1){if(!u(t))throw h.LogNotDefinedError();if(!w.isLog(t))throw h.NotALogError();const e=async t=>{this._keys.map(t=>t.getPublic?t.getPublic("hex"):t);return(await n(t,async t=>{if(!t.key)throw new Error("Entry doesn't have a public key");if(!t.sig)throw new Error("Entry doesn't have a signature");if(1===this._keys.length&&this._keys[0]===this._key&&t.id!==this.id)throw new Error("Entry doesn't belong in this log (wrong ID)");if(this._keys.length>0&&!this._keys.includes("*")&&!((t,r)=>t.find(t=>t===r.key))(this._keys.concat([this._key]),t))return console.warn("Warning: Input log contains entries that are not allowed in this log. Logs weren't joined."),!1;try{await o.verifyEntry(t,this._keystore)}catch(r){throw new Error(`Invalid signature in entry '${t.hash}'`)}return!0})).every(t=>!0===t)},i=((t,r)=>{let e=Object.keys(t._headsIndex),n={},i={};const o=t=>{n[t]||r.get(t)||(e.push(t),n[t]=!0)};for(;e.length>0;){const s=e.shift(),h=t.get(s);h&&!r.get(s)&&h.id===this.id&&(i[h.hash]=h,n[h.hash]=!0,h.next.forEach(o))}return i})(t,this);if(this._key&&this._key.getPublic){if(!await e(Object.values(i)))return this}this._entryIndex=Object.assign(this._entryIndex,i);if(Object.values(i).forEach(t=>t.next.forEach(r=>this._nextsIndex[r]=t.hash)),this._length+=Object.values(i).length,r>-1){let t=this.values;t=t.slice(-r),this._entryIndex=t.reduce(y,{}),this._length=Object.values(this._entryIndex).length}const s=Object.values(i).map(p).reduce(d,[]),f=w.findHeads(Object.values(Object.assign({},this._headsIndex,t._headsIndex))).filter(t=>!s.find(r=>r===t.hash)).filter(t=>!this._nextsIndex[t.hash]).reduce(y,{});this._headsIndex=f;const c=Object.values(this._headsIndex).reduce(g,0);return this._clock=new a(this.clock.id,Math.max(this.clock.time,c)),this}toJSON(){return{id:this.id,heads:this.heads.map(l)}}toSnapshot(){return{id:this.id,heads:this.heads,values:this.values}}toBuffer(){return r.from(JSON.stringify(this.toJSON()))}toString(t){return this.values.slice().reverse().map((r,e)=>{const n=o.findChildren(r,this.values).length;let i=new Array(Math.max(n-1,0));return i=n>1?i.fill("  "):i,(i=n>0?i.concat(["└─"]):i).join("")+(t?t(r.payload):r.payload)}).join("\n")}static isLog(t){return void 0!==t.id&&void 0!==t.heads&&void 0!==t._entryIndex}toMultihash(){return s.toMultihash(this._storage,this)}static fromMultihash(t,r,e=-1,n,i,o){if(!u(t))throw h.ImmutableDBNotDefinedError();if(!u(r))throw new Error(`Invalid hash: ${r}`);return s.fromMultihash(t,r,e,n,o).then(r=>new w(t,r.id,r.values,r.heads,r.clock,i))}static fromEntryHash(t,r,e,n=-1,i,o,a,f){if(!u(t))throw h.ImmutableDBNotDefinedError();if(!u(r))throw new Error("'hash' must be defined");return s.fromEntryHash(t,r,e,n,i,f).then(r=>new w(t,e,r.values,null,null,o,a))}static fromJSON(t,r,e=-1,n,i,o,a){if(!u(t))throw h.ImmutableDBNotDefinedError();return s.fromJSON(t,r,e,n,o,a).then(r=>new w(t,r.id,r.values,null,null,n,i))}static fromEntry(t,r,e=-1,n,i){if(!u(t))throw h.ImmutableDBNotDefinedError();if(!u(r))throw new Error("'sourceEntries' must be defined");return s.fromEntry(t,r,e,n,i).then(r=>new w(t,r.id,r.values))}static findHeads(t){var r=t.reduce((t,r,e,n)=>{return r.next.forEach(e=>t[e]=r.hash),t},{});return t.filter(t=>void 0===r[t.hash]).sort((t,r)=>t.clock.id>r.clock.id)}static findTails(t){var r={},e=[],n={},i=[];t.forEach(t=>{0===t.next.length&&e.push(t);t.next.forEach(e=>{r[e]||(r[e]=[]),r[e].push(t)}),i=i.concat(t.next),n[t.hash]=!0});const s=i.filter(t=>void 0===n[t]).map(t=>r[t]).reduce((t,r,e,n)=>t.concat(f(r,"hash")),[]).concat(e);return f(s,"hash").sort(o.compare)}static findTailHashes(t){var r={};return t.forEach(t=>r[t.hash]=!0),t.reduce((t,e,n,i)=>{return e.next.reverse().forEach(e=>{void 0===r[e]&&t.splice(0,0,e)}),t},[])}}t.exports=w}).call(r,e(4).Buffer)},function(t,r){var e;e=function(){return this}();try{e=e||Function("return this")()||(0,eval)("this")}catch(t){"object"==typeof window&&(e=window)}t.exports=e},function(t,r,e){"use strict";r.byteLength=function(t){var r=u(t),e=r[0],n=r[1];return 3*(e+n)/4-n},r.toByteArray=function(t){for(var r,e=u(t),n=e[0],s=e[1],h=new o(function(t,r,e){return 3*(r+e)/4-e}(0,n,s)),a=0,f=s>0?n-4:n,c=0;c<f;c+=4)r=i[t.charCodeAt(c)]<<18|i[t.charCodeAt(c+1)]<<12|i[t.charCodeAt(c+2)]<<6|i[t.charCodeAt(c+3)],h[a++]=r>>16&255,h[a++]=r>>8&255,h[a++]=255&r;2===s&&(r=i[t.charCodeAt(c)]<<2|i[t.charCodeAt(c+1)]>>4,h[a++]=255&r);1===s&&(r=i[t.charCodeAt(c)]<<10|i[t.charCodeAt(c+1)]<<4|i[t.charCodeAt(c+2)]>>2,h[a++]=r>>8&255,h[a++]=255&r);return h},r.fromByteArray=function(t){for(var r,e=t.length,i=e%3,o=[],s=0,h=e-i;s<h;s+=16383)o.push(c(t,s,s+16383>h?h:s+16383));1===i?(r=t[e-1],o.push(n[r>>2]+n[r<<4&63]+"==")):2===i&&(r=(t[e-2]<<8)+t[e-1],o.push(n[r>>10]+n[r>>4&63]+n[r<<2&63]+"="));return o.join("")};for(var n=[],i=[],o="undefined"!=typeof Uint8Array?Uint8Array:Array,s="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",h=0,a=s.length;h<a;++h)n[h]=s[h],i[s.charCodeAt(h)]=h;function u(t){var r=t.length;if(r%4>0)throw new Error("Invalid string. Length must be a multiple of 4");var e=t.indexOf("=");return-1===e&&(e=r),[e,e===r?0:4-e%4]}function f(t){return n[t>>18&63]+n[t>>12&63]+n[t>>6&63]+n[63&t]}function c(t,r,e){for(var n,i=[],o=r;o<e;o+=3)n=(t[o]<<16&16711680)+(t[o+1]<<8&65280)+(255&t[o+2]),i.push(f(n));return i.join("")}i["-".charCodeAt(0)]=62,i["_".charCodeAt(0)]=63},function(t,r){r.read=function(t,r,e,n,i){var o,s,h=8*i-n-1,a=(1<<h)-1,u=a>>1,f=-7,c=e?i-1:0,l=e?-1:1,d=t[r+c];for(c+=l,o=d&(1<<-f)-1,d>>=-f,f+=h;f>0;o=256*o+t[r+c],c+=l,f-=8);for(s=o&(1<<-f)-1,o>>=-f,f+=n;f>0;s=256*s+t[r+c],c+=l,f-=8);if(0===o)o=1-u;else{if(o===a)return s?NaN:1/0*(d?-1:1);s+=Math.pow(2,n),o-=u}return(d?-1:1)*s*Math.pow(2,o-n)},r.write=function(t,r,e,n,i,o){var s,h,a,u=8*o-i-1,f=(1<<u)-1,c=f>>1,l=23===i?Math.pow(2,-24)-Math.pow(2,-77):0,d=n?0:o-1,p=n?1:-1,g=r<0||0===r&&1/r<0?1:0;for(r=Math.abs(r),isNaN(r)||r===1/0?(h=isNaN(r)?1:0,s=f):(s=Math.floor(Math.log(r)/Math.LN2),r*(a=Math.pow(2,-s))<1&&(s--,a*=2),(r+=s+c>=1?l/a:l*Math.pow(2,1-c))*a>=2&&(s++,a/=2),s+c>=f?(h=0,s=f):s+c>=1?(h=(r*a-1)*Math.pow(2,i),s+=c):(h=r*Math.pow(2,c-1)*Math.pow(2,i),s=0));i>=8;t[e+d]=255&h,d+=p,h/=256,i-=8);for(s=s<<i|h,u+=i;u>0;t[e+d]=255&s,d+=p,s/=256,u-=8);t[e+d-p]|=128*g}},function(t,r){var e={}.toString;t.exports=Array.isArray||function(t){return"[object Array]"==e.call(t)}},function(t,r,e){"use strict";t.exports=class{constuctor(t){}append(t){}merge(t){}get(t){}has(t){}get values(){}get length(){}}},function(t,r,e){"use strict";e(0);const n=e(1),i=e(14),o=e(2),s=e(5),h=e(3),a=e(6),u=(e(16),e(17)),f=(t,r)=>t.slice(t.length-r,t.length);t.exports=class{static toMultihash(t,r){if(!h(t))throw s.ImmutableDBNotDefinedError();if(!h(r))throw s.LogNotDefinedError();if(r.values.length<1)throw new Error("Can't serialize an empty log");return t.object.put(r.toBuffer()).then(t=>t.toJSON().multihash)}static fromMultihash(t,r,e=-1,a,u){if(!h(t))throw s.ImmutableDBNotDefinedError();if(!h(r))throw new Error(`Invalid hash: ${r}`);return t.object.get(r,{enc:"base58"}).then(t=>JSON.parse(t.toJSON().data)).then(r=>{if(!r.heads||!r.id)throw s.NotALogError();return i.fetchAll(t,r.heads,e,a,null,u).then(t=>{const e=t.reduce((t,r)=>r.clock.time>t.time?new o(r.clock.id,r.clock.time):t,new o(r.id)),i=t.slice().sort(n.compare),s=i.filter(t=>r.heads.includes(t.hash));return{id:r.id,values:i,heads:s,clock:e}})})}static fromEntryHash(t,r,e,n=-1,o,a){if(!h(t))throw s.IpfsNotDefinedError();if(!h(r))throw new Error("'entryHash' must be defined");n=n>-1?Math.max(n,1):n;const u=o;return i.fetchParallel(t,[r],n,u,null,null,a).then(t=>({values:n>-1?f(t,n):t}))}static fromJSON(t,r,e=-1,o,a,u){if(!h(t))throw s.ImmutableDBNotDefinedError();return i.fetchParallel(t,r.heads.map(t=>t.hash),e,[],16,a,u).then(t=>{const e=t.slice().sort(n.compare);return t.filter(t=>r.heads.includes(t.hash)),{id:r.id,values:e,heads:r.heads}})}static fromEntry(t,r,e=-1,o,f,c,l){if(!h(t))throw s.ImmutableDBNotDefinedError();if(!h(r))throw new Error("'sourceEntries' must be defined");if(!Array.isArray(r)&&!n.isEntry(r))throw new Error("'sourceEntries' argument must be an array of Entry instances or a single Entry");Array.isArray(r)||(r=[r]),e=e>-1?Math.max(e,r.length):e;const d=o?o.map(t=>t.hash?t.hash:t):o,p=r.map(t=>t.hash);return i.fetchParallel(t,p,e,d,null,null,l).then(t=>{var i=r.concat(t),o=a(i,"hash").sort(n.compare);const s=o.slice(e>-1?-e:-o.length),h=((t,r)=>{var e=t.slice(r.length,t.length);return r.concat(e)})(s,u(s,r,"hash"));return{id:h[h.length-1].id,values:h}})}}},function(t,r,e){"use strict";const n=e(15),i=e(0),o=e(1);class s{static fetchParallel(t,r,e,n=[],o,h,a){const u=(t,r)=>t.concat(r);return i(r,r=>s.fetchAll(t,r,e,n,h,a),{concurrency:Math.max(o||r.length,1)}).then(t=>t.reduce(u,[]))}static fetchAll(t,r,e,i=[],s=null,h){let a=[],u={},f=Array.isArray(r)?r.slice():[r];const c=t=>f.push(t);i.forEach(t=>u[t.hash]=t);return n(()=>f.length>0&&(a.length<e||e<0),()=>{const r=f.shift();return u[r]?Promise.resolve():new Promise((e,n)=>{const i=s?setTimeout(()=>{console.warn(`Warning: Couldn't fetch entry '${r}', request timed out (${s}ms)`),e()},s):null;o.fromMultihash(t,r).then(t=>{clearTimeout(i),o.isEntry(t)&&(t.next.forEach(c),a.push(t),u[r]=t,h&&h(r,t,a.length))}).then(e).catch(t=>{e()})})}).then(()=>a)}}t.exports=s},function(t,r,e){"use strict";const n=t=>new Promise(r=>{r(t())});t.exports=((t,r)=>n(function e(){if(t())return n(r).then(e)}))},function(t,r,e){"use strict";t.exports=function(t,r,e){var n={},i={};return t.forEach(t=>i[e?t[e]:t]=!0),r.reduce((t,r)=>{var o=void 0!==i[e?r[e]:r],s=void 0!==n[e?r[e]:r];return o&&!s&&(t.push(r),n[e?r[e]:r]=!0),t},[])}},function(t,r,e){"use strict";t.exports=function(t,r,e){var n={},i={};return t.forEach(t=>i[e?t[e]:t]=!0),r.reduce((t,r)=>{var o=void 0!==i[e?r[e]:r],s=void 0!==n[e?r[e]:r];return o||s||(t.push(r),n[e?r[e]:r]=!0),t},[])}}]);
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/browser/browser.html
+++ /dev/null
@@ -1,43 +0,0 @@
-<html>
-  <head>
-    <meta charset="utf-8">
-  </head>
-  <body>
-    <h1>ipfs-log example</h1>
-    <pre id="output"></pre>
-
-    <script type="text/javascript" src="../../dist/ipfslog.min.js" charset="utf-8"></script>
-    <script type="text/javascript" src="../../node_modules/ipfs/dist/index.min.js" charset="utf-8"></script>
-
-    <script type="text/javascript">
-      const ipfs = new Ipfs({ 
-        repo: './ipfs-log/examples/browser/0.5.0',
-        start: false,
-        EXPERIMENTAL: {
-          pubsub: false
-        },
-      })
-
-      ipfs.on('error', (e) => console.error(e))
-      ipfs.on('ready', () => {
-        const outputElm = document.getElementById('output')
-
-        // When IPFS is ready, add some log entries
-        let log = new Log(ipfs, 'example')
-        log.append('one')
-          .then((res) => {
-            const values = JSON.stringify(log.values, null, 2)
-            console.log('\n', values)
-            outputElm.innerHTML += values + '<br><br>'
-            return log.append({ two: 'hello' })
-          })
-          .then((res) => {
-            const values = JSON.stringify(log.values, null, 2)
-            console.log('\n', values)
-            outputElm.innerHTML += values + '<br><br>'
-          })
-      })
-
-    </script>
-  </body>
-</html>
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/browser/index.html
+++ /dev/null
@@ -1,10 +0,0 @@
-<html>
-  <head>
-    <meta charset="utf-8">
-  </head>
-  <body>
-    <h1>ipfs-log example</h1>
-    <pre id="output"></pre>
-    <script type="text/javascript" src="bundle.js" charset="utf-8"></script>
-  </body>
-</html>
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/browser/index.js
+++ /dev/null
@@ -1,33 +0,0 @@
-'use strict'
-
-const IPFS = require('ipfs')
-const Log = require('../../src/log')
-
-const ipfs = new IPFS({
-  repo: './ipfs-log/examples/browser/0.5.0',
-  start: false,
-  EXPERIMENTAL: {
-    pubsub: false
-  },
-})
-
-ipfs.on('error', (e) => console.error(e))
-
-ipfs.on('ready', () => {
-  const outputElm = document.getElementById('output')
-
-  // When IPFS is ready, add some log entries
-  let log = new Log(ipfs, 'example')
-  log.append('one')
-    .then((res) => {
-      const values = JSON.stringify(log.values, null, 2)
-      console.log('\n', values)
-      outputElm.innerHTML += values + '<br><br>'
-      return log.append({ two: 'hello' })
-    })
-    .then((res) => {
-      const values = JSON.stringify(log.values, null, 2)
-      console.log('\n', values)
-      outputElm.innerHTML += values + '<br><br>'
-    })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/browser/lib/ipfslog.min.js
+++ /dev/null
@@ -1,8 +0,0 @@
-var Log=function(t){var r={};function e(n){if(r[n])return r[n].exports;var i=r[n]={i:n,l:!1,exports:{}};return t[n].call(i.exports,i,i.exports,e),i.l=!0,i.exports}return e.m=t,e.c=r,e.d=function(t,r,n){e.o(t,r)||Object.defineProperty(t,r,{configurable:!1,enumerable:!0,get:n})},e.n=function(t){var r=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(r,"a",r),r},e.o=function(t,r){return Object.prototype.hasOwnProperty.call(t,r)},e.p="",e(e.s=8)}([function(t,r,e){"use strict";t.exports=((t,r,e)=>new Promise((n,i)=>{if(e=Object.assign({concurrency:1/0},e),"function"!=typeof r)throw new TypeError("Mapper function is required");const o=e.concurrency;if(!("number"==typeof o&&o>=1))throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${o}\` (${typeof o})`);const s=[],a=t[Symbol.iterator]();let h=!1,u=!1,f=0,c=0;const l=()=>{if(h)return;const t=a.next(),e=c;if(c++,t.done)return u=!0,void(0===f&&n(s));f++,Promise.resolve(t.value).then(t=>r(t,e)).then(t=>{s[e]=t,f--,l()},t=>{h=!0,i(t)})};for(let t=0;t<o&&(l(),!u);t++);}))},function(t,r,e){"use strict";(function(r){const n=e(2),i=e(3),o=()=>new Error("Ipfs instance not defined");class s{static async create(t,r,e,a,h=[],u,f,c=[]){if(!i(t))throw o();if(!i(e))throw new Error("Entry requires an id");if(!i(a))throw new Error("Entry requires data");if(!i(h)||!Array.isArray(h))throw new Error("'next' argument is not an array");let l=h.filter(i).map(t=>t.hash?t.hash:t);const d=u?u.id:f?f.getPublic("hex"):e,g=u?u.time:null;let p={hash:null,id:e,payload:a,next:l,refs:c,v:0,clock:new n(d,g)};return r&&f&&(p=await s.signEntry(r,p,f)),p.hash=await s.toMultihash(t,p),p}static async signEntry(t,e,n){const i=await t.sign(n,r.from(JSON.stringify(e)));return e.sig=i,e.key=n.getPublic("hex"),e}static async verifyEntry(t,e){const n=Object.assign({},{hash:null,id:t.id,payload:t.payload,next:t.next,refs:t.refs,v:t.v,clock:t.clock}),i=await e.importPublicKey(t.key);await e.verify(t.sig,i,r.from(JSON.stringify(n)))}static toMultihash(t,e){if(!t)throw o();const n=r.from(JSON.stringify(e));return t.object.put(n).then(t=>t.toJSON().multihash)}static fromMultihash(t,r){if(!t)throw o();if(!r)throw new Error(`Invalid hash: ${r}`);return t.object.get(r,{enc:"base58"}).then(t=>JSON.parse(t.toJSON().data)).then(t=>{let e={hash:r,id:t.id,payload:t.payload,next:t.next,refs:t.refs,v:t.v,clock:t.clock};return t.sig&&Object.assign(e,{sig:t.sig}),t.key&&Object.assign(e,{key:t.key}),e})}static isEntry(t){return void 0!==t.id&&void 0!==t.next&&void 0!==t.refs&&void 0!==t.hash&&void 0!==t.payload&&void 0!==t.v&&void 0!==t.clock}static compare(t,r){var e=n.compare(t.clock,r.clock);return 0===e?t.clock.id<r.clock.id?-1:1:e}static isEqual(t,r){return t.hash===r.hash}static isParent(t,r){return r.next.indexOf(t.hash)>-1}static findChildren(t,r){for(var e=[],n=r.find(r=>s.isParent(t,r)),i=t;n;)e.push(n),i=n,n=r.find(t=>s.isParent(i,t));return e=e.sort((t,r)=>t.clock.time>t.clock.time)}}t.exports=s}).call(r,e(4).Buffer)},function(t,r,e){"use strict";class n{constructor(t,r){this.id=t,this.time=r||0}tick(){return new n(this.id,++this.time)}merge(t){return this.time=Math.max(this.time,t.time),new n(this.id,this.time)}clone(){return new n(this.id,this.time)}static compare(t,r){var e=t.time-r.time;return 0===e&&t.id!==r.id?t.id<r.id?-1:1:e}}t.exports=n},function(t,r,e){"use strict";t.exports=(t=>void 0!==t&&null!==t)},function(t,r,e){"use strict";(function(t){
-/*!
- * The buffer module from node.js, for the browser.
- *
- * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>
- * @license  MIT
- */
-var n=e(10),i=e(11),o=e(12);function s(){return h.TYPED_ARRAY_SUPPORT?2147483647:1073741823}function a(t,r){if(s()<r)throw new RangeError("Invalid typed array length");return h.TYPED_ARRAY_SUPPORT?(t=new Uint8Array(r)).__proto__=h.prototype:(null===t&&(t=new h(r)),t.length=r),t}function h(t,r,e){if(!(h.TYPED_ARRAY_SUPPORT||this instanceof h))return new h(t,r,e);if("number"==typeof t){if("string"==typeof r)throw new Error("If encoding is specified then the first argument must be a string");return c(this,t)}return u(this,t,r,e)}function u(t,r,e,n){if("number"==typeof r)throw new TypeError('"value" argument must not be a number');return"undefined"!=typeof ArrayBuffer&&r instanceof ArrayBuffer?function(t,r,e,n){if(r.byteLength,e<0||r.byteLength<e)throw new RangeError("'offset' is out of bounds");if(r.byteLength<e+(n||0))throw new RangeError("'length' is out of bounds");r=void 0===e&&void 0===n?new Uint8Array(r):void 0===n?new Uint8Array(r,e):new Uint8Array(r,e,n);h.TYPED_ARRAY_SUPPORT?(t=r).__proto__=h.prototype:t=l(t,r);return t}(t,r,e,n):"string"==typeof r?function(t,r,e){"string"==typeof e&&""!==e||(e="utf8");if(!h.isEncoding(e))throw new TypeError('"encoding" must be a valid string encoding');var n=0|g(r,e),i=(t=a(t,n)).write(r,e);i!==n&&(t=t.slice(0,i));return t}(t,r,e):function(t,r){if(h.isBuffer(r)){var e=0|d(r.length);return 0===(t=a(t,e)).length?t:(r.copy(t,0,0,e),t)}if(r){if("undefined"!=typeof ArrayBuffer&&r.buffer instanceof ArrayBuffer||"length"in r)return"number"!=typeof r.length||function(t){return t!=t}(r.length)?a(t,0):l(t,r);if("Buffer"===r.type&&o(r.data))return l(t,r.data)}throw new TypeError("First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.")}(t,r)}function f(t){if("number"!=typeof t)throw new TypeError('"size" argument must be a number');if(t<0)throw new RangeError('"size" argument must not be negative')}function c(t,r){if(f(r),t=a(t,r<0?0:0|d(r)),!h.TYPED_ARRAY_SUPPORT)for(var e=0;e<r;++e)t[e]=0;return t}function l(t,r){var e=r.length<0?0:0|d(r.length);t=a(t,e);for(var n=0;n<e;n+=1)t[n]=255&r[n];return t}function d(t){if(t>=s())throw new RangeError("Attempt to allocate Buffer larger than maximum size: 0x"+s().toString(16)+" bytes");return 0|t}function g(t,r){if(h.isBuffer(t))return t.length;if("undefined"!=typeof ArrayBuffer&&"function"==typeof ArrayBuffer.isView&&(ArrayBuffer.isView(t)||t instanceof ArrayBuffer))return t.byteLength;"string"!=typeof t&&(t=""+t);var e=t.length;if(0===e)return 0;for(var n=!1;;)switch(r){case"ascii":case"latin1":case"binary":return e;case"utf8":case"utf-8":case void 0:return C(t).length;case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return 2*e;case"hex":return e>>>1;case"base64":return J(t).length;default:if(n)return C(t).length;r=(""+r).toLowerCase(),n=!0}}function p(t,r,e){var n=t[r];t[r]=t[e],t[e]=n}function y(t,r,e,n,i){if(0===t.length)return-1;if("string"==typeof e?(n=e,e=0):e>2147483647?e=2147483647:e<-2147483648&&(e=-2147483648),e=+e,isNaN(e)&&(e=i?0:t.length-1),e<0&&(e=t.length+e),e>=t.length){if(i)return-1;e=t.length-1}else if(e<0){if(!i)return-1;e=0}if("string"==typeof r&&(r=h.from(r,n)),h.isBuffer(r))return 0===r.length?-1:w(t,r,e,n,i);if("number"==typeof r)return r&=255,h.TYPED_ARRAY_SUPPORT&&"function"==typeof Uint8Array.prototype.indexOf?i?Uint8Array.prototype.indexOf.call(t,r,e):Uint8Array.prototype.lastIndexOf.call(t,r,e):w(t,[r],e,n,i);throw new TypeError("val must be string, number or Buffer")}function w(t,r,e,n,i){var o,s=1,a=t.length,h=r.length;if(void 0!==n&&("ucs2"===(n=String(n).toLowerCase())||"ucs-2"===n||"utf16le"===n||"utf-16le"===n)){if(t.length<2||r.length<2)return-1;s=2,a/=2,h/=2,e/=2}function u(t,r){return 1===s?t[r]:t.readUInt16BE(r*s)}if(i){var f=-1;for(o=e;o<a;o++)if(u(t,o)===u(r,-1===f?0:o-f)){if(-1===f&&(f=o),o-f+1===h)return f*s}else-1!==f&&(o-=o-f),f=-1}else for(e+h>a&&(e=a-h),o=e;o>=0;o--){for(var c=!0,l=0;l<h;l++)if(u(t,o+l)!==u(r,l)){c=!1;break}if(c)return o}return-1}function v(t,r,e,n){e=Number(e)||0;var i=t.length-e;n?(n=Number(n))>i&&(n=i):n=i;var o=r.length;if(o%2!=0)throw new TypeError("Invalid hex string");n>o/2&&(n=o/2);for(var s=0;s<n;++s){var a=parseInt(r.substr(2*s,2),16);if(isNaN(a))return s;t[e+s]=a}return s}function m(t,r,e,n){return H(C(r,t.length-e),t,e,n)}function E(t,r,e,n){return H(function(t){for(var r=[],e=0;e<t.length;++e)r.push(255&t.charCodeAt(e));return r}(r),t,e,n)}function b(t,r,e,n){return E(t,r,e,n)}function _(t,r,e,n){return H(J(r),t,e,n)}function A(t,r,e,n){return H(function(t,r){for(var e,n,i,o=[],s=0;s<t.length&&!((r-=2)<0);++s)e=t.charCodeAt(s),n=e>>8,i=e%256,o.push(i),o.push(n);return o}(r,t.length-e),t,e,n)}function x(t,r,e){return 0===r&&e===t.length?n.fromByteArray(t):n.fromByteArray(t.slice(r,e))}function P(t,r,e){e=Math.min(t.length,e);for(var n=[],i=r;i<e;){var o,s,a,h,u=t[i],f=null,c=u>239?4:u>223?3:u>191?2:1;if(i+c<=e)switch(c){case 1:u<128&&(f=u);break;case 2:128==(192&(o=t[i+1]))&&(h=(31&u)<<6|63&o)>127&&(f=h);break;case 3:o=t[i+1],s=t[i+2],128==(192&o)&&128==(192&s)&&(h=(15&u)<<12|(63&o)<<6|63&s)>2047&&(h<55296||h>57343)&&(f=h);break;case 4:o=t[i+1],s=t[i+2],a=t[i+3],128==(192&o)&&128==(192&s)&&128==(192&a)&&(h=(15&u)<<18|(63&o)<<12|(63&s)<<6|63&a)>65535&&h<1114112&&(f=h)}null===f?(f=65533,c=1):f>65535&&(f-=65536,n.push(f>>>10&1023|55296),f=56320|1023&f),n.push(f),i+=c}return function(t){var r=t.length;if(r<=I)return String.fromCharCode.apply(String,t);var e="",n=0;for(;n<r;)e+=String.fromCharCode.apply(String,t.slice(n,n+=I));return e}(n)}r.Buffer=h,r.SlowBuffer=function(t){+t!=t&&(t=0);return h.alloc(+t)},r.INSPECT_MAX_BYTES=50,h.TYPED_ARRAY_SUPPORT=void 0!==t.TYPED_ARRAY_SUPPORT?t.TYPED_ARRAY_SUPPORT:function(){try{var t=new Uint8Array(1);return t.__proto__={__proto__:Uint8Array.prototype,foo:function(){return 42}},42===t.foo()&&"function"==typeof t.subarray&&0===t.subarray(1,1).byteLength}catch(t){return!1}}(),r.kMaxLength=s(),h.poolSize=8192,h._augment=function(t){return t.__proto__=h.prototype,t},h.from=function(t,r,e){return u(null,t,r,e)},h.TYPED_ARRAY_SUPPORT&&(h.prototype.__proto__=Uint8Array.prototype,h.__proto__=Uint8Array,"undefined"!=typeof Symbol&&Symbol.species&&h[Symbol.species]===h&&Object.defineProperty(h,Symbol.species,{value:null,configurable:!0})),h.alloc=function(t,r,e){return function(t,r,e,n){return f(r),r<=0?a(t,r):void 0!==e?"string"==typeof n?a(t,r).fill(e,n):a(t,r).fill(e):a(t,r)}(null,t,r,e)},h.allocUnsafe=function(t){return c(null,t)},h.allocUnsafeSlow=function(t){return c(null,t)},h.isBuffer=function(t){return!(null==t||!t._isBuffer)},h.compare=function(t,r){if(!h.isBuffer(t)||!h.isBuffer(r))throw new TypeError("Arguments must be Buffers");if(t===r)return 0;for(var e=t.length,n=r.length,i=0,o=Math.min(e,n);i<o;++i)if(t[i]!==r[i]){e=t[i],n=r[i];break}return e<n?-1:n<e?1:0},h.isEncoding=function(t){switch(String(t).toLowerCase()){case"hex":case"utf8":case"utf-8":case"ascii":case"latin1":case"binary":case"base64":case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return!0;default:return!1}},h.concat=function(t,r){if(!o(t))throw new TypeError('"list" argument must be an Array of Buffers');if(0===t.length)return h.alloc(0);var e;if(void 0===r)for(r=0,e=0;e<t.length;++e)r+=t[e].length;var n=h.allocUnsafe(r),i=0;for(e=0;e<t.length;++e){var s=t[e];if(!h.isBuffer(s))throw new TypeError('"list" argument must be an Array of Buffers');s.copy(n,i),i+=s.length}return n},h.byteLength=g,h.prototype._isBuffer=!0,h.prototype.swap16=function(){var t=this.length;if(t%2!=0)throw new RangeError("Buffer size must be a multiple of 16-bits");for(var r=0;r<t;r+=2)p(this,r,r+1);return this},h.prototype.swap32=function(){var t=this.length;if(t%4!=0)throw new RangeError("Buffer size must be a multiple of 32-bits");for(var r=0;r<t;r+=4)p(this,r,r+3),p(this,r+1,r+2);return this},h.prototype.swap64=function(){var t=this.length;if(t%8!=0)throw new RangeError("Buffer size must be a multiple of 64-bits");for(var r=0;r<t;r+=8)p(this,r,r+7),p(this,r+1,r+6),p(this,r+2,r+5),p(this,r+3,r+4);return this},h.prototype.toString=function(){var t=0|this.length;return 0===t?"":0===arguments.length?P(this,0,t):function(t,r,e){var n=!1;if((void 0===r||r<0)&&(r=0),r>this.length)return"";if((void 0===e||e>this.length)&&(e=this.length),e<=0)return"";if((e>>>=0)<=(r>>>=0))return"";for(t||(t="utf8");;)switch(t){case"hex":return B(this,r,e);case"utf8":case"utf-8":return P(this,r,e);case"ascii":return R(this,r,e);case"latin1":case"binary":return k(this,r,e);case"base64":return x(this,r,e);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return S(this,r,e);default:if(n)throw new TypeError("Unknown encoding: "+t);t=(t+"").toLowerCase(),n=!0}}.apply(this,arguments)},h.prototype.equals=function(t){if(!h.isBuffer(t))throw new TypeError("Argument must be a Buffer");return this===t||0===h.compare(this,t)},h.prototype.inspect=function(){var t="",e=r.INSPECT_MAX_BYTES;return this.length>0&&(t=this.toString("hex",0,e).match(/.{2}/g).join(" "),this.length>e&&(t+=" ... ")),"<Buffer "+t+">"},h.prototype.compare=function(t,r,e,n,i){if(!h.isBuffer(t))throw new TypeError("Argument must be a Buffer");if(void 0===r&&(r=0),void 0===e&&(e=t?t.length:0),void 0===n&&(n=0),void 0===i&&(i=this.length),r<0||e>t.length||n<0||i>this.length)throw new RangeError("out of range index");if(n>=i&&r>=e)return 0;if(n>=i)return-1;if(r>=e)return 1;if(r>>>=0,e>>>=0,n>>>=0,i>>>=0,this===t)return 0;for(var o=i-n,s=e-r,a=Math.min(o,s),u=this.slice(n,i),f=t.slice(r,e),c=0;c<a;++c)if(u[c]!==f[c]){o=u[c],s=f[c];break}return o<s?-1:s<o?1:0},h.prototype.includes=function(t,r,e){return-1!==this.indexOf(t,r,e)},h.prototype.indexOf=function(t,r,e){return y(this,t,r,e,!0)},h.prototype.lastIndexOf=function(t,r,e){return y(this,t,r,e,!1)},h.prototype.write=function(t,r,e,n){if(void 0===r)n="utf8",e=this.length,r=0;else if(void 0===e&&"string"==typeof r)n=r,e=this.length,r=0;else{if(!isFinite(r))throw new Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");r|=0,isFinite(e)?(e|=0,void 0===n&&(n="utf8")):(n=e,e=void 0)}var i=this.length-r;if((void 0===e||e>i)&&(e=i),t.length>0&&(e<0||r<0)||r>this.length)throw new RangeError("Attempt to write outside buffer bounds");n||(n="utf8");for(var o=!1;;)switch(n){case"hex":return v(this,t,r,e);case"utf8":case"utf-8":return m(this,t,r,e);case"ascii":return E(this,t,r,e);case"latin1":case"binary":return b(this,t,r,e);case"base64":return _(this,t,r,e);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return A(this,t,r,e);default:if(o)throw new TypeError("Unknown encoding: "+n);n=(""+n).toLowerCase(),o=!0}},h.prototype.toJSON=function(){return{type:"Buffer",data:Array.prototype.slice.call(this._arr||this,0)}};var I=4096;function R(t,r,e){var n="";e=Math.min(t.length,e);for(var i=r;i<e;++i)n+=String.fromCharCode(127&t[i]);return n}function k(t,r,e){var n="";e=Math.min(t.length,e);for(var i=r;i<e;++i)n+=String.fromCharCode(t[i]);return n}function B(t,r,e){var n=t.length;(!r||r<0)&&(r=0),(!e||e<0||e>n)&&(e=n);for(var i="",o=r;o<e;++o)i+=j(t[o]);return i}function S(t,r,e){for(var n=t.slice(r,e),i="",o=0;o<n.length;o+=2)i+=String.fromCharCode(n[o]+256*n[o+1]);return i}function O(t,r,e){if(t%1!=0||t<0)throw new RangeError("offset is not uint");if(t+r>e)throw new RangeError("Trying to access beyond buffer length")}function T(t,r,e,n,i,o){if(!h.isBuffer(t))throw new TypeError('"buffer" argument must be a Buffer instance');if(r>i||r<o)throw new RangeError('"value" argument is out of bounds');if(e+n>t.length)throw new RangeError("Index out of range")}function M(t,r,e,n){r<0&&(r=65535+r+1);for(var i=0,o=Math.min(t.length-e,2);i<o;++i)t[e+i]=(r&255<<8*(n?i:1-i))>>>8*(n?i:1-i)}function U(t,r,e,n){r<0&&(r=4294967295+r+1);for(var i=0,o=Math.min(t.length-e,4);i<o;++i)t[e+i]=r>>>8*(n?i:3-i)&255}function D(t,r,e,n,i,o){if(e+n>t.length)throw new RangeError("Index out of range");if(e<0)throw new RangeError("Index out of range")}function N(t,r,e,n,o){return o||D(t,0,e,4),i.write(t,r,e,n,23,4),e+4}function Y(t,r,e,n,o){return o||D(t,0,e,8),i.write(t,r,e,n,52,8),e+8}h.prototype.slice=function(t,r){var e,n=this.length;if(t=~~t,r=void 0===r?n:~~r,t<0?(t+=n)<0&&(t=0):t>n&&(t=n),r<0?(r+=n)<0&&(r=0):r>n&&(r=n),r<t&&(r=t),h.TYPED_ARRAY_SUPPORT)(e=this.subarray(t,r)).__proto__=h.prototype;else{var i=r-t;e=new h(i,void 0);for(var o=0;o<i;++o)e[o]=this[o+t]}return e},h.prototype.readUIntLE=function(t,r,e){t|=0,r|=0,e||O(t,r,this.length);for(var n=this[t],i=1,o=0;++o<r&&(i*=256);)n+=this[t+o]*i;return n},h.prototype.readUIntBE=function(t,r,e){t|=0,r|=0,e||O(t,r,this.length);for(var n=this[t+--r],i=1;r>0&&(i*=256);)n+=this[t+--r]*i;return n},h.prototype.readUInt8=function(t,r){return r||O(t,1,this.length),this[t]},h.prototype.readUInt16LE=function(t,r){return r||O(t,2,this.length),this[t]|this[t+1]<<8},h.prototype.readUInt16BE=function(t,r){return r||O(t,2,this.length),this[t]<<8|this[t+1]},h.prototype.readUInt32LE=function(t,r){return r||O(t,4,this.length),(this[t]|this[t+1]<<8|this[t+2]<<16)+16777216*this[t+3]},h.prototype.readUInt32BE=function(t,r){return r||O(t,4,this.length),16777216*this[t]+(this[t+1]<<16|this[t+2]<<8|this[t+3])},h.prototype.readIntLE=function(t,r,e){t|=0,r|=0,e||O(t,r,this.length);for(var n=this[t],i=1,o=0;++o<r&&(i*=256);)n+=this[t+o]*i;return n>=(i*=128)&&(n-=Math.pow(2,8*r)),n},h.prototype.readIntBE=function(t,r,e){t|=0,r|=0,e||O(t,r,this.length);for(var n=r,i=1,o=this[t+--n];n>0&&(i*=256);)o+=this[t+--n]*i;return o>=(i*=128)&&(o-=Math.pow(2,8*r)),o},h.prototype.readInt8=function(t,r){return r||O(t,1,this.length),128&this[t]?-1*(255-this[t]+1):this[t]},h.prototype.readInt16LE=function(t,r){r||O(t,2,this.length);var e=this[t]|this[t+1]<<8;return 32768&e?4294901760|e:e},h.prototype.readInt16BE=function(t,r){r||O(t,2,this.length);var e=this[t+1]|this[t]<<8;return 32768&e?4294901760|e:e},h.prototype.readInt32LE=function(t,r){return r||O(t,4,this.length),this[t]|this[t+1]<<8|this[t+2]<<16|this[t+3]<<24},h.prototype.readInt32BE=function(t,r){return r||O(t,4,this.length),this[t]<<24|this[t+1]<<16|this[t+2]<<8|this[t+3]},h.prototype.readFloatLE=function(t,r){return r||O(t,4,this.length),i.read(this,t,!0,23,4)},h.prototype.readFloatBE=function(t,r){return r||O(t,4,this.length),i.read(this,t,!1,23,4)},h.prototype.readDoubleLE=function(t,r){return r||O(t,8,this.length),i.read(this,t,!0,52,8)},h.prototype.readDoubleBE=function(t,r){return r||O(t,8,this.length),i.read(this,t,!1,52,8)},h.prototype.writeUIntLE=function(t,r,e,n){(t=+t,r|=0,e|=0,n)||T(this,t,r,e,Math.pow(2,8*e)-1,0);var i=1,o=0;for(this[r]=255&t;++o<e&&(i*=256);)this[r+o]=t/i&255;return r+e},h.prototype.writeUIntBE=function(t,r,e,n){(t=+t,r|=0,e|=0,n)||T(this,t,r,e,Math.pow(2,8*e)-1,0);var i=e-1,o=1;for(this[r+i]=255&t;--i>=0&&(o*=256);)this[r+i]=t/o&255;return r+e},h.prototype.writeUInt8=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,1,255,0),h.TYPED_ARRAY_SUPPORT||(t=Math.floor(t)),this[r]=255&t,r+1},h.prototype.writeUInt16LE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,2,65535,0),h.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8):M(this,t,r,!0),r+2},h.prototype.writeUInt16BE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,2,65535,0),h.TYPED_ARRAY_SUPPORT?(this[r]=t>>>8,this[r+1]=255&t):M(this,t,r,!1),r+2},h.prototype.writeUInt32LE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,4,4294967295,0),h.TYPED_ARRAY_SUPPORT?(this[r+3]=t>>>24,this[r+2]=t>>>16,this[r+1]=t>>>8,this[r]=255&t):U(this,t,r,!0),r+4},h.prototype.writeUInt32BE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,4,4294967295,0),h.TYPED_ARRAY_SUPPORT?(this[r]=t>>>24,this[r+1]=t>>>16,this[r+2]=t>>>8,this[r+3]=255&t):U(this,t,r,!1),r+4},h.prototype.writeIntLE=function(t,r,e,n){if(t=+t,r|=0,!n){var i=Math.pow(2,8*e-1);T(this,t,r,e,i-1,-i)}var o=0,s=1,a=0;for(this[r]=255&t;++o<e&&(s*=256);)t<0&&0===a&&0!==this[r+o-1]&&(a=1),this[r+o]=(t/s>>0)-a&255;return r+e},h.prototype.writeIntBE=function(t,r,e,n){if(t=+t,r|=0,!n){var i=Math.pow(2,8*e-1);T(this,t,r,e,i-1,-i)}var o=e-1,s=1,a=0;for(this[r+o]=255&t;--o>=0&&(s*=256);)t<0&&0===a&&0!==this[r+o+1]&&(a=1),this[r+o]=(t/s>>0)-a&255;return r+e},h.prototype.writeInt8=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,1,127,-128),h.TYPED_ARRAY_SUPPORT||(t=Math.floor(t)),t<0&&(t=255+t+1),this[r]=255&t,r+1},h.prototype.writeInt16LE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,2,32767,-32768),h.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8):M(this,t,r,!0),r+2},h.prototype.writeInt16BE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,2,32767,-32768),h.TYPED_ARRAY_SUPPORT?(this[r]=t>>>8,this[r+1]=255&t):M(this,t,r,!1),r+2},h.prototype.writeInt32LE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,4,2147483647,-2147483648),h.TYPED_ARRAY_SUPPORT?(this[r]=255&t,this[r+1]=t>>>8,this[r+2]=t>>>16,this[r+3]=t>>>24):U(this,t,r,!0),r+4},h.prototype.writeInt32BE=function(t,r,e){return t=+t,r|=0,e||T(this,t,r,4,2147483647,-2147483648),t<0&&(t=4294967295+t+1),h.TYPED_ARRAY_SUPPORT?(this[r]=t>>>24,this[r+1]=t>>>16,this[r+2]=t>>>8,this[r+3]=255&t):U(this,t,r,!1),r+4},h.prototype.writeFloatLE=function(t,r,e){return N(this,t,r,!0,e)},h.prototype.writeFloatBE=function(t,r,e){return N(this,t,r,!1,e)},h.prototype.writeDoubleLE=function(t,r,e){return Y(this,t,r,!0,e)},h.prototype.writeDoubleBE=function(t,r,e){return Y(this,t,r,!1,e)},h.prototype.copy=function(t,r,e,n){if(e||(e=0),n||0===n||(n=this.length),r>=t.length&&(r=t.length),r||(r=0),n>0&&n<e&&(n=e),n===e)return 0;if(0===t.length||0===this.length)return 0;if(r<0)throw new RangeError("targetStart out of bounds");if(e<0||e>=this.length)throw new RangeError("sourceStart out of bounds");if(n<0)throw new RangeError("sourceEnd out of bounds");n>this.length&&(n=this.length),t.length-r<n-e&&(n=t.length-r+e);var i,o=n-e;if(this===t&&e<r&&r<n)for(i=o-1;i>=0;--i)t[i+r]=this[i+e];else if(o<1e3||!h.TYPED_ARRAY_SUPPORT)for(i=0;i<o;++i)t[i+r]=this[i+e];else Uint8Array.prototype.set.call(t,this.subarray(e,e+o),r);return o},h.prototype.fill=function(t,r,e,n){if("string"==typeof t){if("string"==typeof r?(n=r,r=0,e=this.length):"string"==typeof e&&(n=e,e=this.length),1===t.length){var i=t.charCodeAt(0);i<256&&(t=i)}if(void 0!==n&&"string"!=typeof n)throw new TypeError("encoding must be a string");if("string"==typeof n&&!h.isEncoding(n))throw new TypeError("Unknown encoding: "+n)}else"number"==typeof t&&(t&=255);if(r<0||this.length<r||this.length<e)throw new RangeError("Out of range index");if(e<=r)return this;var o;if(r>>>=0,e=void 0===e?this.length:e>>>0,t||(t=0),"number"==typeof t)for(o=r;o<e;++o)this[o]=t;else{var s=h.isBuffer(t)?t:C(new h(t,n).toString()),a=s.length;for(o=0;o<e-r;++o)this[o+r]=s[o%a]}return this};var L=/[^+\/0-9A-Za-z-_]/g;function j(t){return t<16?"0"+t.toString(16):t.toString(16)}function C(t,r){var e;r=r||1/0;for(var n=t.length,i=null,o=[],s=0;s<n;++s){if((e=t.charCodeAt(s))>55295&&e<57344){if(!i){if(e>56319){(r-=3)>-1&&o.push(239,191,189);continue}if(s+1===n){(r-=3)>-1&&o.push(239,191,189);continue}i=e;continue}if(e<56320){(r-=3)>-1&&o.push(239,191,189),i=e;continue}e=65536+(i-55296<<10|e-56320)}else i&&(r-=3)>-1&&o.push(239,191,189);if(i=null,e<128){if((r-=1)<0)break;o.push(e)}else if(e<2048){if((r-=2)<0)break;o.push(e>>6|192,63&e|128)}else if(e<65536){if((r-=3)<0)break;o.push(e>>12|224,e>>6&63|128,63&e|128)}else{if(!(e<1114112))throw new Error("Invalid code point");if((r-=4)<0)break;o.push(e>>18|240,e>>12&63|128,e>>6&63|128,63&e|128)}}return o}function J(t){return n.toByteArray(function(t){if((t=function(t){return t.trim?t.trim():t.replace(/^\s+|\s+$/g,"")}(t).replace(L,"")).length<2)return"";for(;t.length%4!=0;)t+="=";return t}(t))}function H(t,r,e,n){for(var i=0;i<n&&!(i+e>=r.length||i>=t.length);++i)r[i+e]=t[i];return i}}).call(r,e(9))},function(t,r,e){"use strict";const n=e(0),i=e(14),o=e(1);class s{static fetchParallel(t,r,e,i=[],o,a,h){const u=(t,r)=>t.concat(r);return n(r,r=>s.fetchAll(t,r,e,i,a,h),{concurrency:Math.max(o||r.length,1)}).then(t=>t.reduce(u,[]))}static async fetchAll(t,r,e,s=[],a=null,h,u,f=32,c=0){let l=[],d={},g={},p=Array.isArray(r)?{0:r.slice()}:{0:[r]};const y=(t,r)=>{g[t]||(p[r]||(p[r]=[]),p[r].includes(t)||p[r].push(t),g[t]=r)};s.forEach(t=>d[t.hash]=t);const w=r=>{const e=r;return!e||d[e]?Promise.resolve():new Promise((r,n)=>{u&&u(e,null,l.length,l,p),o.fromMultihash(t,e).then(t=>{if(o.isEntry(t))try{t.next.forEach(y),t.refs.forEach(y),l.push(t),d[e]=t,h&&h(e,t,l.length,l,p)}catch(t){console.error(t)}}).then(async t=>(c>0&&await((t=0)=>new Promise(r=>setTimeout(r,t)))(c),t)).then(r).catch(t=>{r()})})};let v=0;const m=async()=>{if(v<f){const t=((t=1)=>{return Object.values(p).reduce((r,e)=>{for(;e.length>0&&r.length<t;){const t=e.shift();r.push(t)}return r},[])})(f);v+=t.length,await n(t,w),v-=t.length}};return await i(async()=>await m(),()=>void 0!==Object.values(p).find(t=>t&&t.length>0)&&(l.length<e||e<0)),d={},g={},p=[],l}}t.exports=s},function(t,r,e){"use strict";t.exports={ImmutableDBNotDefinedError:()=>new Error("ImmutableDB instance not defined"),LogNotDefinedError:()=>new Error("Log instance not defined"),NotALogError:()=>new Error("Given argument is not an instance of Log")}},function(t,r,e){"use strict";t.exports=function(t,r){let e={};return t.forEach(t=>e[r?t[r]:t]=t),Object.keys(e).map(t=>e[t])}},function(t,r,e){"use strict";(function(r){const n=e(0),i=e(13),o=e(1),s=e(5),a=e(15),h=e(6),u=e(2),f=e(18),c=e(3),l=e(7),d=()=>(new Date).getTime().toString(),g=t=>t.hash,p=(t,r)=>t.concat(r),y=t=>t.next,w=t=>t.next[0],v=(t,r)=>Math.max(t,r.clock.time),m=(t,r)=>(t[r.hash]=r,t);class E extends i{constructor(t,r,e,n,i,o,s=[]){if(!c(t))throw h.ImmutableDBNotDefinedError();if(c(e)&&!Array.isArray(e))throw new Error("'entries' argument must be an array of Entry instances");if(c(n)&&!Array.isArray(n))throw new Error("'heads' argument must be an array");super(),this._storage=t,this._id=r||d(),this._keystore=this._storage.keystore,this._key=o,this._keys=Array.isArray(s)?s:[s],e=e||[],this._entryIndex=e.reduce(m,{}),n=n||E.findHeads(e),this._headsIndex=n.reduce(m,{}),this._nextsIndex={},e.forEach(t=>t.next.forEach(r=>this._nextsIndex[r]=t.hash)),this._length=e?e.length:0;const a=Math.max(i?i.time:0,this.heads.reduce(v,0)),f=o&&o.getPublic?o.getPublic("hex"):o||this._id;this._clock=new u(f,a)}get id(){return this._id}get clock(){return this._clock}get length(){return this._length}get values(){return Object.values(this._entryIndex).sort(o.compare)||[]}get heads(){return Object.values(this._headsIndex)||[]}get tails(){return E.findTails(this.values)}get tailHashes(){return E.findTailHashes(this.values)}get(t){return this._entryIndex[t]}has(t){return void 0!==this._entryIndex[t.hash||t]}traverse(t,r,e){let n=t.map(e).reduce(p,[]),i={},o={},s=0;const a=t=>{o[t]||i[t]||(n.push(t),i[t]=!0)};for(t.forEach(t=>{o[t.hash]=t,i[t.hash]=!0,s++});n.length>0&&s<r;){const t=n.shift(),r=this.get(t);r&&(s++,o[r.hash]=r,i[r.hash]=!0,r.next.forEach(a))}return n=[],i={},o}async append(t,r=1){if(this._key&&this._key.getPublic&&!this._keys.includes(this._key.getPublic("hex"))&&!this._keys.includes("*"))throw new Error("Not allowed to write");const e=Math.max(this.clock.time,this.heads.reduce(v,0))+1;this._clock=new u(this.clock.id,e);const n=Object.values(this.traverse(this.heads,this.heads.length,y)).sort((t,r)=>t.clock.time>r.clock.time).map(t=>t.hash),i=Object.values(this.traverse(this.heads,r,w)),s=(t=>{const r=new Set;for(let e=1;e<=t;e*=2){const t=Math.min(e-1,i.length-1),n=i[t];r.add(n)}})(Math.min(r,i.length));let a=new Set(s);i.length<r&&i[i.length-1]&&a.add(i[i.length-1]);n.forEach(t=>a.delete(t));const h=Array.from(a).map(g),f=await o.create(this._storage,this._keystore,this.id,t,n,this.clock,this._key,h);return this._entryIndex[f.hash]=f,n.forEach(t=>this._nextsIndex[t]=f.hash),this._headsIndex={},this._headsIndex[f.hash]=f,this._length++,f}async join(t,r=-1){if(!c(t))throw h.LogNotDefinedError();if(!E.isLog(t))throw h.NotALogError();const e=async t=>{this._keys.map(t=>t.getPublic?t.getPublic("hex"):t);return(await n(t,async t=>{if(!t.key)throw new Error("Entry doesn't have a public key");if(!t.sig)throw new Error("Entry doesn't have a signature");if(1===this._keys.length&&this._keys[0]===this._key&&t.id!==this.id)throw new Error("Entry doesn't belong in this log (wrong ID)");if(this._keys.length>0&&!this._keys.includes("*")&&!((t,r)=>t.find(t=>t===r.key))(this._keys.concat([this._key]),t))return console.warn("Warning: Input log contains entries that are not allowed in this log. Logs weren't joined."),!1;try{await o.verifyEntry(t,this._keystore)}catch(r){throw new Error(`Invalid signature in entry '${t.hash}'`)}return!0})).every(t=>!0===t)},i=((t,r)=>{let e=Object.keys(t._headsIndex),n={},i={};const o=t=>{n[t]||r.get(t)||(e.push(t),n[t]=!0)};for(;e.length>0;){const s=e.shift(),a=t.get(s);a&&!r.get(s)&&a.id===this.id&&(i[a.hash]=a,n[a.hash]=!0,a.next.forEach(o))}return i})(t,this);if(this._key&&this._key.getPublic){if(!await e(Object.values(i)))return this}this._entryIndex=Object.assign(this._entryIndex,i);if(Object.values(i).forEach(t=>t.next.forEach(r=>this._nextsIndex[r]=t.hash)),this._length+=Object.values(i).length,r>-1){let t=this.values;t=t.slice(-r),this._entryIndex=t.reduce(m,{}),this._length=Object.values(this._entryIndex).length}const s=Object.values(i).map(y).reduce(p,[]),a=E.findHeads(Object.values(Object.assign({},this._headsIndex,t._headsIndex))).filter(t=>!s.find(r=>r===t.hash)).filter(t=>!this._nextsIndex[t.hash]).reduce(m,{});this._headsIndex=a;const f=Object.values(this._headsIndex).reduce(v,0);return this._clock=new u(this.clock.id,Math.max(this.clock.time,f)),this}toJSON(){return{id:this.id,heads:this.heads.map(g)}}toSnapshot(){return{id:this.id,heads:this.heads,values:this.values}}toBuffer(){return r.from(JSON.stringify(this.toJSON()))}toString(t){return this.values.slice().reverse().map((r,e)=>{const n=o.findChildren(r,this.values).length;let i=new Array(Math.max(n-1,0));return i=n>1?i.fill("  "):i,(i=n>0?i.concat(["└─"]):i).join("")+(t?t(r.payload):r.payload)}).join("\n")}static isLog(t){return void 0!==t.id&&void 0!==t.heads&&void 0!==t._entryIndex}toMultihash(){return a.toMultihash(this._storage,this)}static fromMultihash(t,r,e=-1,n,i,o){if(!c(t))throw h.ImmutableDBNotDefinedError();if(!c(r))throw new Error(`Invalid hash: ${r}`);return a.fromMultihash(t,r,e,n,o).then(r=>new E(t,r.id,r.values,r.heads,r.clock,i))}static fromEntryHash(t,r,e,n=-1,i,o,s,u){if(!c(t))throw h.ImmutableDBNotDefinedError();if(!c(r))throw new Error("'hash' must be defined");return a.fromEntryHash(t,r,e,n,i,u).then(r=>new E(t,e,r.values,null,null,o,s))}static fromJSON(t,r,e=-1,n,i,o,s){if(!c(t))throw h.ImmutableDBNotDefinedError();return a.fromJSON(t,r,e,n,o,s).then(r=>new E(t,r.id,r.values,null,null,n,i))}static fromEntry(t,r,e=-1,n,i){if(!c(t))throw h.ImmutableDBNotDefinedError();if(!c(r))throw new Error("'sourceEntries' must be defined");return a.fromEntry(t,r,e,n,i).then(r=>new E(t,r.id,r.values))}static findHeads(t){var r=t.reduce((t,r,e,n)=>{return r.next.forEach(e=>t[e]=r.hash),t},{});return t.filter(t=>void 0===r[t.hash]).sort((t,r)=>t.clock.id>r.clock.id)}static findTails(t){var r={},e=[],n={},i=[];t.forEach(t=>{0===t.next.length&&e.push(t);t.next.forEach(e=>{r[e]||(r[e]=[]),r[e].push(t)}),i=i.concat(t.next),n[t.hash]=!0});const s=i.filter(t=>void 0===n[t]).map(t=>r[t]).reduce((t,r,e,n)=>t.concat(l(r,"hash")),[]).concat(e);return l(s,"hash").sort(o.compare)}static findTailHashes(t){var r={};return t.forEach(t=>r[t.hash]=!0),t.reduce((t,e,n,i)=>{return e.next.reverse().forEach(e=>{void 0===r[e]&&t.splice(0,0,e)}),t},[])}static get MemStore(){return f}static get EntryIO(){return s}}t.exports=E}).call(r,e(4).Buffer)},function(t,r){var e;e=function(){return this}();try{e=e||Function("return this")()||(0,eval)("this")}catch(t){"object"==typeof window&&(e=window)}t.exports=e},function(t,r,e){"use strict";r.byteLength=function(t){var r=u(t),e=r[0],n=r[1];return 3*(e+n)/4-n},r.toByteArray=function(t){for(var r,e=u(t),n=e[0],s=e[1],a=new o(function(t,r,e){return 3*(r+e)/4-e}(0,n,s)),h=0,f=s>0?n-4:n,c=0;c<f;c+=4)r=i[t.charCodeAt(c)]<<18|i[t.charCodeAt(c+1)]<<12|i[t.charCodeAt(c+2)]<<6|i[t.charCodeAt(c+3)],a[h++]=r>>16&255,a[h++]=r>>8&255,a[h++]=255&r;2===s&&(r=i[t.charCodeAt(c)]<<2|i[t.charCodeAt(c+1)]>>4,a[h++]=255&r);1===s&&(r=i[t.charCodeAt(c)]<<10|i[t.charCodeAt(c+1)]<<4|i[t.charCodeAt(c+2)]>>2,a[h++]=r>>8&255,a[h++]=255&r);return a},r.fromByteArray=function(t){for(var r,e=t.length,i=e%3,o=[],s=0,a=e-i;s<a;s+=16383)o.push(c(t,s,s+16383>a?a:s+16383));1===i?(r=t[e-1],o.push(n[r>>2]+n[r<<4&63]+"==")):2===i&&(r=(t[e-2]<<8)+t[e-1],o.push(n[r>>10]+n[r>>4&63]+n[r<<2&63]+"="));return o.join("")};for(var n=[],i=[],o="undefined"!=typeof Uint8Array?Uint8Array:Array,s="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",a=0,h=s.length;a<h;++a)n[a]=s[a],i[s.charCodeAt(a)]=a;function u(t){var r=t.length;if(r%4>0)throw new Error("Invalid string. Length must be a multiple of 4");var e=t.indexOf("=");return-1===e&&(e=r),[e,e===r?0:4-e%4]}function f(t){return n[t>>18&63]+n[t>>12&63]+n[t>>6&63]+n[63&t]}function c(t,r,e){for(var n,i=[],o=r;o<e;o+=3)n=(t[o]<<16&16711680)+(t[o+1]<<8&65280)+(255&t[o+2]),i.push(f(n));return i.join("")}i["-".charCodeAt(0)]=62,i["_".charCodeAt(0)]=63},function(t,r){r.read=function(t,r,e,n,i){var o,s,a=8*i-n-1,h=(1<<a)-1,u=h>>1,f=-7,c=e?i-1:0,l=e?-1:1,d=t[r+c];for(c+=l,o=d&(1<<-f)-1,d>>=-f,f+=a;f>0;o=256*o+t[r+c],c+=l,f-=8);for(s=o&(1<<-f)-1,o>>=-f,f+=n;f>0;s=256*s+t[r+c],c+=l,f-=8);if(0===o)o=1-u;else{if(o===h)return s?NaN:1/0*(d?-1:1);s+=Math.pow(2,n),o-=u}return(d?-1:1)*s*Math.pow(2,o-n)},r.write=function(t,r,e,n,i,o){var s,a,h,u=8*o-i-1,f=(1<<u)-1,c=f>>1,l=23===i?Math.pow(2,-24)-Math.pow(2,-77):0,d=n?0:o-1,g=n?1:-1,p=r<0||0===r&&1/r<0?1:0;for(r=Math.abs(r),isNaN(r)||r===1/0?(a=isNaN(r)?1:0,s=f):(s=Math.floor(Math.log(r)/Math.LN2),r*(h=Math.pow(2,-s))<1&&(s--,h*=2),(r+=s+c>=1?l/h:l*Math.pow(2,1-c))*h>=2&&(s++,h/=2),s+c>=f?(a=0,s=f):s+c>=1?(a=(r*h-1)*Math.pow(2,i),s+=c):(a=r*Math.pow(2,c-1)*Math.pow(2,i),s=0));i>=8;t[e+d]=255&a,d+=g,a/=256,i-=8);for(s=s<<i|a,u+=i;u>0;t[e+d]=255&s,d+=g,s/=256,u-=8);t[e+d-g]|=128*p}},function(t,r){var e={}.toString;t.exports=Array.isArray||function(t){return"[object Array]"==e.call(t)}},function(t,r,e){"use strict";t.exports=class{constuctor(t){}append(t){}merge(t){}get(t){}has(t){}get values(){}get length(){}}},function(t,r,e){"use strict";const n=t=>new Promise(r=>{r(t())});t.exports=((t,r)=>n(function e(){return n(t).then(t=>{if(r(t))return e()})}))},function(t,r,e){"use strict";e(0);const n=e(1),i=e(5),o=e(2),s=e(6),a=e(3),h=e(7),u=(e(16),e(17)),f=(t,r)=>t.slice(t.length-r,t.length),c=(t,r)=>(t[r.hash]=r,t);t.exports=class{static toMultihash(t,r){if(!a(t))throw s.ImmutableDBNotDefinedError();if(!a(r))throw s.LogNotDefinedError();if(r.values.length<1)throw new Error("Can't serialize an empty log");return t.object.put(r.toBuffer()).then(t=>t.toJSON().multihash)}static async fromMultihash(t,r,e=-1,h,u){if(!a(t))throw s.ImmutableDBNotDefinedError();if(!a(r))throw new Error(`Invalid hash: ${r}`);const l=await t.object.get(r,{enc:"base58"}),d=JSON.parse(l.toJSON().data);if(!d.heads||!d.id)throw s.NotALogError();const g=await i.fetchParallel(t,d.heads,e,h,null,null,u),p=Object.values(g.reduce(c,{})),y=p.reduce((t,r)=>r.clock.time>t.time?new o(r.clock.id,r.clock.time):t,new o(d.id)),w=e>-1?f(p.sort(n.compare),e):p,v=w.filter(t=>d.heads.includes(t.hash));return{id:d.id,values:w,heads:v,clock:y}}static fromEntryHash(t,r,e,n=-1,o,h){if(!a(t))throw s.IpfsNotDefinedError();if(!a(r))throw new Error("'entryHash' must be defined");n=n>-1?Math.max(n,1):n;const u=o;return i.fetchParallel(t,[r],n,u,null,null,h).then(t=>({values:n>-1?f(t,n):t}))}static fromJSON(t,r,e=-1,o,h,u){if(!a(t))throw s.ImmutableDBNotDefinedError();return i.fetchParallel(t,r.heads.map(t=>t.hash),e,[],16,h,u).then(t=>{const e=t.slice().sort(n.compare);return t.filter(t=>r.heads.includes(t.hash)),{id:r.id,values:e,heads:r.heads}})}static fromEntry(t,r,e=-1,o,f,c,l){if(!a(t))throw s.ImmutableDBNotDefinedError();if(!a(r))throw new Error("'sourceEntries' must be defined");if(!Array.isArray(r)&&!n.isEntry(r))throw new Error("'sourceEntries' argument must be an array of Entry instances or a single Entry");Array.isArray(r)||(r=[r]),e=e>-1?Math.max(e,r.length):e;const d=o?o.map(t=>t.hash?t.hash:t):o,g=r.map(t=>t.hash);return i.fetchParallel(t,g,e,d,null,null,l).then(t=>{var i=r.concat(t),o=h(i,"hash").sort(n.compare);const s=o.slice(e>-1?-e:-o.length),a=((t,r)=>{var e=t.slice(r.length,t.length);return r.concat(e)})(s,u(s,r,"hash"));return{id:a[a.length-1].id,values:a}})}}},function(t,r,e){"use strict";t.exports=function(t,r,e){var n={},i={};return t.forEach(t=>i[e?t[e]:t]=!0),r.reduce((t,r)=>{var o=void 0!==i[e?r[e]:r],s=void 0!==n[e?r[e]:r];return o&&!s&&(t.push(r),n[e?r[e]:r]=!0),t},[])}},function(t,r,e){"use strict";t.exports=function(t,r,e){var n={},i={};return t.forEach(t=>i[e?t[e]:t]=!0),r.reduce((t,r)=>{var o=void 0!==i[e?r[e]:r],s=void 0!==n[e?r[e]:r];return o||s||(t.push(r),n[e?r[e]:r]=!0),t},[])}},function(t,r,e){"use strict";t.exports=class{constructor(){this._store={}}async put(t){const r="MEM"+(1e8*Math.random()).toString();return this._store||(this._store={}),this._store[r]=t,Promise.resolve({toJSON:()=>({data:t,multihash:r})})}async get(t){return Promise.resolve({toJSON:()=>({data:this._store[t],multihash:t})})}}}]);
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/browser/loader-visualization.html
+++ /dev/null
@@ -1,298 +0,0 @@
-<html>
-  <head>
-    <meta charset="utf-8">
-    <link href="https://fonts.googleapis.com/css?family=Tajawal" rel="stylesheet">
-
-    <style type="text/css">
-      body {
-        font-family: 'Tajawal', sans-serif;
-        margin: 0;
-        padding: 0em 4em;
-        line-height: 1.1;
-      }
-
-      h1 {
-        font-size: 3em;
-        text-transform: uppercase;
-        margin: 0;
-      }
-
-      h2 {
-        font-size: 1em;
-        text-transform: uppercase;
-        margin: 0;
-        color: rgba(0, 0, 0, 0.5);
-      }
-
-      span {
-        font-size: 0.7em;
-      }
-
-      #parameters {
-        margin: 2em 0em;
-        margin-top: 0.75em;
-      }
-
-      #output-load, #output-create {
-        margin: 0;
-      }
-
-      #log {
-        margin: 2em 0em;
-      }
-
-      #output-create {
-        padding-top: 0.25em;
-      }
-
-      #startButton {
-        margin: 0em 1em;
-        font-weight: 700;
-        padding: 0.25em 2em;
-      }
-    </style>
-  </head>
-  <body>
-    <div id="parameters">
-      <span>Log Length</span>
-      <input type="text" name="" id="countInput" value="100">
-      <span>References Depth</span>
-      <input type="text" name="" id="refCountInput" value="32">
-      <span>Parallelism</span>
-      <input type="text" name="" id="concurrencyInput" value="64">
-      <span>Latency (ms)</span>
-      <input type="text" name="" id="delayInput" value="0">
-      <span>In-Memory</span>
-      <input type="checkbox" name="" id="useMemStoreInput" checked>
-      <button id="startButton">Load!</button>
-    </div>
-    <h1>ipfs-log</h1>
-    <h2>loading simulation</h2>
-    <a href="https://github.com/orbitdb/ipfs-log">https://github.com/orbitdb/ipfs-log</a>
-    <div id="log">
-      <svg id="log-svg" width=10000 height=4 shape-rendering="optimizeSpeed">
-        <rect id="totalPercentage"></rect>
-        <rect id="createProgressPercentage"></rect>
-        <rect id="loadProgressPercentage"></rect>
-      </svg>
-    </div>
-    <pre id="output-create"></pre>
-    <pre id="output-load"></pre>
-    <script type="text/javascript" src="lib/ipfslog.min.js" charset="utf-8"></script>
-    <script type="text/javascript" src="lib/ipfs/index.min.js" charset="utf-8"></script>
-    <script src="https://d3js.org/d3.v4.min.js"></script>
-
-    <script>
-      const outputLoadingElm = document.getElementById('output-load')
-      const outputElm = document.getElementById('output-create')
-      const logElm = document.getElementById('log')
-      /* Adjustable parameters */
-      const startButtonElm = document.getElementById('startButton')
-      const concurrencyElm = document.getElementById('concurrencyInput')
-      const countElm = document.getElementById('countInput')
-      const refCountElm = document.getElementById('refCountInput')
-      const delayElm = document.getElementById('delayInput')
-      const useMemStoreElm = document.getElementById('useMemStoreInput')
-      let concurrency = parseInt(concurrencyElm.value)
-      let count = parseInt(countElm.value)
-      let refCount = parseInt(refCountElm.value)
-      let delay = parseInt(delayElm.value)
-
-      const EntryIO = Log.EntryIO
-
-      const MemStore = Log.MemStore
-      let _ipfsObjectPut, _ipfsObjectGet
-
-      const ipfs = new Ipfs({
-        repo: './ipfs-log/examples/browser/loader-viz',
-        start: false,
-        EXPERIMENTAL: {
-          pubsub: true
-        },
-      })
-
-      ipfs.on('error', (e) => console.error(e))
-
-      ipfs.on('ready', async () => {
-        run()
-      })
-
-      let log
-
-      const sleep = (ms = 1000) => new Promise(resolve => setTimeout(resolve, ms))
-
-      const initMemStore = () => {
-        const memstore = new MemStore(ipfs)
-        if (!_ipfsObjectGet && !_ipfsObjectPut) {
-          _ipfsObjectGet = ipfs.object.get.bind(ipfs)
-          _ipfsObjectPut = ipfs.object.put.bind(ipfs)
-        }
-        ipfs.object.put = memstore.put.bind(memstore)
-        ipfs.object.get = memstore.get.bind(memstore)
-      }
-
-      const resetMemStore = () => {
-        if (_ipfsObjectGet && _ipfsObjectPut) {
-          ipfs.object.put = _ipfsObjectPut
-          ipfs.object.get = _ipfsObjectGet
-        }
-        _ipfsObjectGet = null
-        _ipfsObjectPut = null
-      }
-
-      const run = async () => {
-        const useMemStore = useMemStoreElm.checked
-        if (useMemStore) {
-          initMemStore()
-        } else {
-          resetMemStore()
-        }
-
-        startButtonElm.removeEventListener('click', run)
-        startButtonElm.disabled = true
-        await resetRendering()
-
-        concurrency = parseInt(concurrencyElm.value)
-        count = parseInt(countElm.value)
-        refCount = parseInt(refCountElm.value)
-        delay = parseInt(delayElm.value)
-
-        outputElm.innerHTML = `Creating a log... 0 / ${count}<br>`
-        outputLoadingElm.innerHTML = ""
-        await sleep(100)
-
-        window.onLogCreationStarted()
-
-        const st = new Date().getTime()
-        log = new Log(ipfs, 'X')
-
-        for (let i = 1; i < count + 1; i ++) {
-          const hash = await log.append('hello' + i, refCount)
-          if (i % 10 === 0) {
-            await onLogCreateUpdated(log, i, hash)
-            // if (delay > 0)
-            //   await sleep(1)
-          }
-        }
-
-        const lt2 = new Date().getTime()
-        setTimeout(() => {
-          // outputElm.innerHTML += "Creating took: " + (lt2 - st) + " ms"
-          outputElm.innerHTML = `Creating a log... ${count} / ${count} (${(lt2 - st)} ms)`
-        }, 100)
-        // outputLoadingElm.innerHTML += "Creating took: " + (lt2 - st) + " ms"
-
-        // outputLoadingElm.innerHTML = "Loading a log..."
-        window.onLogCreated()
-        const lt1 = new Date().getTime()
-        const result = await EntryIO.fetchAll(
-          ipfs, 
-          log.heads.map(e => e.hash), 
-          -1, 
-          [], 
-          20000, 
-          window.onDataUpdated, 
-          null,
-          concurrency,
-          delay
-        )
-        const et = new Date().getTime()
-        setTimeout(() => {
-          outputLoadingElm.innerHTML = "Loading a log...  " + result.length + " / " + log.length + " (" + (et - lt1) + " ms)<br>"
-          // outputLoadingElm.innerHTML += "<br>Loading took: " + (et - lt1) + " ms<br>"
-          outputLoadingElm.innerHTML += "Duration: " + (et - st) + " ms<br>"
-          startButtonElm.addEventListener('click', run)
-          startButtonElm.disabled = false
-        }, 100)
-      }
-
-      /* Rendering */
-
-      let sizeY = 6
-      let sizeX = logElm.clientWidth / count
-      const margin = 0
-
-      let svgContainer
-
-      const resetRendering = async () => {
-        const w = logElm.clientWidth
-        svgContainer = d3.select("#log-svg")
-          .attr("width", w)
-          .attr("height", sizeY)
-
-        svgContainer.select("#totalPercentage")
-          .attr("height", sizeY)
-          .attr("width", w)
-          .style("fill", "rgb(228, 228, 228)")
-
-        svgContainer.select("#createProgressPercentage")
-          .attr("width", 0)
-        svgContainer.select("#loadProgressPercentage")
-          .attr("width", 0)
-
-        return new Promise((resolve) => {
-          setTimeout(() => resolve(), 0)
-        })
-      }
-
-      window.onresize = (event) => {
-        sizeX = logElm.clientWidth / count
-      }
-
-      let _renderIndex = {}
-      let circleElements = []
-      let d = new Array(count)
-
-      let loadProgressRenderInterval
-      let createProgressRenderInterval
-
-      let logLength = 0
-      window.onLogCreateUpdated = (log, progress, entry) => {
-        logLength = progress
-        return new Promise((resolve) => {
-          setTimeout(() => resolve(), 0)
-        })
-      }
-
-      window.onLogCreationStarted = () => {
-        createProgressRenderInterval = setInterval(() => {
-            outputElm.innerHTML = "Creating a log... " + logLength + " / " + count + "<br>"
-
-            svgContainer.select("#createProgressPercentage")
-              .attr("height", sizeY)
-              .attr("width", (logLength / (count / logElm.clientWidth)))
-              .style("fill", "rgba(112, 164, 112)")
-
-            if (logLength === count) {
-              clearInterval(createProgressRenderInterval)
-              return
-            }
-        }, 100)
-      }
-
-      let loadLength = 0
-      window.onDataUpdated = (hash, entry, resultLength, result, queue) => {
-        loadLength = resultLength
-        return new Promise((resolve) => {
-          setTimeout(() => resolve(), 0)
-        })
-      }
-
-      window.onLogCreated = () => {
-        loadProgressRenderInterval = setInterval(() => {
-          outputLoadingElm.innerHTML = "Loading a log...  " + loadLength + " / " + count
-
-          svgContainer.select("#loadProgressPercentage")
-            .attr("height", sizeY)
-            .attr("width", (loadLength / (count / logElm.clientWidth)))
-            .style("fill", "rgb(112, 228, 112)")
-
-          if (loadLength === count) {
-            clearInterval(loadProgressRenderInterval)
-            return
-          }
-        }, 100)
-      }
-    </script>
-  </body>
-</html>
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/examples/log.js
+++ /dev/null
@@ -1,54 +0,0 @@
-'use strict'
-
-const IPFS = require('ipfs')
-const Log = require('../src/log')
-const Keystore = require('orbit-db-keystore')
-
-const dataPath = './ipfs/examples/log'
-
-const ipfs = new IPFS({
-  repo: dataPath + '/ipfs',
-  start: false,
-  EXPERIMENTAL: {
-    pubsub: true
-  },
-})
-
-ipfs.on('error', (err) => console.error(err))
-ipfs.on('ready', async () => {
-  const keystore = new Keystore(dataPath + '/keystore')
-  ipfs.keystore = keystore
-
-  let key1, key2, key3
-  try {
-    key1 = keystore.getKey('A') || keystore.createKey('A')
-    key2 = keystore.getKey('C') || keystore.createKey('C')
-  } catch (e) {
-    console.error(e)
-  }
-
-  let log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-  let log2 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-  let log3 = new Log(ipfs, 'A', null, null, null, key2, [key1.getPublic('hex'), key2.getPublic('hex')])
-
-  try {
-    await log1.append('one')
-    await log1.append('two')
-    await log2.append('three')
-    // Join the logs
-    await log3.join(log1)
-    await log3.join(log2)
-    // Add one more
-    await log3.append('four')
-    console.log(log3.values)
-  } catch (e) {
-    console.error(e)
-    process.exit(1)
-  }
-  console.log(log3.toString())
-  // four
-  // └─two
-  //   └─one
-  // └─three
-  process.exit(0)
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/entry-io.js
+++ /dev/null
@@ -1,309 +0,0 @@
-'use strict';
-
-var _regenerator = require('babel-runtime/regenerator');
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _promise = require('babel-runtime/core-js/promise');
-
-var _promise2 = _interopRequireDefault(_promise);
-
-var _values = require('babel-runtime/core-js/object/values');
-
-var _values2 = _interopRequireDefault(_values);
-
-var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var pMap = require('p-map');
-var pDoWhilst = require('p-do-whilst');
-var Entry = require('./entry');
-
-var EntryIO = function () {
-  function EntryIO() {
-    (0, _classCallCheck3.default)(this, EntryIO);
-  }
-
-  (0, _createClass3.default)(EntryIO, null, [{
-    key: 'fetchParallel',
-
-    // Fetch log graphs in parallel
-    value: function fetchParallel(ipfs, hashes, length) {
-      var exclude = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [];
-      var concurrency = arguments[4];
-      var timeout = arguments[5];
-      var onProgressCallback = arguments[6];
-
-      var fetchOne = function fetchOne(hash) {
-        return EntryIO.fetchAll(ipfs, hash, length, exclude, timeout, onProgressCallback);
-      };
-      var concatArrays = function concatArrays(arr1, arr2) {
-        return arr1.concat(arr2);
-      };
-      var flatten = function flatten(arr) {
-        return arr.reduce(concatArrays, []);
-      };
-      return pMap(hashes, fetchOne, { concurrency: Math.max(concurrency || hashes.length, 1) }).then(flatten // Flatten the results
-      );
-    }
-
-    /**
-     * Fetch log entries sequentially
-     *
-     * @param {IPFS} [ipfs] An IPFS instance
-     * @param {string} [hash] Multihash of the entry to fetch
-     * @param {string} [parent] Parent of the node to be fetched
-     * @param {Object} [all] Entries to skip
-     * @param {Number} [amount=-1] How many entries to fetch
-     * @param {Number} [depth=0] Current depth of the recursion
-     * @param {function(hash, entry, parent, depth)} onProgressCallback
-     * @returns {Promise<Array<Entry>>}
-     */
-
-  }, {
-    key: 'fetchAll',
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee4(ipfs, hashes, amount) {
-        var exclude = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [];
-        var timeout = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;
-        var onProgressCallback = arguments[5];
-        var onStartProgressCallback = arguments[6];
-
-        var _this = this;
-
-        var concurrency = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 32;
-        var delay = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : 0;
-
-        var result, cache, loadingCache, loadingQueue, addToLoadingQueue, addToExcludeCache, loadingQueueHasMore, shouldFetchMore, getNextFromQueue, fetchEntry, running, _processQueue;
-
-        return _regenerator2.default.wrap(function _callee4$(_context4) {
-          while (1) {
-            switch (_context4.prev = _context4.next) {
-              case 0:
-                result = [];
-                cache = {};
-                loadingCache = {};
-                loadingQueue = Array.isArray(hashes) ? { 0: hashes.slice() } : { 0: [hashes]
-
-                  // Add a multihash to the loading queue
-                };
-
-                addToLoadingQueue = function addToLoadingQueue(e, idx) {
-                  if (!loadingCache[e]) {
-                    if (!loadingQueue[idx]) loadingQueue[idx] = [];
-                    if (!loadingQueue[idx].includes(e)) {
-                      loadingQueue[idx].push(e);
-                    }
-                    loadingCache[e] = idx;
-                  }
-                };
-
-                // Add entries that we don't need to fetch to the "cache"
-
-
-                addToExcludeCache = function addToExcludeCache(e) {
-                  return cache[e.hash] = e;
-                };
-
-                exclude.forEach(addToExcludeCache);
-
-                loadingQueueHasMore = function loadingQueueHasMore() {
-                  return (0, _values2.default)(loadingQueue).find(function (e) {
-                    return e && e.length > 0;
-                  }) !== undefined;
-                };
-
-                shouldFetchMore = function shouldFetchMore() {
-                  return loadingQueueHasMore() && (result.length < amount || amount < 0);
-                };
-
-                getNextFromQueue = function getNextFromQueue() {
-                  var length = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;
-
-                  var all = (0, _values2.default)(loadingQueue).reduce(function (res, acc) {
-                    while (acc.length > 0 && res.length < length) {
-                      var e = acc.shift();
-                      res.push(e);
-                    }
-                    return res;
-                  }, []);
-                  return all;
-                };
-
-                fetchEntry = function fetchEntry(entryHash) {
-                  var hash = entryHash;
-
-                  if (!hash || cache[hash]) {
-                    return _promise2.default.resolve();
-                  }
-
-                  return new _promise2.default(function (resolve, reject) {
-                    // Resolve the promise after a timeout (if given) in order to
-                    // not get stuck loading a block that is unreachable
-                    // const timer = timeout 
-                    // ? setTimeout(() => {
-                    //     console.warn(`Warning: Couldn't fetch entry '${hash}', request timed out (${timeout}ms)`)
-                    //     resolve()
-                    //   } , timeout) 
-                    // : null
-
-                    var sleep = function sleep() {
-                      var ms = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
-                      return new _promise2.default(function (resolve) {
-                        return setTimeout(resolve, ms);
-                      });
-                    };
-
-                    var addToResults = function addToResults(entry) {
-                      // clearTimeout(timer)
-                      if (Entry.isEntry(entry)) {
-                        try {
-                          entry.next.forEach(addToLoadingQueue);
-                          entry.refs.forEach(addToLoadingQueue);
-
-                          result.push(entry);
-                          cache[hash] = entry;
-                          if (onProgressCallback) {
-                            onProgressCallback(hash, entry, result.length, result, loadingQueue);
-                          }
-                        } catch (e) {
-                          console.error(e);
-                        }
-                      }
-                    };
-
-                    if (onStartProgressCallback) {
-                      onStartProgressCallback(hash, null, result.length, result, loadingQueue);
-                    }
-
-                    // Load the entry
-                    Entry.fromMultihash(ipfs, hash).then(addToResults).then(function () {
-                      var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(entry) {
-                        return _regenerator2.default.wrap(function _callee$(_context) {
-                          while (1) {
-                            switch (_context.prev = _context.next) {
-                              case 0:
-                                if (!(delay > 0)) {
-                                  _context.next = 3;
-                                  break;
-                                }
-
-                                _context.next = 3;
-                                return sleep(delay);
-
-                              case 3:
-                                return _context.abrupt('return', entry);
-
-                              case 4:
-                              case 'end':
-                                return _context.stop();
-                            }
-                          }
-                        }, _callee, _this);
-                      }));
-
-                      return function (_x11) {
-                        return _ref2.apply(this, arguments);
-                      };
-                    }()).then(resolve).catch(function (err) {
-                      resolve();
-                    });
-                  });
-                };
-
-                running = 0;
-
-                _processQueue = function () {
-                  var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2() {
-                    var nexts;
-                    return _regenerator2.default.wrap(function _callee2$(_context2) {
-                      while (1) {
-                        switch (_context2.prev = _context2.next) {
-                          case 0:
-                            if (!(running < concurrency)) {
-                              _context2.next = 6;
-                              break;
-                            }
-
-                            nexts = getNextFromQueue(concurrency);
-
-                            running += nexts.length;
-                            _context2.next = 5;
-                            return pMap(nexts, fetchEntry);
-
-                          case 5:
-                            running -= nexts.length;
-
-                          case 6:
-                          case 'end':
-                            return _context2.stop();
-                        }
-                      }
-                    }, _callee2, _this);
-                  }));
-
-                  return function _processQueue() {
-                    return _ref3.apply(this, arguments);
-                  };
-                }();
-
-                _context4.next = 15;
-                return pDoWhilst((0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3() {
-                  return _regenerator2.default.wrap(function _callee3$(_context3) {
-                    while (1) {
-                      switch (_context3.prev = _context3.next) {
-                        case 0:
-                          _context3.next = 2;
-                          return _processQueue();
-
-                        case 2:
-                          return _context3.abrupt('return', _context3.sent);
-
-                        case 3:
-                        case 'end':
-                          return _context3.stop();
-                      }
-                    }
-                  }, _callee3, _this);
-                })), shouldFetchMore
-
-                // Free memory to avoid minor GC
-                );
-
-              case 15:
-                cache = {};
-                loadingCache = {};
-                loadingQueue = [];
-
-                return _context4.abrupt('return', result);
-
-              case 19:
-              case 'end':
-                return _context4.stop();
-            }
-          }
-        }, _callee4, this);
-      }));
-
-      function fetchAll(_x6, _x7, _x8) {
-        return _ref.apply(this, arguments);
-      }
-
-      return fetchAll;
-    }()
-  }]);
-  return EntryIO;
-}();
-
-module.exports = EntryIO;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/entry.js
+++ /dev/null
@@ -1,366 +0,0 @@
-'use strict';
-
-var _assign = require('babel-runtime/core-js/object/assign');
-
-var _assign2 = _interopRequireDefault(_assign);
-
-var _stringify = require('babel-runtime/core-js/json/stringify');
-
-var _stringify2 = _interopRequireDefault(_stringify);
-
-var _regenerator = require('babel-runtime/regenerator');
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var Clock = require('./lamport-clock');
-var isDefined = require('./utils/is-defined');
-
-var IpfsNotDefinedError = function IpfsNotDefinedError() {
-  return new Error('Ipfs instance not defined');
-};
-
-var Entry = function () {
-  function Entry() {
-    (0, _classCallCheck3.default)(this, Entry);
-  }
-
-  (0, _createClass3.default)(Entry, null, [{
-    key: 'create',
-
-    /**
-     * Create an Entry
-     * @param {IPFS} ipfs - An IPFS instance
-     * @param {string|Buffer|Object|Array} data - Data of the entry to be added. Can be any JSON.stringifyable data.
-     * @param {Array<Entry|string>} [next=[]] Parents of the entry
-     * @example
-     * const entry = await Entry.create(ipfs, 'hello')
-     * console.log(entry)
-     * // { hash: "Qm...Foo", payload: "hello", next: [] }
-     * @returns {Promise<Entry>}
-     */
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(ipfs, keystore, id, data) {
-        var next = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [];
-        var clock = arguments[5];
-        var signKey = arguments[6];
-        var refs = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : [];
-        var toEntry, nexts, clockId, clockTime, entry;
-        return _regenerator2.default.wrap(function _callee$(_context) {
-          while (1) {
-            switch (_context.prev = _context.next) {
-              case 0:
-                if (isDefined(ipfs)) {
-                  _context.next = 2;
-                  break;
-                }
-
-                throw IpfsNotDefinedError();
-
-              case 2:
-                if (isDefined(id)) {
-                  _context.next = 4;
-                  break;
-                }
-
-                throw new Error('Entry requires an id');
-
-              case 4:
-                if (isDefined(data)) {
-                  _context.next = 6;
-                  break;
-                }
-
-                throw new Error('Entry requires data');
-
-              case 6:
-                if (!(!isDefined(next) || !Array.isArray(next))) {
-                  _context.next = 8;
-                  break;
-                }
-
-                throw new Error("'next' argument is not an array");
-
-              case 8:
-
-                // Clean the next objects and convert to hashes
-                toEntry = function toEntry(e) {
-                  return e.hash ? e.hash : e;
-                };
-
-                nexts = next.filter(isDefined).map(toEntry
-
-                // Take the id of the given clock by default,
-                // if clock not given, take the signing key if it's a Key instance,
-                // or if none given, take the id as the clock id
-                );
-                clockId = clock ? clock.id : signKey ? signKey.getPublic('hex') : id;
-                clockTime = clock ? clock.time : null;
-                entry = {
-                  hash: null, // "Qm...Foo", we'll set the hash after persisting the entry
-                  id: id, // For determining a unique chain
-                  payload: data, // Can be any JSON.stringifyable data
-                  next: nexts, // Array of Multihashes
-                  refs: refs,
-                  v: 0, // For future data structure updates, should currently always be 0
-                  clock: new Clock(clockId, clockTime)
-
-                  // If signing key was passedd, sign the enrty
-                };
-
-                if (!(keystore && signKey)) {
-                  _context.next = 17;
-                  break;
-                }
-
-                _context.next = 16;
-                return Entry.signEntry(keystore, entry, signKey);
-
-              case 16:
-                entry = _context.sent;
-
-              case 17:
-                _context.next = 19;
-                return Entry.toMultihash(ipfs, entry);
-
-              case 19:
-                entry.hash = _context.sent;
-                return _context.abrupt('return', entry);
-
-              case 21:
-              case 'end':
-                return _context.stop();
-            }
-          }
-        }, _callee, this);
-      }));
-
-      function create(_x3, _x4, _x5, _x6) {
-        return _ref.apply(this, arguments);
-      }
-
-      return create;
-    }()
-  }, {
-    key: 'signEntry',
-    value: function () {
-      var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2(keystore, entry, key) {
-        var signature;
-        return _regenerator2.default.wrap(function _callee2$(_context2) {
-          while (1) {
-            switch (_context2.prev = _context2.next) {
-              case 0:
-                _context2.next = 2;
-                return keystore.sign(key, Buffer.from((0, _stringify2.default)(entry)));
-
-              case 2:
-                signature = _context2.sent;
-
-                entry.sig = signature;
-                entry.key = key.getPublic('hex');
-                return _context2.abrupt('return', entry);
-
-              case 6:
-              case 'end':
-                return _context2.stop();
-            }
-          }
-        }, _callee2, this);
-      }));
-
-      function signEntry(_x7, _x8, _x9) {
-        return _ref2.apply(this, arguments);
-      }
-
-      return signEntry;
-    }()
-  }, {
-    key: 'verifyEntry',
-    value: function () {
-      var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3(entry, keystore) {
-        var e, pubKey;
-        return _regenerator2.default.wrap(function _callee3$(_context3) {
-          while (1) {
-            switch (_context3.prev = _context3.next) {
-              case 0:
-                e = (0, _assign2.default)({}, {
-                  hash: null,
-                  id: entry.id,
-                  payload: entry.payload,
-                  next: entry.next,
-                  refs: entry.refs,
-                  v: entry.v,
-                  clock: entry.clock
-                });
-                _context3.next = 3;
-                return keystore.importPublicKey(entry.key);
-
-              case 3:
-                pubKey = _context3.sent;
-                _context3.next = 6;
-                return keystore.verify(entry.sig, pubKey, Buffer.from((0, _stringify2.default)(e)));
-
-              case 6:
-              case 'end':
-                return _context3.stop();
-            }
-          }
-        }, _callee3, this);
-      }));
-
-      function verifyEntry(_x10, _x11) {
-        return _ref3.apply(this, arguments);
-      }
-
-      return verifyEntry;
-    }()
-
-    /**
-     * Get the multihash of an Entry
-     * @param {IPFS} [ipfs] An IPFS instance
-     * @param {Entry} [entry] Entry to get a multihash for
-     * @example
-     * const hash = await Entry.toMultihash(ipfs, entry)
-     * console.log(hash)
-     * // "Qm...Foo"
-     * @returns {Promise<string>}
-     */
-
-  }, {
-    key: 'toMultihash',
-    value: function toMultihash(ipfs, entry) {
-      if (!ipfs) throw IpfsNotDefinedError();
-      var data = Buffer.from((0, _stringify2.default)(entry));
-      return ipfs.object.put(data).then(function (res) {
-        return res.toJSON().multihash;
-      });
-    }
-
-    /**
-     * Create an Entry from a multihash
-     * @param {IPFS} [ipfs] An IPFS instance
-     * @param {string} [hash] Multihash as Base58 encoded string to create an Entry from
-     * @example
-     * const hash = await Entry.fromMultihash(ipfs, "Qm...Foo")
-     * console.log(hash)
-     * // { hash: "Qm...Foo", payload: "hello", next: [] }
-     * @returns {Promise<Entry>}
-     */
-
-  }, {
-    key: 'fromMultihash',
-    value: function fromMultihash(ipfs, hash) {
-      if (!ipfs) throw IpfsNotDefinedError();
-      if (!hash) throw new Error('Invalid hash: ' + hash);
-      return ipfs.object.get(hash, { enc: 'base58' }).then(function (obj) {
-        return JSON.parse(obj.toJSON().data);
-      }).then(function (data) {
-        var entry = {
-          hash: hash,
-          id: data.id,
-          payload: data.payload,
-          next: data.next,
-          refs: data.refs,
-          v: data.v,
-          clock: data.clock
-        };
-        if (data.sig) (0, _assign2.default)(entry, { sig: data.sig });
-        if (data.key) (0, _assign2.default)(entry, { key: data.key });
-        return entry;
-      });
-    }
-
-    /**
-     * Check if an object is an Entry
-     * @param {Entry} obj
-     * @returns {boolean}
-     */
-
-  }, {
-    key: 'isEntry',
-    value: function isEntry(obj) {
-      return obj.id !== undefined && obj.next !== undefined && obj.refs !== undefined && obj.hash !== undefined && obj.payload !== undefined && obj.v !== undefined && obj.clock !== undefined;
-    }
-  }, {
-    key: 'compare',
-    value: function compare(a, b) {
-      var distance = Clock.compare(a.clock, b.clock);
-      if (distance === 0) return a.clock.id < b.clock.id ? -1 : 1;
-      return distance;
-    }
-
-    /**
-     * Check if an entry equals another entry
-     * @param {Entry} a
-     * @param {Entry} b
-     * @returns {boolean}
-     */
-
-  }, {
-    key: 'isEqual',
-    value: function isEqual(a, b) {
-      return a.hash === b.hash;
-    }
-
-    /**
-     * Check if an entry is a parent to another entry.
-     * @param {Entry} [entry1] Entry to check
-     * @param {Entry} [entry2] Parent
-     * @returns {boolean}
-     */
-
-  }, {
-    key: 'isParent',
-    value: function isParent(entry1, entry2) {
-      return entry2.next.indexOf(entry1.hash) > -1;
-    }
-
-    /**
-     * Find entry's children from an Array of entries
-     *
-     * @description
-     * Returns entry's children as an Array up to the last know child.
-     *
-     * @param {Entry} [entry] Entry for which to find the parents
-     * @param {Array<Entry>} [vaules] Entries to search parents from
-     * @returns {Array<Entry>}
-     */
-
-  }, {
-    key: 'findChildren',
-    value: function findChildren(entry, values) {
-      var stack = [];
-      var parent = values.find(function (e) {
-        return Entry.isParent(entry, e);
-      });
-      var prev = entry;
-      while (parent) {
-        stack.push(parent);
-        prev = parent;
-        parent = values.find(function (e) {
-          return Entry.isParent(prev, e);
-        });
-      }
-      stack = stack.sort(function (a, b) {
-        return a.clock.time > a.clock.time;
-      });
-      return stack;
-    }
-  }]);
-  return Entry;
-}();
-
-module.exports = Entry;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/g-set.js
+++ /dev/null
@@ -1,51 +0,0 @@
-'use strict';
-
-/**
- * Interface for G-Set CRDT
- *
- * From:
- * "A comprehensive study of Convergent and Commutative Replicated Data Types"
- * https://hal.inria.fr/inria-00555588
- */
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var GSet = function () {
-  function GSet() {
-    (0, _classCallCheck3.default)(this, GSet);
-  }
-
-  (0, _createClass3.default)(GSet, [{
-    key: 'constuctor',
-    value: function constuctor(values) {}
-  }, {
-    key: 'append',
-    value: function append(value) {}
-  }, {
-    key: 'merge',
-    value: function merge(set) {}
-  }, {
-    key: 'get',
-    value: function get(value) {}
-  }, {
-    key: 'has',
-    value: function has(value) {}
-  }, {
-    key: 'values',
-    get: function get() {}
-  }, {
-    key: 'length',
-    get: function get() {}
-  }]);
-  return GSet;
-}();
-
-module.exports = GSet;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/lamport-clock.js
+++ /dev/null
@@ -1,53 +0,0 @@
-'use strict';
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var LamportClock = function () {
-  function LamportClock(id, time) {
-    (0, _classCallCheck3.default)(this, LamportClock);
-
-    this.id = id;
-    this.time = time || 0;
-  }
-
-  (0, _createClass3.default)(LamportClock, [{
-    key: 'tick',
-    value: function tick() {
-      return new LamportClock(this.id, ++this.time);
-    }
-  }, {
-    key: 'merge',
-    value: function merge(clock) {
-      this.time = Math.max(this.time, clock.time);
-      return new LamportClock(this.id, this.time);
-    }
-  }, {
-    key: 'clone',
-    value: function clone() {
-      return new LamportClock(this.id, this.time);
-    }
-  }], [{
-    key: 'compare',
-    value: function compare(a, b) {
-      // Calculate the "distance" based on the clock, ie. lower or greater
-      var dist = a.time - b.time;
-
-      // If the sequence number is the same (concurrent events),
-      // and the IDs are different, take the one with a "lower" id
-      if (dist === 0 && a.id !== b.id) return a.id < b.id ? -1 : 1;
-
-      return dist;
-    }
-  }]);
-  return LamportClock;
-}();
-
-module.exports = LamportClock;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/log-errors.js
+++ /dev/null
@@ -1,17 +0,0 @@
-'use strict';
-
-var ImmutableDBNotDefinedError = function ImmutableDBNotDefinedError() {
-  return new Error('ImmutableDB instance not defined');
-};
-var LogNotDefinedError = function LogNotDefinedError() {
-  return new Error('Log instance not defined');
-};
-var NotALogError = function NotALogError() {
-  return new Error('Given argument is not an instance of Log');
-};
-
-module.exports = {
-  ImmutableDBNotDefinedError: ImmutableDBNotDefinedError,
-  LogNotDefinedError: LogNotDefinedError,
-  NotALogError: NotALogError
-};
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/log-io.js
+++ /dev/null
@@ -1,276 +0,0 @@
-'use strict';
-
-var _regenerator = require('babel-runtime/regenerator');
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _values = require('babel-runtime/core-js/object/values');
-
-var _values2 = _interopRequireDefault(_values);
-
-var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var pMap = require('p-map');
-var Entry = require('./entry');
-var EntryIO = require('./entry-io');
-var Clock = require('./lamport-clock');
-var LogError = require('./log-errors');
-var isDefined = require('./utils/is-defined');
-var _uniques = require('./utils/uniques');
-var intersection = require('./utils/intersection');
-var difference = require('./utils/difference');
-
-var last = function last(arr, n) {
-  return arr.slice(arr.length - n, arr.length);
-};
-var uniqueEntriesReducer = function uniqueEntriesReducer(res, acc) {
-  res[acc.hash] = acc;
-  return res;
-};
-
-var LogIO = function () {
-  function LogIO() {
-    (0, _classCallCheck3.default)(this, LogIO);
-  }
-
-  (0, _createClass3.default)(LogIO, null, [{
-    key: 'toMultihash',
-    value: function toMultihash(ipfs, log) {
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      if (!isDefined(log)) throw LogError.LogNotDefinedError();
-
-      if (log.values.length < 1) throw new Error('Can\'t serialize an empty log');
-
-      return ipfs.object.put(log.toBuffer()).then(function (dagNode) {
-        return dagNode.toJSON().multihash;
-      });
-    }
-
-    /**
-     * Create a log from multihash
-     * @param {IPFS} ipfs - An IPFS instance
-     * @param {string} hash - Multihash (as a Base58 encoded string) to create the log from
-     * @param {Number} [length=-1] - How many items to include in the log
-     * @param {function(hash, entry, parent, depth)} onProgressCallback
-     * @returns {Promise<Log>}
-     */
-
-  }, {
-    key: 'fromMultihash',
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(ipfs, hash) {
-        var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-        var exclude = arguments[3];
-        var onProgressCallback = arguments[4];
-        var dagNode, logData, entries, uniques, clock, finalEntries, heads;
-        return _regenerator2.default.wrap(function _callee$(_context) {
-          while (1) {
-            switch (_context.prev = _context.next) {
-              case 0:
-                if (isDefined(ipfs)) {
-                  _context.next = 2;
-                  break;
-                }
-
-                throw LogError.ImmutableDBNotDefinedError();
-
-              case 2:
-                if (isDefined(hash)) {
-                  _context.next = 4;
-                  break;
-                }
-
-                throw new Error('Invalid hash: ' + hash);
-
-              case 4:
-                _context.next = 6;
-                return ipfs.object.get(hash, { enc: 'base58' });
-
-              case 6:
-                dagNode = _context.sent;
-                logData = JSON.parse(dagNode.toJSON().data);
-
-                if (!(!logData.heads || !logData.id)) {
-                  _context.next = 10;
-                  break;
-                }
-
-                throw LogError.NotALogError();
-
-              case 10:
-                _context.next = 12;
-                return EntryIO.fetchParallel(ipfs, logData.heads, length, exclude, null, null, onProgressCallback);
-
-              case 12:
-                entries = _context.sent;
-                uniques = (0, _values2.default)(entries.reduce(uniqueEntriesReducer, {})
-
-                // Find latest clock
-                );
-                clock = uniques.reduce(function (clock, entry) {
-                  return entry.clock.time > clock.time ? new Clock(entry.clock.id, entry.clock.time) : clock;
-                }, new Clock(logData.id)
-
-                // Cut the entries to the requested size
-                );
-                finalEntries = length > -1 ? last(uniques.sort(Entry.compare), length) : uniques;
-
-                // Find the head entries
-
-                heads = finalEntries.filter(function (e) {
-                  return logData.heads.includes(e.hash);
-                });
-                return _context.abrupt('return', {
-                  id: logData.id,
-                  values: finalEntries,
-                  heads: heads,
-                  clock: clock
-                });
-
-              case 18:
-              case 'end':
-                return _context.stop();
-            }
-          }
-        }, _callee, this);
-      }));
-
-      function fromMultihash(_x2, _x3) {
-        return _ref.apply(this, arguments);
-      }
-
-      return fromMultihash;
-    }()
-  }, {
-    key: 'fromEntryHash',
-    value: function fromEntryHash(ipfs, entryHash, id) {
-      var length = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : -1;
-      var exclude = arguments[4];
-      var onProgressCallback = arguments[5];
-
-      if (!isDefined(ipfs)) throw LogError.IpfsNotDefinedError();
-      if (!isDefined(entryHash)) throw new Error("'entryHash' must be defined");
-
-      // Fetch given length, return size at least the given input entries
-      length = length > -1 ? Math.max(length, 1) : length;
-
-      // Make sure we pass hashes instead of objects to the fetcher function
-      var excludeHashes = exclude; // ? exclude.map(e => e.hash ? e.hash : e) : exclude
-
-      return EntryIO.fetchParallel(ipfs, [entryHash], length, excludeHashes, null, null, onProgressCallback).then(function (entries) {
-        // Cap the result at the right size by taking the last n entries,
-        // or if given length is -1, then take all
-        var sliced = length > -1 ? last(entries, length) : entries;
-        return {
-          values: sliced
-        };
-      });
-    }
-  }, {
-    key: 'fromJSON',
-    value: function fromJSON(ipfs, json) {
-      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-      var key = arguments[3];
-      var timeout = arguments[4];
-      var onProgressCallback = arguments[5];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      return EntryIO.fetchParallel(ipfs, json.heads.map(function (e) {
-        return e.hash;
-      }), length, [], 16, timeout, onProgressCallback).then(function (entries) {
-        var finalEntries = entries.slice().sort(Entry.compare);
-        var heads = entries.filter(function (e) {
-          return json.heads.includes(e.hash);
-        });
-        return {
-          id: json.id,
-          values: finalEntries,
-          heads: json.heads
-        };
-      });
-    }
-
-    /**
-     * Create a new log starting from an entry
-     * @param {IPFS} ipfs An IPFS instance
-     * @param {Array<Entry>} entries An entry or an array of entries to fetch a log from
-     * @param {Number} [length=-1] How many entries to include. Default: infinite.
-     * @param {Array<Entry|string>} [exclude] Entries to not fetch (cached)
-     * @param {function(hash, entry, parent, depth)} [onProgressCallback]
-     * @returns {Promise<Log>}
-     */
-
-  }, {
-    key: 'fromEntry',
-    value: function fromEntry(ipfs, sourceEntries) {
-      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-      var exclude = arguments[3];
-      var key = arguments[4];
-      var keys = arguments[5];
-      var onProgressCallback = arguments[6];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      if (!isDefined(sourceEntries)) throw new Error("'sourceEntries' must be defined");
-
-      // Make sure we only have Entry objects as input
-      if (!Array.isArray(sourceEntries) && !Entry.isEntry(sourceEntries)) {
-        throw new Error('\'sourceEntries\' argument must be an array of Entry instances or a single Entry');
-      }
-
-      if (!Array.isArray(sourceEntries)) {
-        sourceEntries = [sourceEntries];
-      }
-
-      // Fetch given length, return size at least the given input entries
-      length = length > -1 ? Math.max(length, sourceEntries.length) : length;
-
-      // Make sure we pass hashes instead of objects to the fetcher function
-      var excludeHashes = exclude ? exclude.map(function (e) {
-        return e.hash ? e.hash : e;
-      }) : exclude;
-      var hashes = sourceEntries.map(function (e) {
-        return e.hash;
-      });
-
-      return EntryIO.fetchParallel(ipfs, hashes, length, excludeHashes, null, null, onProgressCallback).then(function (entries) {
-        var combined = sourceEntries.concat(entries);
-        var uniques = _uniques(combined, 'hash').sort(Entry.compare
-
-        // Cap the result at the right size by taking the last n entries
-        );var sliced = uniques.slice(length > -1 ? -length : -uniques.length
-
-        // Make sure that the given input entries are present in the result
-        // in order to not lose references
-        );var missingSourceEntries = difference(sliced, sourceEntries, 'hash');
-
-        var replaceInFront = function replaceInFront(a, withEntries) {
-          var sliced = a.slice(withEntries.length, a.length);
-          return withEntries.concat(sliced);
-        };
-
-        // Add the input entries at the beginning of the array and remove
-        // as many elements from the array before inserting the original entries
-        var result = replaceInFront(sliced, missingSourceEntries);
-        return {
-          id: result[result.length - 1].id,
-          values: result
-        };
-      });
-    }
-  }]);
-  return LogIO;
-}();
-
-module.exports = LogIO;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/log.js
+++ /dev/null
@@ -1,1017 +0,0 @@
-'use strict';
-
-var _stringify = require('babel-runtime/core-js/json/stringify');
-
-var _stringify2 = _interopRequireDefault(_stringify);
-
-var _assign = require('babel-runtime/core-js/object/assign');
-
-var _assign2 = _interopRequireDefault(_assign);
-
-var _keys = require('babel-runtime/core-js/object/keys');
-
-var _keys2 = _interopRequireDefault(_keys);
-
-var _regenerator = require('babel-runtime/regenerator');
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _from = require('babel-runtime/core-js/array/from');
-
-var _from2 = _interopRequireDefault(_from);
-
-var _set = require('babel-runtime/core-js/set');
-
-var _set2 = _interopRequireDefault(_set);
-
-var _values = require('babel-runtime/core-js/object/values');
-
-var _values2 = _interopRequireDefault(_values);
-
-var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _getPrototypeOf = require('babel-runtime/core-js/object/get-prototype-of');
-
-var _getPrototypeOf2 = _interopRequireDefault(_getPrototypeOf);
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-var _possibleConstructorReturn2 = require('babel-runtime/helpers/possibleConstructorReturn');
-
-var _possibleConstructorReturn3 = _interopRequireDefault(_possibleConstructorReturn2);
-
-var _inherits2 = require('babel-runtime/helpers/inherits');
-
-var _inherits3 = _interopRequireDefault(_inherits2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var pMap = require('p-map');
-var GSet = require('./g-set');
-var Entry = require('./entry');
-var EntryIO = require('./entry-io');
-var LogIO = require('./log-io');
-var LogError = require('./log-errors');
-var Clock = require('./lamport-clock');
-var MemStore = require('./utils/mem-store');
-var isDefined = require('./utils/is-defined');
-var _uniques = require('./utils/uniques');
-
-var randomId = function randomId() {
-  return new Date().getTime().toString();
-};
-var getHash = function getHash(e) {
-  return e.hash;
-};
-var flatMap = function flatMap(res, acc) {
-  return res.concat(acc);
-};
-var getNextPointers = function getNextPointers(entry) {
-  return entry.next;
-};
-var getFirstNextPointer = function getFirstNextPointer(entry) {
-  return entry.next[0];
-};
-var maxClockTimeReducer = function maxClockTimeReducer(res, acc) {
-  return Math.max(res, acc.clock.time);
-};
-var uniqueEntriesReducer = function uniqueEntriesReducer(res, acc) {
-  res[acc.hash] = acc;
-  return res;
-};
-
-/**
- * Log
- *
- * @description
- * Log implements a G-Set CRDT and adds ordering
- *
- * From:
- * "A comprehensive study of Convergent and Commutative Replicated Data Types"
- * https://hal.inria.fr/inria-00555588
- */
-
-var Log = function (_GSet) {
-  (0, _inherits3.default)(Log, _GSet);
-
-  /**
-   * Create a new Log instance
-   * @param  {IPFS}           ipfs    An IPFS instance
-   * @param  {String}         id      ID of the log
-   * @param  {[Array<Entry>]} entries An Array of Entries from which to create the log from
-   * @param  {[Array<Entry>]} heads   Set the heads of the log
-   * @param  {[Clock]}        clock   Set the clock of the log
-   * @return {Log}            Log
-   */
-  function Log(ipfs, id, entries, heads, clock, key) {
-    var keys = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : [];
-    (0, _classCallCheck3.default)(this, Log);
-
-    if (!isDefined(ipfs)) {
-      throw LogError.ImmutableDBNotDefinedError();
-    }
-
-    if (isDefined(entries) && !Array.isArray(entries)) {
-      throw new Error('\'entries\' argument must be an array of Entry instances');
-    }
-
-    if (isDefined(heads) && !Array.isArray(heads)) {
-      throw new Error('\'heads\' argument must be an array');
-    }
-
-    var _this = (0, _possibleConstructorReturn3.default)(this, (Log.__proto__ || (0, _getPrototypeOf2.default)(Log)).call(this));
-
-    _this._storage = ipfs;
-    _this._id = id || randomId
-
-    // Signing related setup
-    ();_this._keystore = _this._storage.keystore;
-    _this._key = key;
-    _this._keys = Array.isArray(keys) ? keys : [keys];
-
-    // Add entries to the internal cache
-    entries = entries || [];
-    _this._entryIndex = entries.reduce(uniqueEntriesReducer, {}
-
-    // Set heads if not passed as an argument
-    );heads = heads || Log.findHeads(entries);
-    _this._headsIndex = heads.reduce(uniqueEntriesReducer, {}
-
-    // Index of all next pointers in this log
-    );_this._nextsIndex = {};
-    entries.forEach(function (e) {
-      return e.next.forEach(function (a) {
-        return _this._nextsIndex[a] = e.hash;
-      });
-    }
-
-    // Set the length, we calculate the length manually internally
-    );_this._length = entries ? entries.length : 0;
-
-    // Set the clock
-    var maxTime = Math.max(clock ? clock.time : 0, _this.heads.reduce(maxClockTimeReducer, 0)
-    // Take the given key as the clock id is it's a Key instance,
-    // otherwise if key was given, take whatever it is,
-    // and if it was null, take the given id as the clock id
-    );var clockId = key && key.getPublic ? key.getPublic('hex') : key ? key : _this._id;
-    _this._clock = new Clock(clockId, maxTime);
-    return _this;
-  }
-
-  /**
-   * Returns the ID of the log
-   * @returns {string}
-   */
-
-
-  (0, _createClass3.default)(Log, [{
-    key: 'get',
-
-
-    /**
-     * Find an entry
-     * @param {string} [hash] The Multihash of the entry as Base58 encoded string
-     * @returns {Entry|undefined}
-     */
-    value: function get(hash) {
-      return this._entryIndex[hash];
-    }
-  }, {
-    key: 'has',
-    value: function has(entry) {
-      return this._entryIndex[entry.hash || entry] !== undefined;
-    }
-  }, {
-    key: 'traverse',
-    value: function traverse(rootEntries, amount, getNexts) {
-      // console.log("traverse>", rootEntries)
-      var stack = rootEntries.map(getNexts).reduce(flatMap, []);
-      var traversed = {};
-      var result = {};
-      var count = 0;
-
-      var addToStack = function addToStack(hash) {
-        if (!result[hash] && !traversed[hash]) {
-          stack.push(hash);
-          traversed[hash] = true;
-        }
-      };
-
-      var addRootHash = function addRootHash(rootEntry) {
-        result[rootEntry.hash] = rootEntry;
-        traversed[rootEntry.hash] = true;
-        count++;
-      };
-
-      rootEntries.forEach(addRootHash);
-
-      while (stack.length > 0 && count < amount) {
-        var hash = stack.shift();
-        var entry = this.get(hash);
-        if (entry) {
-          count++;
-          result[entry.hash] = entry;
-          traversed[entry.hash] = true;
-          entry.next.forEach(addToStack);
-        }
-      }
-      // Free memory
-      // This seems to get rid of a lot of small GC happening
-      // during an append. Why?
-      stack = [];
-      traversed = {};
-      return result;
-    }
-
-    /**
-     * Append an entry to the log
-     * @param  {Entry} entry Entry to add
-     * @return {Log}   New Log containing the appended value
-     */
-
-  }, {
-    key: 'append',
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(data) {
-        var _this2 = this;
-
-        var pointerCount = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
-        var newTime, nexts, all, getEveryPow2, references, refSet, delRef, refs, entry;
-        return _regenerator2.default.wrap(function _callee$(_context) {
-          while (1) {
-            switch (_context.prev = _context.next) {
-              case 0:
-                if (!(this._key && this._key.getPublic && !this._keys.includes(this._key.getPublic('hex')) && !this._keys.includes('*'))) {
-                  _context.next = 2;
-                  break;
-                }
-
-                throw new Error("Not allowed to write");
-
-              case 2:
-
-                // Update the clock (find the latest clock)
-                newTime = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0)) + 1;
-
-                this._clock = new Clock(this.clock.id, newTime);
-
-                // Get the heads
-                nexts = (0, _values2.default)(this.traverse(this.heads, this.heads.length, getNextPointers)).sort(function (a, b) {
-                  return a.clock.time > b.clock.time;
-                }).map(function (e) {
-                  return e.hash;
-                }
-
-                // Get the required amount of hashes to next entries (as per current state of the log)
-                );
-                all = (0, _values2.default)(this.traverse(this.heads, pointerCount, getFirstNextPointer)
-
-                // Get entries of pow2 at maxDistance (2nd, 4th, 8th, 16th, ...)
-                );
-
-                getEveryPow2 = function getEveryPow2(maxDistance) {
-                  var entries = new _set2.default();
-                  for (var i = 1; i <= maxDistance; i *= 2) {
-                    var index = Math.min(i - 1, all.length - 1);
-                    var ref = all[index];
-                    entries.add(ref);
-                  }
-                };
-
-                // If pointer count is 4, returns 2
-                // If pointer count is 8, returns 3 references
-                // If pointer count is 512, returns 9 references
-                // If pointer count is 2048, returns 11 references
-
-
-                references = getEveryPow2(Math.min(pointerCount, all.length));
-                refSet = new _set2.default(references);
-
-                // Always include the last known reference
-
-                if (all.length < pointerCount && all[all.length - 1]) refSet.add(all[all.length - 1]
-
-                // Delete the heads from the refs
-                );
-                delRef = function delRef(e) {
-                  return refSet.delete(e);
-                };
-
-                nexts.forEach(delRef);
-                refs = (0, _from2.default)(refSet).map(getHash
-
-                // Create the entry and add it to the internal cache
-                );
-                _context.next = 15;
-                return Entry.create(this._storage, this._keystore, this.id, data, nexts, this.clock, this._key, refs);
-
-              case 15:
-                entry = _context.sent;
-
-                this._entryIndex[entry.hash] = entry;
-                nexts.forEach(function (e) {
-                  return _this2._nextsIndex[e] = entry.hash;
-                });
-                this._headsIndex = {};
-                this._headsIndex[entry.hash] = entry;
-                // Update the internal length counter
-                this._length++;
-                return _context.abrupt('return', entry);
-
-              case 22:
-              case 'end':
-                return _context.stop();
-            }
-          }
-        }, _callee, this);
-      }));
-
-      function append(_x3) {
-        return _ref.apply(this, arguments);
-      }
-
-      return append;
-    }()
-
-    /**
-     * Join two logs
-     *
-     * @description Joins two logs returning a new log. Doesn't mutate the original logs.
-     *
-     * @param {IPFS}   [ipfs] An IPFS instance
-     * @param {Log}    log    Log to join with this Log
-     * @param {Number} [size] Max size of the joined log
-     * @param {string} [id]   ID to use for the new log
-     *
-     * @example
-     * log1.join(log2)
-     *
-     * @returns {Promise<Log>}
-     */
-
-  }, {
-    key: 'join',
-    value: function () {
-      var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee4(log) {
-        var _this3 = this;
-
-        var size = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
-        var verifyEntries, difference, newItems, canJoin, addToNextsIndex, tmp, notReferencedByNewItems, notInCurrentNexts, nextsFromNewItems, mergedHeads, maxClock;
-        return _regenerator2.default.wrap(function _callee4$(_context4) {
-          while (1) {
-            switch (_context4.prev = _context4.next) {
-              case 0:
-                if (isDefined(log)) {
-                  _context4.next = 2;
-                  break;
-                }
-
-                throw LogError.LogNotDefinedError();
-
-              case 2:
-                if (Log.isLog(log)) {
-                  _context4.next = 4;
-                  break;
-                }
-
-                throw LogError.NotALogError
-
-                // Verify the entries
-                // TODO: move to Entry
-                ();
-
-              case 4:
-                verifyEntries = function () {
-                  var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3(entries) {
-                    var isTrue, getPubKey, checkAllKeys, pubkeys, verify, checked;
-                    return _regenerator2.default.wrap(function _callee3$(_context3) {
-                      while (1) {
-                        switch (_context3.prev = _context3.next) {
-                          case 0:
-                            isTrue = function isTrue(e) {
-                              return e === true;
-                            };
-
-                            getPubKey = function getPubKey(e) {
-                              return e.getPublic ? e.getPublic('hex') : e;
-                            };
-
-                            checkAllKeys = function checkAllKeys(keys, entry) {
-                              var keyMatches = function keyMatches(e) {
-                                return e === entry.key;
-                              };
-                              return keys.find(keyMatches);
-                            };
-
-                            pubkeys = _this3._keys.map(getPubKey);
-
-                            verify = function () {
-                              var _ref4 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2(entry) {
-                                return _regenerator2.default.wrap(function _callee2$(_context2) {
-                                  while (1) {
-                                    switch (_context2.prev = _context2.next) {
-                                      case 0:
-                                        if (entry.key) {
-                                          _context2.next = 2;
-                                          break;
-                                        }
-
-                                        throw new Error("Entry doesn't have a public key");
-
-                                      case 2:
-                                        if (entry.sig) {
-                                          _context2.next = 4;
-                                          break;
-                                        }
-
-                                        throw new Error("Entry doesn't have a signature");
-
-                                      case 4:
-                                        if (!(_this3._keys.length === 1 && _this3._keys[0] === _this3._key)) {
-                                          _context2.next = 7;
-                                          break;
-                                        }
-
-                                        if (!(entry.id !== _this3.id)) {
-                                          _context2.next = 7;
-                                          break;
-                                        }
-
-                                        throw new Error("Entry doesn't belong in this log (wrong ID)");
-
-                                      case 7:
-                                        if (!(_this3._keys.length > 0 && !_this3._keys.includes('*') && !checkAllKeys(_this3._keys.concat([_this3._key]), entry))) {
-                                          _context2.next = 10;
-                                          break;
-                                        }
-
-                                        console.warn("Warning: Input log contains entries that are not allowed in this log. Logs weren't joined.");
-                                        return _context2.abrupt('return', false);
-
-                                      case 10:
-                                        _context2.prev = 10;
-                                        _context2.next = 13;
-                                        return Entry.verifyEntry(entry, _this3._keystore);
-
-                                      case 13:
-                                        _context2.next = 18;
-                                        break;
-
-                                      case 15:
-                                        _context2.prev = 15;
-                                        _context2.t0 = _context2['catch'](10);
-                                        throw new Error('Invalid signature in entry \'' + entry.hash + '\'');
-
-                                      case 18:
-                                        return _context2.abrupt('return', true);
-
-                                      case 19:
-                                      case 'end':
-                                        return _context2.stop();
-                                    }
-                                  }
-                                }, _callee2, _this3, [[10, 15]]);
-                              }));
-
-                              return function verify(_x7) {
-                                return _ref4.apply(this, arguments);
-                              };
-                            }();
-
-                            _context3.next = 7;
-                            return pMap(entries, verify);
-
-                          case 7:
-                            checked = _context3.sent;
-                            return _context3.abrupt('return', checked.every(isTrue));
-
-                          case 9:
-                          case 'end':
-                            return _context3.stop();
-                        }
-                      }
-                    }, _callee3, _this3);
-                  }));
-
-                  return function verifyEntries(_x6) {
-                    return _ref3.apply(this, arguments);
-                  };
-                }();
-
-                difference = function difference(log, exclude) {
-                  var stack = (0, _keys2.default)(log._headsIndex);
-                  var traversed = {};
-                  var res = {};
-
-                  var pushToStack = function pushToStack(hash) {
-                    if (!traversed[hash] && !exclude.get(hash)) {
-                      stack.push(hash);
-                      traversed[hash] = true;
-                    }
-                  };
-
-                  while (stack.length > 0) {
-                    var hash = stack.shift();
-                    var entry = log.get(hash);
-                    if (entry && !exclude.get(hash) && entry.id === _this3.id) {
-                      res[entry.hash] = entry;
-                      traversed[entry.hash] = true;
-                      entry.next.forEach(pushToStack);
-                    }
-                  }
-                  return res;
-                };
-
-                // Merge the entries
-
-
-                newItems = difference(log, this
-
-                // if a key was given, verify the entries from the incoming log
-                );
-
-                if (!(this._key && this._key.getPublic)) {
-                  _context4.next = 13;
-                  break;
-                }
-
-                _context4.next = 10;
-                return verifyEntries((0, _values2.default)(newItems)
-                // Return early if any of the given entries didn't verify
-                );
-
-              case 10:
-                canJoin = _context4.sent;
-
-                if (canJoin) {
-                  _context4.next = 13;
-                  break;
-                }
-
-                return _context4.abrupt('return', this);
-
-              case 13:
-
-                // Update the internal entry index
-                this._entryIndex = (0, _assign2.default)(this._entryIndex, newItems
-
-                // Update the internal next pointers index
-                );
-                addToNextsIndex = function addToNextsIndex(e) {
-                  return e.next.forEach(function (a) {
-                    return _this3._nextsIndex[a] = e.hash;
-                  });
-                };
-
-                (0, _values2.default)(newItems).forEach(addToNextsIndex
-
-                // Update the length
-                );this._length += (0, _values2.default)(newItems).length;
-
-                // Slice to the requested size
-                if (size > -1) {
-                  tmp = this.values;
-
-                  tmp = tmp.slice(-size);
-                  this._entryIndex = tmp.reduce(uniqueEntriesReducer, {});
-                  this._length = (0, _values2.default)(this._entryIndex).length;
-                }
-
-                // Merge the heads
-
-                notReferencedByNewItems = function notReferencedByNewItems(e) {
-                  return !nextsFromNewItems.find(function (a) {
-                    return a === e.hash;
-                  });
-                };
-
-                notInCurrentNexts = function notInCurrentNexts(e) {
-                  return !_this3._nextsIndex[e.hash];
-                };
-
-                nextsFromNewItems = (0, _values2.default)(newItems).map(getNextPointers).reduce(flatMap, []);
-                mergedHeads = Log.findHeads((0, _values2.default)((0, _assign2.default)({}, this._headsIndex, log._headsIndex))).filter(notReferencedByNewItems).filter(notInCurrentNexts).reduce(uniqueEntriesReducer, {});
-
-
-                this._headsIndex = mergedHeads;
-
-                // Find the latest clock from the heads
-                maxClock = (0, _values2.default)(this._headsIndex).reduce(maxClockTimeReducer, 0);
-
-                this._clock = new Clock(this.clock.id, Math.max(this.clock.time, maxClock));
-                return _context4.abrupt('return', this);
-
-              case 26:
-              case 'end':
-                return _context4.stop();
-            }
-          }
-        }, _callee4, this);
-      }));
-
-      function join(_x5) {
-        return _ref2.apply(this, arguments);
-      }
-
-      return join;
-    }()
-
-    /**
-     * Get the log in JSON format
-     * @returns {Object<{heads}>}
-     */
-
-  }, {
-    key: 'toJSON',
-    value: function toJSON() {
-      return {
-        id: this.id,
-        heads: this.heads.map(getHash)
-      };
-    }
-  }, {
-    key: 'toSnapshot',
-    value: function toSnapshot() {
-      return {
-        id: this.id,
-        heads: this.heads,
-        values: this.values
-      };
-    }
-    /**
-     * Get the log as a Buffer
-     * @returns {Buffer}
-     */
-
-  }, {
-    key: 'toBuffer',
-    value: function toBuffer() {
-      return Buffer.from((0, _stringify2.default)(this.toJSON()));
-    }
-
-    /**
-     * Returns the log entries as a formatted string
-     * @example
-     * two
-     * └─one
-     *   └─three
-     * @returns {string}
-     */
-
-  }, {
-    key: 'toString',
-    value: function toString(payloadMapper) {
-      var _this4 = this;
-
-      return this.values.slice().reverse().map(function (e, idx) {
-        var parents = Entry.findChildren(e, _this4.values);
-        var len = parents.length;
-        var padding = new Array(Math.max(len - 1, 0));
-        padding = len > 1 ? padding.fill('  ') : padding;
-        padding = len > 0 ? padding.concat(['└─']) : padding;
-        return padding.join('') + (payloadMapper ? payloadMapper(e.payload) : e.payload);
-      }).join('\n');
-    }
-
-    /**
-     * Check whether an object is a Log instance
-     * @param {Object} log An object to check
-     * @returns {true|false}
-     */
-
-  }, {
-    key: 'toMultihash',
-
-
-    /**
-     * Get the log's multihash
-     * @returns {Promise<string>} Multihash of the Log as Base58 encoded string
-     */
-    value: function toMultihash() {
-      return LogIO.toMultihash(this._storage, this);
-    }
-
-    /**
-     * Create a log from multihash
-     * @param {IPFS}   ipfs        An IPFS instance
-     * @param {string} hash        Multihash (as a Base58 encoded string) to create the log from
-     * @param {Number} [length=-1] How many items to include in the log
-     * @param {Function(hash, entry, parent, depth)} onProgressCallback
-     * @return {Promise<Log>}      New Log
-     */
-
-  }, {
-    key: 'id',
-    get: function get() {
-      return this._id;
-    }
-
-    /**
-     * Returns the clock of the log
-     * @returns {string}
-     */
-
-  }, {
-    key: 'clock',
-    get: function get() {
-      return this._clock;
-    }
-
-    /**
-     * Returns the length of the log
-     * @return {Number} Length
-     */
-
-  }, {
-    key: 'length',
-    get: function get() {
-      return this._length;
-    }
-
-    /**
-     * Returns the values in the log
-     * @returns {Array<Entry>}
-     */
-
-  }, {
-    key: 'values',
-    get: function get() {
-      return (0, _values2.default)(this._entryIndex).sort(Entry.compare) || [];
-    }
-
-    /**
-     * Returns an array of heads as multihashes
-     * @returns {Array<string>}
-     */
-
-  }, {
-    key: 'heads',
-    get: function get() {
-      return (0, _values2.default)(this._headsIndex) || [];
-    }
-
-    /**
-     * Returns an array of Entry objects that reference entries which
-     * are not in the log currently
-     * @returns {Array<Entry>}
-     */
-
-  }, {
-    key: 'tails',
-    get: function get() {
-      return Log.findTails(this.values);
-    }
-
-    /**
-     * Returns an array of multihashes that are referenced by entries which
-     * are not in the log currently
-     * @returns {Array<string>} Array of multihashes
-     */
-
-  }, {
-    key: 'tailHashes',
-    get: function get() {
-      return Log.findTailHashes(this.values);
-    }
-  }], [{
-    key: 'isLog',
-    value: function isLog(log) {
-      return log.id !== undefined && log.heads !== undefined && log._entryIndex !== undefined;
-    }
-  }, {
-    key: 'fromMultihash',
-    value: function fromMultihash(ipfs, hash) {
-      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-      var exclude = arguments[3];
-      var key = arguments[4];
-      var onProgressCallback = arguments[5];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      if (!isDefined(hash)) throw new Error('Invalid hash: ' + hash);
-
-      // TODO: need to verify the entries with 'key'
-      return LogIO.fromMultihash(ipfs, hash, length, exclude, onProgressCallback).then(function (data) {
-        return new Log(ipfs, data.id, data.values, data.heads, data.clock, key);
-      });
-    }
-
-    /**
-     * Create a log from a single entry's multihash
-     * @param {IPFS}   ipfs        An IPFS instance
-     * @param {string} hash        Multihash (as a Base58 encoded string) of the Entry from which to create the log from
-     * @param {Number} [length=-1] How many entries to include in the log
-     * @param {Function(hash, entry, parent, depth)} onProgressCallback
-     * @return {Promise<Log>}      New Log
-     */
-
-  }, {
-    key: 'fromEntryHash',
-    value: function fromEntryHash(ipfs, hash, id) {
-      var length = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : -1;
-      var exclude = arguments[4];
-      var key = arguments[5];
-      var keys = arguments[6];
-      var onProgressCallback = arguments[7];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      if (!isDefined(hash)) throw new Error("'hash' must be defined");
-
-      // TODO: need to verify the entries with 'key'
-      return LogIO.fromEntryHash(ipfs, hash, id, length, exclude, onProgressCallback).then(function (data) {
-        return new Log(ipfs, id, data.values, null, null, key, keys);
-      });
-    }
-
-    /**
-     * Create a log from a Log Snapshot JSON
-     * @param {IPFS} ipfs          An IPFS instance
-     * @param {Object} json        Log snapshot as JSON object
-     * @param {Number} [length=-1] How many entries to include in the log
-     * @param {Function(hash, entry, parent, depth)} [onProgressCallback]
-     * @return {Promise<Log>}      New Log
-     */
-
-  }, {
-    key: 'fromJSON',
-    value: function fromJSON(ipfs, json) {
-      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-      var key = arguments[3];
-      var keys = arguments[4];
-      var timeout = arguments[5];
-      var onProgressCallback = arguments[6];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError
-
-      // TODO: need to verify the entries with 'key'
-      ();return LogIO.fromJSON(ipfs, json, length, key, timeout, onProgressCallback).then(function (data) {
-        return new Log(ipfs, data.id, data.values, null, null, key, keys);
-      });
-    }
-
-    /**
-     * Create a new log from an Entry instance
-     * @param {IPFS}                ipfs          An IPFS instance
-     * @param {Entry|Array<Entry>}  sourceEntries An Entry or an array of entries to fetch a log from
-     * @param {Number}              [length=-1]   How many entries to include. Default: infinite.
-     * @param {Array<Entry|string>} [exclude]     Array of entries or hashes or entries to not fetch (foe eg. cached entries)
-     * @param {Function(hash, entry, parent, depth)} [onProgressCallback]
-     * @return {Promise<Log>}       New Log
-     */
-
-  }, {
-    key: 'fromEntry',
-    value: function fromEntry(ipfs, sourceEntries) {
-      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
-      var exclude = arguments[3];
-      var onProgressCallback = arguments[4];
-
-      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();
-      if (!isDefined(sourceEntries)) throw new Error("'sourceEntries' must be defined");
-
-      // TODO: need to verify the entries with 'key'
-      return LogIO.fromEntry(ipfs, sourceEntries, length, exclude, onProgressCallback).then(function (data) {
-        return new Log(ipfs, data.id, data.values);
-      });
-    }
-
-    /**
-     * Find heads from a collection of entries
-     *
-     * @description
-     * Finds entries that are the heads of this collection,
-     * ie. entries that are not referenced by other entries
-     *
-     * @param {Array<Entry>} Entries to search heads from
-     * @returns {Array<Entry>}
-     */
-
-  }, {
-    key: 'findHeads',
-    value: function findHeads(entries) {
-      var indexReducer = function indexReducer(res, entry, idx, arr) {
-        var addToResult = function addToResult(e) {
-          return res[e] = entry.hash;
-        };
-        entry.next.forEach(addToResult);
-        return res;
-      };
-
-      var items = entries.reduce(indexReducer, {});
-
-      var exists = function exists(e) {
-        return items[e.hash] === undefined;
-      };
-      var compareIds = function compareIds(a, b) {
-        return a.clock.id > b.clock.id;
-      };
-
-      return entries.filter(exists).sort(compareIds);
-    }
-
-    // Find entries that point to another entry that is not in the
-    // input array
-
-  }, {
-    key: 'findTails',
-    value: function findTails(entries) {
-      // Reverse index { next -> entry }
-      var reverseIndex = {};
-      // Null index containing entries that have no parents (nexts)
-      var nullIndex = [];
-      // Hashes for all entries for quick lookups
-      var hashes = {};
-      // Hashes of all next entries
-      var nexts = [];
-
-      var addToIndex = function addToIndex(e) {
-        if (e.next.length === 0) {
-          nullIndex.push(e);
-        }
-        var addToReverseIndex = function addToReverseIndex(a) {
-          /* istanbul ignore else */
-          if (!reverseIndex[a]) reverseIndex[a] = [];
-          reverseIndex[a].push(e);
-        };
-
-        // Add all entries and their parents to the reverse index
-        e.next.forEach(addToReverseIndex
-        // Get all next references
-        );nexts = nexts.concat(e.next
-        // Get the hashes of input entries
-        );hashes[e.hash] = true;
-      };
-
-      // Create our indices
-      entries.forEach(addToIndex);
-
-      var addUniques = function addUniques(res, entries, idx, arr) {
-        return res.concat(_uniques(entries, 'hash'));
-      };
-      var exists = function exists(e) {
-        return hashes[e] === undefined;
-      };
-      var findFromReverseIndex = function findFromReverseIndex(e) {
-        return reverseIndex[e];
-      };
-
-      // Drop hashes that are not in the input entries
-      var tails = nexts // For every multihash in nexts:
-      .filter(exists // Remove undefineds and nulls
-      ).map(findFromReverseIndex // Get the Entry from the reverse index
-      ).reduce(addUniques, [] // Flatten the result and take only uniques
-      ).concat(nullIndex // Combine with tails the have no next refs (ie. first-in-their-chain)
-
-      );return _uniques(tails, 'hash').sort(Entry.compare);
-    }
-
-    // Find the hashes to entries that are not in a collection
-    // but referenced by other entries
-
-  }, {
-    key: 'findTailHashes',
-    value: function findTailHashes(entries) {
-      var hashes = {};
-      var addToIndex = function addToIndex(e) {
-        return hashes[e.hash] = true;
-      };
-
-      var reduceTailHashes = function reduceTailHashes(res, entry, idx, arr) {
-        var addToResult = function addToResult(e) {
-          /* istanbul ignore else */
-          if (hashes[e] === undefined) {
-            res.splice(0, 0, e);
-          }
-        };
-        entry.next.reverse().forEach(addToResult);
-        return res;
-      };
-
-      entries.forEach(addToIndex);
-      return entries.reduce(reduceTailHashes, []);
-    }
-
-    /* Expose utlities, usable via Log.MemStore */
-
-  }, {
-    key: 'MemStore',
-    get: function get() {
-      return MemStore;
-    }
-  }, {
-    key: 'EntryIO',
-    get: function get() {
-      return EntryIO;
-    }
-  }]);
-  return Log;
-}(GSet);
-
-module.exports = Log;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/mem-store.js
+++ /dev/null
@@ -1,222 +0,0 @@
-'use strict';
-
-var _promise = require('babel-runtime/core-js/promise');
-
-var _promise2 = _interopRequireDefault(_promise);
-
-var _regenerator = require('babel-runtime/regenerator');
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _asyncToGenerator2 = require('babel-runtime/helpers/asyncToGenerator');
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require('babel-runtime/helpers/createClass');
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var multihashing = require('multihashing-async');
-var mh = require('multihashes');
-
-var defaultHashAlg = 'sha2-256';
-
-var defaultFormat = { format: 'dag-cbor', hashAlg: defaultHashAlg
-
-  /* ImmutableDB using IPLD (through IPFS) */
-};
-var IPLDStore = function () {
-  function IPLDStore(ipfs) {
-    (0, _classCallCheck3.default)(this, IPLDStore);
-
-    // super()
-    this._ipfs = ipfs;
-  }
-
-  (0, _createClass3.default)(IPLDStore, [{
-    key: 'put',
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(value) {
-        var cid;
-        return _regenerator2.default.wrap(function _callee$(_context) {
-          while (1) {
-            switch (_context.prev = _context.next) {
-              case 0:
-                _context.next = 2;
-                return this._ipfs.dag.put(value, defaultFormat);
-
-              case 2:
-                cid = _context.sent;
-                return _context.abrupt('return', cid.toBaseEncodedString());
-
-              case 4:
-              case 'end':
-                return _context.stop();
-            }
-          }
-        }, _callee, this);
-      }));
-
-      function put(_x) {
-        return _ref.apply(this, arguments);
-      }
-
-      return put;
-    }()
-  }, {
-    key: 'get',
-    value: function () {
-      var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2(key) {
-        var result;
-        return _regenerator2.default.wrap(function _callee2$(_context2) {
-          while (1) {
-            switch (_context2.prev = _context2.next) {
-              case 0:
-                _context2.next = 2;
-                return this._ipfs.dag.get(key);
-
-              case 2:
-                result = _context2.sent;
-                return _context2.abrupt('return', result.value);
-
-              case 4:
-              case 'end':
-                return _context2.stop();
-            }
-          }
-        }, _callee2, this);
-      }));
-
-      function get(_x2) {
-        return _ref2.apply(this, arguments);
-      }
-
-      return get;
-    }()
-  }]);
-  return IPLDStore;
-}();
-
-var createMultihash = function createMultihash(data, hashAlg) {
-  return new _promise2.default(function (resolve, reject) {
-    multihashing(data, hashAlg || defaultHashAlg, function (err, multihash) {
-      if (err) return reject(err);
-
-      resolve(mh.toB58String(multihash));
-    });
-  });
-};
-
-// const LRU = require('lru')
-// const ImmutableDB = require('./immutabledb-interface')
-// const createMultihash = require('./create-multihash')
-
-/* Memory store using an LRU cache */
-
-var MemStore = function () {
-  function MemStore() {
-    (0, _classCallCheck3.default)(this, MemStore);
-
-    this._store = {}; //new LRU(1000)
-  }
-
-  (0, _createClass3.default)(MemStore, [{
-    key: 'put',
-    value: function () {
-      var _ref3 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee3(value) {
-        var data, hash;
-        return _regenerator2.default.wrap(function _callee3$(_context3) {
-          while (1) {
-            switch (_context3.prev = _context3.next) {
-              case 0:
-                data = value; //new Buffer(JSON.stringify(value))
-                // const hash = "MEM" + Math.floor(Math.random() * 100000000)
-
-                hash = "MEM" + (Math.random() * 100000000).toString
-                // const hash = await createMultihash(data)
-                // console.log(this._store)
-                // this._store.set(hash, data)
-                ();
-                if (!this._store) this._store = {};
-                // console.log(this._store)
-                // console.log(hash, data)
-                this._store[hash] = data;
-                // return hash
-                return _context3.abrupt('return', _promise2.default.resolve({
-                  toJSON: function toJSON() {
-                    return {
-                      data: value,
-                      multihash: hash
-                    };
-                  }
-                }));
-
-              case 5:
-              case 'end':
-                return _context3.stop();
-            }
-          }
-        }, _callee3, this);
-      }));
-
-      function put(_x3) {
-        return _ref3.apply(this, arguments);
-      }
-
-      return put;
-    }()
-  }, {
-    key: 'get',
-    value: function () {
-      var _ref4 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee4(key) {
-        var _this = this;
-
-        var data;
-        return _regenerator2.default.wrap(function _callee4$(_context4) {
-          while (1) {
-            switch (_context4.prev = _context4.next) {
-              case 0:
-                // const data = this._store.get(key)
-                data = this._store[key];
-
-                // if (data) {
-                //   const value = JSON.parse(data)
-                //   return value
-                // }
-
-                // return data
-
-                return _context4.abrupt('return', _promise2.default.resolve({
-                  toJSON: function toJSON() {
-                    return {
-                      data: _this._store[key],
-                      multihash: key
-                    };
-                  }
-                }));
-
-              case 2:
-              case 'end':
-                return _context4.stop();
-            }
-          }
-        }, _callee4, this);
-      }));
-
-      function get(_x4) {
-        return _ref4.apply(this, arguments);
-      }
-
-      return get;
-    }()
-  }]);
-  return MemStore;
-}();
-
-module.exports = MemStore;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/utils/difference.js
+++ /dev/null
@@ -1,28 +0,0 @@
-'use strict';
-
-function difference(a, b, key) {
-  // Indices for quick lookups
-  var processed = {};
-  var existing = {};
-
-  // Create an index of the first collection
-  var addToIndex = function addToIndex(e) {
-    return existing[key ? e[key] : e] = true;
-  };
-  a.forEach(addToIndex
-
-  // Reduce to entries that are not in the first collection
-  );var reducer = function reducer(res, entry) {
-    var isInFirst = existing[key ? entry[key] : entry] !== undefined;
-    var hasBeenProcessed = processed[key ? entry[key] : entry] !== undefined;
-    if (!isInFirst && !hasBeenProcessed) {
-      res.push(entry);
-      processed[key ? entry[key] : entry] = true;
-    }
-    return res;
-  };
-
-  return b.reduce(reducer, []);
-}
-
-module.exports = difference;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/utils/intersection.js
+++ /dev/null
@@ -1,28 +0,0 @@
-'use strict';
-
-function intersection(a, b, key) {
-  // Indices for quick lookups
-  var processed = {};
-  var existing = {};
-
-  // Create an index of the first collection
-  var addToIndex = function addToIndex(e) {
-    return existing[key ? e[key] : e] = true;
-  };
-  a.forEach(addToIndex
-
-  // Reduce to entries that are not in the first collection
-  );var reducer = function reducer(res, entry) {
-    var isInFirst = existing[key ? entry[key] : entry] !== undefined;
-    var hasBeenProcessed = processed[key ? entry[key] : entry] !== undefined;
-    if (isInFirst && !hasBeenProcessed) {
-      res.push(entry);
-      processed[key ? entry[key] : entry] = true;
-    }
-    return res;
-  };
-
-  return b.reduce(reducer, []);
-}
-
-module.exports = intersection;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/utils/is-defined.js
+++ /dev/null
@@ -1,7 +0,0 @@
-'use strict';
-
-var isDefined = function isDefined(arg) {
-  return arg !== undefined && arg !== null;
-};
-
-module.exports = isDefined;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/utils/mem-store.js
+++ /dev/null
@@ -1,106 +0,0 @@
-'use strict';
-
-var _regenerator = require("babel-runtime/regenerator");
-
-var _regenerator2 = _interopRequireDefault(_regenerator);
-
-var _promise = require("babel-runtime/core-js/promise");
-
-var _promise2 = _interopRequireDefault(_promise);
-
-var _asyncToGenerator2 = require("babel-runtime/helpers/asyncToGenerator");
-
-var _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);
-
-var _classCallCheck2 = require("babel-runtime/helpers/classCallCheck");
-
-var _classCallCheck3 = _interopRequireDefault(_classCallCheck2);
-
-var _createClass2 = require("babel-runtime/helpers/createClass");
-
-var _createClass3 = _interopRequireDefault(_createClass2);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-var MemStore = function () {
-  function MemStore() {
-    (0, _classCallCheck3.default)(this, MemStore);
-
-    this._store = {};
-  }
-
-  (0, _createClass3.default)(MemStore, [{
-    key: "put",
-    value: function () {
-      var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee(data) {
-        var hash;
-        return _regenerator2.default.wrap(function _callee$(_context) {
-          while (1) {
-            switch (_context.prev = _context.next) {
-              case 0:
-                hash = "MEM" + (Math.random() * 100000000).toString
-                // const hash = await createMultihash(data)
-                ();
-                if (!this._store) this._store = {};
-                this._store[hash] = data;
-                return _context.abrupt("return", _promise2.default.resolve({
-                  toJSON: function toJSON() {
-                    return {
-                      data: data,
-                      multihash: hash
-                    };
-                  }
-                }));
-
-              case 4:
-              case "end":
-                return _context.stop();
-            }
-          }
-        }, _callee, this);
-      }));
-
-      function put(_x) {
-        return _ref.apply(this, arguments);
-      }
-
-      return put;
-    }()
-  }, {
-    key: "get",
-    value: function () {
-      var _ref2 = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee2(key) {
-        var _this = this;
-
-        return _regenerator2.default.wrap(function _callee2$(_context2) {
-          while (1) {
-            switch (_context2.prev = _context2.next) {
-              case 0:
-                return _context2.abrupt("return", _promise2.default.resolve({
-                  toJSON: function toJSON() {
-                    return {
-                      data: _this._store[key],
-                      multihash: key
-                    };
-                  }
-                }));
-
-              case 1:
-              case "end":
-                return _context2.stop();
-            }
-          }
-        }, _callee2, this);
-      }));
-
-      function get(_x2) {
-        return _ref2.apply(this, arguments);
-      }
-
-      return get;
-    }()
-  }]);
-  return MemStore;
-}();
-
-module.exports = MemStore;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/lib/es5/utils/uniques.js
+++ /dev/null
@@ -1,22 +0,0 @@
-'use strict';
-
-var _keys = require('babel-runtime/core-js/object/keys');
-
-var _keys2 = _interopRequireDefault(_keys);
-
-function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
-
-function uniques(value, key) {
-  // Create an index of the collection
-  var uniques = {};
-  var get = function get(e) {
-    return uniques[e];
-  };
-  var addToIndex = function addToIndex(e) {
-    return uniques[key ? e[key] : e] = e;
-  };
-  value.forEach(addToIndex);
-  return (0, _keys2.default)(uniques).map(get);
-}
-
-module.exports = uniques;
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/entry-io.js
+++ /dev/null
@@ -1,150 +0,0 @@
-'use strict'
-
-const pMap = require('p-map')
-const pDoWhilst = require('p-do-whilst')
-const Entry = require('./entry')
-
-class EntryIO {
-  // Fetch log graphs in parallel
-  static fetchParallel (ipfs, hashes, length, exclude = [], concurrency, timeout, onProgressCallback) {
-    const fetchOne = (hash) => EntryIO.fetchAll(ipfs, hash, length, exclude, timeout, onProgressCallback)
-    const concatArrays = (arr1, arr2) => arr1.concat(arr2)
-    const flatten = (arr) => arr.reduce(concatArrays, [])
-    return pMap(hashes, fetchOne, { concurrency: Math.max(concurrency || hashes.length, 1) })
-      .then(flatten) // Flatten the results
-  }
-
-  /**
-   * Fetch log entries sequentially
-   *
-   * @param {IPFS} [ipfs] An IPFS instance
-   * @param {string} [hash] Multihash of the entry to fetch
-   * @param {string} [parent] Parent of the node to be fetched
-   * @param {Object} [all] Entries to skip
-   * @param {Number} [amount=-1] How many entries to fetch
-   * @param {Number} [depth=0] Current depth of the recursion
-   * @param {function(hash, entry, parent, depth)} onProgressCallback
-   * @returns {Promise<Array<Entry>>}
-   */
-  static async fetchAll (ipfs, hashes, amount, exclude = [], timeout = null, onProgressCallback, onStartProgressCallback, concurrency = 32, delay = 0) {
-    let result = []
-    let cache = {}
-    let loadingCache = {}
-    let loadingQueue = Array.isArray(hashes)
-      ? {0: hashes.slice()}
-      : {0: [hashes]}
-
-    // Add a multihash to the loading queue
-    const addToLoadingQueue = (e, idx) => {
-      if (!loadingCache[e]) {
-        if (!loadingQueue[idx]) loadingQueue[idx] = []
-        if (!loadingQueue[idx].includes(e)) {
-          loadingQueue[idx].push(e)
-        }
-        loadingCache[e] = idx
-      }
-    }
-
-    // Add entries that we don't need to fetch to the "cache"
-    var addToExcludeCache = e => cache[e.hash] = e
-    exclude.forEach(addToExcludeCache)
-
-    const loadingQueueHasMore = () => Object.values(loadingQueue)
-      .find(e => e && e.length > 0) !== undefined
-
-    const shouldFetchMore = () => {
-      return loadingQueueHasMore()
-          && (result.length < amount || amount < 0)
-    }
-
-    const getNextFromQueue = (length = 1) => {
-      const all = Object.values(loadingQueue).reduce((res, acc) => {
-        while (acc.length > 0 && res.length < length) {
-          const e = acc.shift()
-          res.push(e)
-        }
-        return res
-      }, [])
-      return all
-    }
-
-    const fetchEntry = (entryHash) => {
-      const hash = entryHash
-
-      if (!hash || cache[hash]) {
-        return Promise.resolve()
-      }
-
-      return new Promise((resolve, reject) => {
-        // Resolve the promise after a timeout (if given) in order to
-        // not get stuck loading a block that is unreachable
-        // const timer = timeout 
-        // ? setTimeout(() => {
-        //     console.warn(`Warning: Couldn't fetch entry '${hash}', request timed out (${timeout}ms)`)
-        //     resolve()
-        //   } , timeout) 
-        // : null
-
-        const sleep = (ms = 0) => new Promise(resolve => setTimeout(resolve, ms))
-
-        const addToResults = (entry) => {
-          // clearTimeout(timer)
-          if (Entry.isEntry(entry)) {
-            try {
-              entry.next.forEach(addToLoadingQueue)
-              entry.refs.forEach(addToLoadingQueue)
-
-              result.push(entry)
-              cache[hash] = entry
-              if (onProgressCallback) {
-                onProgressCallback(hash, entry, result.length, result, loadingQueue)
-              }
-            } catch (e) {
-              console.error(e)
-            }
-          }
-        }
-
-        if (onStartProgressCallback) {
-          onStartProgressCallback(hash, null, result.length, result, loadingQueue)
-        }
-
-        // Load the entry
-        Entry.fromMultihash(ipfs, hash)
-          .then(addToResults)
-          .then(async (entry) => {
-            // Simulate network latency
-            if (delay > 0)
-              await sleep(delay)
-
-            return entry
-          })
-          .then(resolve)
-          .catch(err => {
-            resolve()
-          })
-      })
-    }
-
-    let running = 0
-    const _processQueue = async () => {
-      if (running < concurrency) {
-        const nexts = getNextFromQueue(concurrency)
-        running += nexts.length
-        await pMap(nexts, fetchEntry)
-        running -= nexts.length
-      }
-    }
-
-    await pDoWhilst(async () => await _processQueue(), shouldFetchMore)
-
-    // Free memory to avoid minor GC
-    cache = {}
-    loadingCache = {}
-    loadingQueue = []
-
-    return result
-  }
-}
-
-module.exports = EntryIO
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/entry.js
+++ /dev/null
@@ -1,191 +0,0 @@
-'use strict'
-
-const Clock = require('./lamport-clock')
-const isDefined = require('./utils/is-defined')
-
-const IpfsNotDefinedError = () => new Error('Ipfs instance not defined')
-
-class Entry {
-  /**
-   * Create an Entry
-   * @param {IPFS} ipfs - An IPFS instance
-   * @param {string|Buffer|Object|Array} data - Data of the entry to be added. Can be any JSON.stringifyable data.
-   * @param {Array<Entry|string>} [next=[]] Parents of the entry
-   * @example
-   * const entry = await Entry.create(ipfs, 'hello')
-   * console.log(entry)
-   * // { hash: "Qm...Foo", payload: "hello", next: [] }
-   * @returns {Promise<Entry>}
-   */
-  static async create (ipfs, keystore, id, data, next = [], clock, signKey, refs = []) {
-    if (!isDefined(ipfs)) throw IpfsNotDefinedError()
-    if (!isDefined(id)) throw new Error('Entry requires an id')
-    if (!isDefined(data)) throw new Error('Entry requires data')
-    if (!isDefined(next) || !Array.isArray(next)) throw new Error("'next' argument is not an array")
-
-    // Clean the next objects and convert to hashes
-    const toEntry = (e) => e.hash ? e.hash : e
-    let nexts = next.filter(isDefined)
-      .map(toEntry)
-
-    // Take the id of the given clock by default,
-    // if clock not given, take the signing key if it's a Key instance,
-    // or if none given, take the id as the clock id
-    const clockId = clock ? clock.id : (signKey ? signKey.getPublic('hex') : id)
-    const clockTime = clock ? clock.time : null
-
-    let entry = {
-      hash: null, // "Qm...Foo", we'll set the hash after persisting the entry
-      id: id, // For determining a unique chain
-      payload: data, // Can be any JSON.stringifyable data
-      next: nexts, // Array of Multihashes
-      refs: refs,
-      v: 0, // For future data structure updates, should currently always be 0
-      clock: new Clock(clockId, clockTime),
-    }
-
-    // If signing key was passedd, sign the enrty
-    if (keystore && signKey) {
-      entry = await Entry.signEntry(keystore, entry, signKey) 
-    }
-
-    entry.hash = await Entry.toMultihash(ipfs, entry)
-    return entry
-  }
-
-  static async signEntry (keystore, entry, key) {
-    const signature = await keystore.sign(key, Buffer.from(JSON.stringify(entry)))
-    entry.sig = signature
-    entry.key = key.getPublic('hex')
-    return entry
-  }
-
-  static async verifyEntry (entry, keystore) {
-    const e = Object.assign({}, {
-      hash: null,
-      id: entry.id,
-      payload: entry.payload,
-      next: entry.next,
-      refs: entry.refs,
-      v: entry.v,
-      clock: entry.clock,
-    })
-
-    const pubKey = await keystore.importPublicKey(entry.key)
-    await keystore.verify(entry.sig, pubKey, Buffer.from(JSON.stringify(e)))
-  }
-
-  /**
-   * Get the multihash of an Entry
-   * @param {IPFS} [ipfs] An IPFS instance
-   * @param {Entry} [entry] Entry to get a multihash for
-   * @example
-   * const hash = await Entry.toMultihash(ipfs, entry)
-   * console.log(hash)
-   * // "Qm...Foo"
-   * @returns {Promise<string>}
-   */
-  static toMultihash (ipfs, entry) {
-    if (!ipfs) throw IpfsNotDefinedError()
-    const data = Buffer.from(JSON.stringify(entry))
-    return ipfs.object.put(data)
-      .then((res) => res.toJSON().multihash)
-  }
-
-  /**
-   * Create an Entry from a multihash
-   * @param {IPFS} [ipfs] An IPFS instance
-   * @param {string} [hash] Multihash as Base58 encoded string to create an Entry from
-   * @example
-   * const hash = await Entry.fromMultihash(ipfs, "Qm...Foo")
-   * console.log(hash)
-   * // { hash: "Qm...Foo", payload: "hello", next: [] }
-   * @returns {Promise<Entry>}
-   */
-  static fromMultihash (ipfs, hash) {
-    if (!ipfs) throw IpfsNotDefinedError()
-    if (!hash) throw new Error(`Invalid hash: ${hash}`)
-    return ipfs.object.get(hash, { enc: 'base58' })
-      .then((obj) => JSON.parse(obj.toJSON().data))
-      .then((data) => {
-        let entry = {
-          hash: hash,
-          id: data.id,
-          payload: data.payload,
-          next: data.next,
-          refs: data.refs,
-          v: data.v,
-          clock: data.clock,
-        }
-        if (data.sig) Object.assign(entry, { sig: data.sig })
-        if (data.key) Object.assign(entry, { key: data.key })
-        return entry
-      })
-  }
-
-  /**
-   * Check if an object is an Entry
-   * @param {Entry} obj
-   * @returns {boolean}
-   */
-  static isEntry (obj) {
-    return obj.id !== undefined
-      && obj.next !== undefined
-      && obj.refs !== undefined
-      && obj.hash !== undefined
-      && obj.payload !== undefined
-      && obj.v !== undefined
-      && obj.clock !== undefined
-  }
-
-  static compare (a, b) {
-    var distance = Clock.compare(a.clock, b.clock)
-    if (distance === 0) return a.clock.id < b.clock.id ? -1 : 1
-    return distance
-  }
-
-  /**
-   * Check if an entry equals another entry
-   * @param {Entry} a
-   * @param {Entry} b
-   * @returns {boolean}
-   */
-  static isEqual (a, b) {
-    return a.hash === b.hash
-  }
-
-  /**
-   * Check if an entry is a parent to another entry.
-   * @param {Entry} [entry1] Entry to check
-   * @param {Entry} [entry2] Parent
-   * @returns {boolean}
-   */
-  static isParent (entry1, entry2) {
-    return entry2.next.indexOf(entry1.hash) > -1
-  }
-
-  /**
-   * Find entry's children from an Array of entries
-   *
-   * @description
-   * Returns entry's children as an Array up to the last know child.
-   *
-   * @param {Entry} [entry] Entry for which to find the parents
-   * @param {Array<Entry>} [vaules] Entries to search parents from
-   * @returns {Array<Entry>}
-   */
-  static findChildren (entry, values) {
-    var stack = []
-    var parent = values.find((e) => Entry.isParent(entry, e))
-    var prev = entry
-    while (parent) {
-      stack.push(parent)
-      prev = parent
-      parent = values.find((e) => Entry.isParent(prev, e))
-    }
-    stack = stack.sort((a, b) => a.clock.time > a.clock.time)
-    return stack
-  }
-}
-
-module.exports = Entry
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/g-set.js
+++ /dev/null
@@ -1,20 +0,0 @@
-'use strict'
-
-/**
- * Interface for G-Set CRDT
- *
- * From:
- * "A comprehensive study of Convergent and Commutative Replicated Data Types"
- * https://hal.inria.fr/inria-00555588
- */
-class GSet {
-  constuctor (values) {}
-  append (value) {}
-  merge (set) {}
-  get (value) {}
-  has (value) {}
-  get values () {}
-  get length () {}
-}
-
-module.exports = GSet
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/lamport-clock.js
+++ /dev/null
@@ -1,34 +0,0 @@
-'use strict'
-
-class LamportClock {
-  constructor (id, time) {
-    this.id = id
-    this.time = time || 0
-  }
-
-  tick () {
-    return new LamportClock(this.id, ++this.time)
-  }
-
-  merge (clock) {
-    this.time = Math.max(this.time, clock.time)
-    return new LamportClock(this.id, this.time)
-  }
-
-  clone () {
-    return new LamportClock(this.id, this.time)
-  }
-
-  static compare (a, b) {
-    // Calculate the "distance" based on the clock, ie. lower or greater
-    var dist = a.time - b.time
-
-    // If the sequence number is the same (concurrent events),
-    // and the IDs are different, take the one with a "lower" id
-    if (dist === 0 && a.id !== b.id) return a.id < b.id ? -1 : 1
-
-    return dist
-  }
-}
-
-module.exports = LamportClock
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/log-errors.js
+++ /dev/null
@@ -1,11 +0,0 @@
-'use strict'
-
-const ImmutableDBNotDefinedError = () => new Error('ImmutableDB instance not defined')
-const LogNotDefinedError = () => new Error('Log instance not defined')
-const NotALogError = () => new Error('Given argument is not an instance of Log')
-
-module.exports = {
-  ImmutableDBNotDefinedError: ImmutableDBNotDefinedError,
-  LogNotDefinedError: LogNotDefinedError,
-  NotALogError: NotALogError,
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/log-io.js
+++ /dev/null
@@ -1,166 +0,0 @@
-'use strict'
-
-const pMap = require('p-map')
-const Entry = require('./entry')
-const EntryIO = require('./entry-io')
-const Clock = require('./lamport-clock')
-const LogError = require('./log-errors')
-const isDefined = require('./utils/is-defined')
-const _uniques = require('./utils/uniques')
-const intersection = require('./utils/intersection')
-const difference = require('./utils/difference')
-
-const last = (arr, n) => arr.slice(arr.length - n, arr.length)
-const uniqueEntriesReducer = (res, acc) => {
-  res[acc.hash] = acc
-  return res
-}
-
-class LogIO {
-  static toMultihash (ipfs, log) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(log)) throw LogError.LogNotDefinedError()
-
-    if (log.values.length < 1) throw new Error(`Can't serialize an empty log`)
-
-    return ipfs.object.put(log.toBuffer())
-      .then((dagNode) => dagNode.toJSON().multihash)
-  }
-
-  /**
-   * Create a log from multihash
-   * @param {IPFS} ipfs - An IPFS instance
-   * @param {string} hash - Multihash (as a Base58 encoded string) to create the log from
-   * @param {Number} [length=-1] - How many items to include in the log
-   * @param {function(hash, entry, parent, depth)} onProgressCallback
-   * @returns {Promise<Log>}
-   */
-  static async fromMultihash (ipfs, hash, length = -1, exclude, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(hash)) throw new Error(`Invalid hash: ${hash}`)
-
-    const dagNode = await ipfs.object.get(hash, { enc: 'base58' })
-    const logData = JSON.parse(dagNode.toJSON().data)
-
-    if (!logData.heads || !logData.id) throw LogError.NotALogError()
-
-    const entries = await EntryIO.fetchParallel(ipfs, logData.heads, length, exclude, null, null, onProgressCallback)
-
-    const uniques = Object.values(entries.reduce(uniqueEntriesReducer, {}))
-
-    // Find latest clock
-    const clock = uniques.reduce((clock, entry) => {
-      return entry.clock.time > clock.time
-        ? new Clock(entry.clock.id, entry.clock.time)
-        : clock
-    }, new Clock(logData.id))
-
-    // Cut the entries to the requested size
-    const finalEntries = length > -1 
-      ? last(uniques.sort(Entry.compare), length)
-      : uniques
-
-    // Find the head entries
-    const heads = finalEntries.filter(e => logData.heads.includes(e.hash))
-
-    return {
-      id: logData.id,
-      values: finalEntries,
-      heads: heads,
-      clock: clock,
-    }
-  }
-
-  static fromEntryHash (ipfs, entryHash, id, length = -1, exclude, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.IpfsNotDefinedError()
-    if (!isDefined(entryHash)) throw new Error("'entryHash' must be defined")
-
-    // Fetch given length, return size at least the given input entries
-    length = length > -1 ? Math.max(length, 1) : length
-
-    // Make sure we pass hashes instead of objects to the fetcher function
-    const excludeHashes = exclude// ? exclude.map(e => e.hash ? e.hash : e) : exclude
-
-    return EntryIO.fetchParallel(ipfs, [entryHash], length, excludeHashes, null, null, onProgressCallback)
-      .then((entries) => {
-        // Cap the result at the right size by taking the last n entries,
-        // or if given length is -1, then take all
-        const sliced = length > -1 ? last(entries, length) : entries
-        return {
-          values: sliced,
-        }
-      })
-  }
-
-  static fromJSON (ipfs, json, length = -1, key, timeout, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    return EntryIO.fetchParallel(ipfs, json.heads.map(e => e.hash), length, [], 16, timeout, onProgressCallback)
-      .then((entries) => {
-        const finalEntries = entries.slice().sort(Entry.compare)
-        const heads = entries.filter(e => json.heads.includes(e.hash))
-        return {
-          id: json.id,
-          values: finalEntries,
-          heads: json.heads,
-        }
-      })
-  }
-
-  /**
-   * Create a new log starting from an entry
-   * @param {IPFS} ipfs An IPFS instance
-   * @param {Array<Entry>} entries An entry or an array of entries to fetch a log from
-   * @param {Number} [length=-1] How many entries to include. Default: infinite.
-   * @param {Array<Entry|string>} [exclude] Entries to not fetch (cached)
-   * @param {function(hash, entry, parent, depth)} [onProgressCallback]
-   * @returns {Promise<Log>}
-   */
-  static fromEntry (ipfs, sourceEntries, length = -1, exclude, key, keys, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(sourceEntries)) throw new Error("'sourceEntries' must be defined")
-
-    // Make sure we only have Entry objects as input
-    if (!Array.isArray(sourceEntries) && !Entry.isEntry(sourceEntries)) {
-      throw new Error(`'sourceEntries' argument must be an array of Entry instances or a single Entry`)
-    }
-
-    if (!Array.isArray(sourceEntries)) {
-      sourceEntries = [sourceEntries]
-    }
-
-    // Fetch given length, return size at least the given input entries
-    length = length > -1 ? Math.max(length, sourceEntries.length) : length
-
-    // Make sure we pass hashes instead of objects to the fetcher function
-    const excludeHashes = exclude ? exclude.map(e => e.hash ? e.hash : e) : exclude
-    const hashes = sourceEntries.map(e => e.hash)
-
-    return EntryIO.fetchParallel(ipfs, hashes, length, excludeHashes, null, null, onProgressCallback)
-      .then((entries) => {
-        var combined = sourceEntries.concat(entries)
-        var uniques = _uniques(combined, 'hash').sort(Entry.compare)
-
-        // Cap the result at the right size by taking the last n entries
-        const sliced = uniques.slice(length > -1 ? -length : -uniques.length)
-
-        // Make sure that the given input entries are present in the result
-        // in order to not lose references
-        const missingSourceEntries = difference(sliced, sourceEntries, 'hash')
-
-        const replaceInFront = (a, withEntries) => {
-          var sliced = a.slice(withEntries.length, a.length)
-          return withEntries.concat(sliced)
-        }
-
-        // Add the input entries at the beginning of the array and remove
-        // as many elements from the array before inserting the original entries
-        const result = replaceInFront(sliced, missingSourceEntries)
-        return {
-          id: result[result.length - 1].id,
-          values: result,
-        }
-      })
-  }
-}
-
-module.exports = LogIO
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/log.js
+++ /dev/null
@@ -1,717 +0,0 @@
-'use strict'
-
-const pMap = require('p-map')
-const GSet = require('./g-set')
-const Entry = require('./entry')
-const EntryIO = require('./entry-io')
-const LogIO = require('./log-io')
-const LogError = require('./log-errors')
-const Clock = require('./lamport-clock')
-const MemStore = require('./utils/mem-store')
-const isDefined = require('./utils/is-defined')
-const _uniques = require('./utils/uniques')
-
-const randomId = () => new Date().getTime().toString()
-const getHash = e => e.hash
-const flatMap = (res, acc) => res.concat(acc)
-const getNextPointers = entry => entry.next
-const getFirstNextPointer = entry => entry.next[0]
-const maxClockTimeReducer = (res, acc) => Math.max(res, acc.clock.time)
-const uniqueEntriesReducer = (res, acc) => {
-  res[acc.hash] = acc
-  return res
-}
-
-/**
- * Log
- *
- * @description
- * Log implements a G-Set CRDT and adds ordering
- *
- * From:
- * "A comprehensive study of Convergent and Commutative Replicated Data Types"
- * https://hal.inria.fr/inria-00555588
- */
-class Log extends GSet {
-  /**
-   * Create a new Log instance
-   * @param  {IPFS}           ipfs    An IPFS instance
-   * @param  {String}         id      ID of the log
-   * @param  {[Array<Entry>]} entries An Array of Entries from which to create the log from
-   * @param  {[Array<Entry>]} heads   Set the heads of the log
-   * @param  {[Clock]}        clock   Set the clock of the log
-   * @return {Log}            Log
-   */
-  constructor (ipfs, id, entries, heads, clock, key, keys = [], nextsIndex = new Map()) {
-    if (!isDefined(ipfs)) {
-      throw LogError.ImmutableDBNotDefinedError()
-    }
-
-    if (isDefined(entries) && !Array.isArray(entries)) {
-      throw new Error(`'entries' argument must be an array of Entry instances`)
-    }
-
-    if (isDefined(heads) && !Array.isArray(heads)) {
-      throw new Error(`'heads' argument must be an array`)
-    }
-
-    super()
-
-    this._storage = ipfs
-    this._id = id || randomId()
-
-    // Signing related setup
-    this._keystore = this._storage.keystore
-    this._key = key
-    this._keys = Array.isArray(keys) ? keys : [keys]
-
-    // Add entries to the internal cache
-    entries = entries || []
-    //this._entryIndex = entries.reduce(uniqueEntriesReducer, {})
-
-    // Set heads if not passed as an argument
-    heads = heads || Log.findHeads(entries)
-    this._headsIndex = heads.reduce(uniqueEntriesReducer, {})
-
-    // Index of all next pointers in this log
-    this._nextsIndex = nextsIndex
-    entries.forEach(e => this._nextsIndex.set(e.hash, e.next[0]))
-
-    // Set the length, we calculate the length manually internally
-    if (isDefined(entries) && Array.isArray(entries)) {
-      this._length = entries.length
-    } else if (isDefined(nextsIndex)) {
-      this._length = nextsIndex.size
-    } else {
-      this._length = 0
-    }
-
-    // Set the clock
-    const maxTime = Math.max(clock ? clock.time : 0, this.heads.reduce(maxClockTimeReducer, 0))
-    // Take the given key as the clock id is it's a Key instance,
-    // otherwise if key was given, take whatever it is,
-    // and if it was null, take the given id as the clock id
-    const clockId = (key && key.getPublic) ? key.getPublic('hex') : (key ? key : this._id)
-    this._clock = new Clock(clockId, maxTime)
-  }
-
-  /**
-   * Returns the ID of the log
-   * @returns {string}
-   */
-  get id () {
-    return this._id
-  }
-
-  /**
-   * Returns the clock of the log
-   * @returns {string}
-   */
-  get clock () {
-    return this._clock
-  }
-
-  /**
-   * Returns the length of the log
-   * @return {Number} Length
-   */
-  get length () {
-    return this._length
-  }
-
-  /**
-   * Returns the values in the log
-   * @returns {Array<Entry>}
-   */
-  async values () {
-    let entries = []
-    for (const [entryHash, nextHash] of this._nextsIndex) {
-      const entry = await this.get(entryHash)
-      entries.push(entry)
-    }
-    return entries.sort(Entry.compare)
-  }
-
-  /**
-   * Returns an array of heads as multihashes
-   * @returns {Array<string>}
-   */
-  get heads () {
-    return Object.values(this._headsIndex) || []
-  }
-
-  /**
-   * Returns an array of Entry objects that reference entries which
-   * are not in the log currently
-   * @returns {Array<Entry>}
-   */
-  async tails () {
-    const tailHashes = this.tailHashes
-    const tails = await pMap(tailHashes, hash => this.get(hash))
-    return tails
-  }
-
-  /**
-   * Returns an array of multihashes that are referenced by entries which
-   * are not in the log currently
-   * @returns {Array<string>} Array of multihashes
-   */
-  get tailHashes () {
-    const entries = Array.from(this._nextsIndex.keys())
-    let tailHashes = []
-    for (const [entryHash, nextHash] of this._nextsIndex) {
-      if (entries.indexOf(nextHash) < 0) {
-        tailHashes.push(entryHash)
-      }
-    }
-    return tailHashes
-  }
-
-  /**
-   * Find an entry
-   * @param {string} [hash] The Multihash of the entry as Base58 encoded string
-   * @returns {Entry|undefined}
-   */
-  async get (hash) {
-    const entry = await Entry.fromMultihash(this._storage, hash)
-    return entry
-  }
-
-  has (entry = {}) {
-    return this._nextsIndex.has(entry.hash || entry)
-  }
-
-  async traverse (rootEntries, amount, getNexts) {
-    // console.log("traverse>", rootEntries)
-    let stack = rootEntries.map(getNexts).reduce(flatMap, [])
-    let traversed = {}
-    let result = {}
-    let count = 0
-
-    const addToStack = hash => {
-      if (!result[hash] && !traversed[hash]) {
-        stack.push(hash)
-        traversed[hash] = true
-      }
-    }
-
-    const addRootHash = rootEntry => {
-      result[rootEntry.hash] = rootEntry
-      traversed[rootEntry.hash] = true
-      count ++
-    }
-
-    rootEntries.forEach(addRootHash)
-
-    while (stack.length > 0 && count < amount) {
-      const hash = stack.shift()
-      const entry = await this.get(hash)
-      if (entry) {
-        count ++
-        result[entry.hash] = entry
-        traversed[entry.hash] = true
-        entry.next.forEach(addToStack)
-      }
-    }
-    // Free memory
-    // This seems to get rid of a lot of small GC happening
-    // during an append. Why?
-    stack = []
-    traversed = {}
-    return result
-  }
-
-  traverseNexts (rootEntries, amount, getNexts) {
-    // console.log("traverse>", rootEntries)
-    let stack = rootEntries.map(getNexts).reduce(flatMap, [])
-    let traversed = {}
-    let result = []
-    let count = 0
-
-    const addToStack = hash => {
-      if (!traversed[hash] && result.indexOf(hash) === -1) {
-        stack.push(hash)
-        traversed[hash] = true
-      }
-    }
-
-    const addRootHash = rootEntry => {
-      result.push(rootEntry.hash)
-      traversed[rootEntry.hash] = true
-      count ++
-    }
-
-    rootEntries.forEach(addRootHash)
-
-    while (stack.length > 0 && count < amount) {
-      const hash = stack.shift()
-      const hasEntry = this._nextsIndex.has(hash)
-      if (hasEntry) {
-        count ++
-        result.push(hash)
-        traversed[hash] = true
-        //addToStack(getKeyByValue(this._nextsIndex, hash))
-        addToStack(this._nextsIndex.get(hash))
-        //entry.next.forEach(addToStack)
-      }
-    }
-    // Free memory
-    // This seems to get rid of a lot of small GC happening
-    // during an append. Why?
-    stack = []
-    traversed = {}
-    return result
-  }
-
-  /**
-   * Append an entry to the log
-   * @param  {Entry} entry Entry to add
-   * @return {Log}   New Log containing the appended value
-   */
-  async append (data, pointerCount = 1) {
-    // Verify that we're allowed to append
-    if ((this._key && this._key.getPublic)
-        && !this._keys.includes(this._key.getPublic('hex'))
-        && !this._keys.includes('*')) {
-      throw new Error("Not allowed to write")
-    }
-
-    // Update the clock (find the latest clock)
-    const newTime = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0)) + 1
-    this._clock = new Clock(this.clock.id, newTime)
-
-    // Get the heads
-    /* const nexts = Object.values(this.traverse(this.heads, this.heads.length, getNextPointers))
-     *                     .sort((a, b) => a.clock.time > b.clock.time)
-     *                     .map(e => e.hash)     */
-
-    const sortHeads = this.heads.sort((a, b) => a.clock.time > b.clock.time)
-    const nexts = sortHeads.map((h) => {
-      return h.hash
-    })
-
-    // Get the required amount of hashes to next entries (as per current state of the log)
-    // const all = Object.values(this.traverse(this.heads, pointerCount, getFirstNextPointer))
-    const all = this.traverseNexts(this.heads, pointerCount, getFirstNextPointer)
-
-
-    // Get entries of pow2 at maxDistance (2nd, 4th, 8th, 16th, ...)
-    const getEveryPow2 = (maxDistance) => {
-      const entries = new Set()
-      for (let i = 1; i <= maxDistance; i *= 2) {
-        const index = Math.min(i - 1, all.length - 1)
-        const ref = all[index]
-        entries.add(ref)
-      }
-      return entries
-    }
-
-    // If pointer count is 4, returns 2
-    // If pointer count is 8, returns 3 references
-    // If pointer count is 512, returns 9 references
-    // If pointer count is 2048, returns 11 references
-    const references = getEveryPow2(Math.min(pointerCount, all.length))
-    let refSet = new Set(references)
-
-    // Always include the last known reference
-    if (all.length < pointerCount && all[all.length - 1])
-      refSet.add(all[all.length - 1])
-
-    // Delete the heads from the refs
-    const delRef = e => refSet.delete(e)
-    nexts.forEach(delRef)
-    //const refs = Array.from(refSet).map(getHash)
-    const refs = Array.from(refSet)
-
-    // Create the entry and add it to the internal cache
-    const entry = await Entry.create(this._storage, this._keystore, this.id, data, nexts, this.clock, this._key, refs)
-    //this._entryIndex[entry.hash] = entry
-    //nexts.forEach(e => this._nextsIndex[e] = entry.hash)
-    this._nextsIndex.set(entry.hash, nexts[0])
-    this._headsIndex = {}
-    this._headsIndex[entry.hash] = entry
-    // Update the internal length counter
-    this._length ++
-    return entry
-  }
-
-  /**
-   * Join two logs
-   *
-   * @description Joins two logs returning a new log. Doesn't mutate the original logs.
-   *
-   * @param {IPFS}   [ipfs] An IPFS instance
-   * @param {Log}    log    Log to join with this Log
-   * @param {Number} [size] Max size of the joined log
-   * @param {string} [id]   ID to use for the new log
-   *
-   * @example
-   * log1.join(log2)
-   *
-   * @returns {Promise<Log>}
-   */
-  async join (log, size = -1) {
-    if (!isDefined(log)) throw LogError.LogNotDefinedError()
-    if (!Log.isLog(log)) throw LogError.NotALogError()
-
-    // Verify the entries
-    // TODO: move to Entry
-    const verifyEntries = async (entries) => {
-      const isTrue = e => e === true
-      const getPubKey = e => e.getPublic ? e.getPublic('hex') : e
-      const checkAllKeys = (keys, entry) => {
-        const keyMatches = e => e === entry.key
-        return keys.find(keyMatches)
-      }
-      const pubkeys = this._keys.map(getPubKey)
-
-      const verify = async (entry) => {
-        if (!entry.key) throw new Error("Entry doesn't have a public key")
-        if (!entry.sig) throw new Error("Entry doesn't have a signature")
-
-        if (this._keys.length === 1 && this._keys[0] === this._key ) {
-          if (entry.id !== this.id)
-            throw new Error("Entry doesn't belong in this log (wrong ID)")
-        }
-
-        if (this._keys.length > 0
-            && !this._keys.includes('*')
-            && !checkAllKeys(this._keys.concat([this._key]), entry)) {
-          console.warn("Warning: Input log contains entries that are not allowed in this log. Logs weren't joined.")
-          return false
-        }
-
-        try {
-          await Entry.verifyEntry(entry, this._keystore)
-        } catch (e) {
-          throw new Error(`Invalid signature in entry '${entry.hash}'`)
-        }
-
-        return true
-      }
-
-      const checked = await pMap(entries, verify)
-      return checked.every(isTrue)
-    }
-
-    //TODO: use nextsIndex to find differences (avoid log.get)
-    const difference = async (log, exclude) => {
-      let stack = Object.keys(log._headsIndex)
-      let traversed = {}
-      let res = new Map()
-
-      const pushToStack = hash => {
-        if (!traversed[hash] && !exclude.has(hash)) {
-          stack.push(hash)
-          traversed[hash] = true
-        }
-      }
-
-      while (stack.length > 0) {
-        const hash = stack.shift()
-        const hasEntry = log.has(hash)
-        if (hasEntry && !exclude.has(hash)) {
-          const nextHash = log._nextsIndex.get(hash)
-          res.set(hash, nextHash)
-          traversed[hash] = true
-          if (nextHash) pushToStack(nextHash)
-        }
-      }
-      return new Map([...res].reverse())
-    }
-
-    // Merge the entries
-    const newItems = await difference(log, this)
-
-    // if a key was given, verify the entries from the incoming log
-    /* if (this._key && this._key.getPublic) {
-     *   const canJoin = await verifyEntries(Object.values(newItems))
-     *   // Return early if any of the given entries didn't verify
-     *   if (!canJoin)
-     *     return this
-     * }
-     */
-    // Update the internal entry index
-    //this._entryIndex = Object.assign(this._entryIndex, newItems)
-
-    // Update the internal next pointers index - TODO: without entries
-    this._nextsIndex = new Map([...this._nextsIndex, ...newItems])
-
-    // Update the length
-    this._length += newItems.size
-
-    // Slice to the requested size
-    /* if (size > -1) {
-     *   let tmp = this.values //TODO: don't use this.values
-     *   tmp = tmp.slice(-size)
-     *   this._entryIndex = tmp.reduce(uniqueEntriesReducer, {})
-     *   this._length = Object.values(this._entryIndex).length
-     * }
-     */
-
-    // Merge the heads
-    const notReferencedByNewItems = e => !nextsFromNewItems.find(a => a === e.hash)
-    const nextValues = Array.from(this._nextsIndex.values()).filter(value => value)
-    const nexts = {}
-    nextValues.forEach(value => nexts[value] = true)
-    //const nexts = new Map(Array.from(this._nextsIndex.values()).map(e => { e : true }))
-    const notInCurrentNexts = e => !nexts[e.hash]
-    const nextsFromNewItems = Array.from(newItems.values()).filter(e => e !== undefined)
-    const mergedHeads = Log.findHeads(Object.values(Object.assign({}, this._headsIndex, log._headsIndex)))
-      .filter(notReferencedByNewItems)
-      .filter(notInCurrentNexts)
-      .reduce(uniqueEntriesReducer, {})
-
-    this._headsIndex = mergedHeads
-
-    // Find the latest clock from the heads
-    const maxClock = Object.values(this._headsIndex).reduce(maxClockTimeReducer, 0)
-    this._clock = new Clock(this.clock.id, Math.max(this.clock.time, maxClock))
-    return this
-  }
-
-  /**
-   * Get the log in JSON format
-   * @returns {Object<{heads}>}
-   */
-  toJSON () {
-    return {
-      id: this.id,
-      heads: this.heads.map(getHash),
-      nexts: this._nextsIndex.entries()
-    }
-  }
-
-  toSnapshot () {
-    return {
-      id: this.id,
-      heads: this.heads,
-      //values: this.values,
-      nexts: this._nextsIndex.entries()
-    }
-  }
-  /**
-   * Get the log as a Buffer
-   * @returns {Buffer}
-   */
-  toBuffer () {
-    return Buffer.from(JSON.stringify(this.toJSON()))
-  }
-
-  /**
-   * Returns the log entries as a formatted string
-   * @example
-   * two
-   * └─one
-   *   └─three
-   * @returns {string}
-   */
-  toString (payloadMapper) {
-    return this.values
-      .slice()
-      .reverse()
-      .map((e, idx) => {
-        const parents = Entry.findChildren(e, this.values)
-        const len = parents.length
-        let padding = new Array(Math.max(len - 1, 0))
-        padding = len > 1 ? padding.fill('  ') : padding
-        padding = len > 0 ? padding.concat(['└─']) : padding
-        return padding.join('') + (payloadMapper ? payloadMapper(e.payload) : e.payload)
-      })
-      .join('\n')
-  }
-
-  /**
-   * Check whether an object is a Log instance
-   * @param {Object} log An object to check
-   * @returns {true|false}
-   */
-  static isLog (log) {
-    return log.id !== undefined
-      && log.heads !== undefined
-  }
-
-  /**
-   * Get the log's multihash
-   * @returns {Promise<string>} Multihash of the Log as Base58 encoded string
-   */
-  toMultihash () {
-    return LogIO.toMultihash(this._storage, this)
-  }
-
-  /**
-   * Create a log from multihash
-   * @param {IPFS}   ipfs        An IPFS instance
-   * @param {string} hash        Multihash (as a Base58 encoded string) to create the log from
-   * @param {Number} [length=-1] How many items to include in the log
-   * @param {Function(hash, entry, parent, depth)} onProgressCallback
-   * @return {Promise<Log>}      New Log
-   */
-  static fromMultihash (ipfs, hash, length = -1, exclude, key, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(hash)) throw new Error(`Invalid hash: ${hash}`)
-
-    // TODO: need to verify the entries with 'key'
-    return LogIO.fromMultihash(ipfs, hash, length, exclude, onProgressCallback)
-      .then((data) => new Log(ipfs, data.id, data.values, data.heads, data.clock, key))
-  }
-
-  /**
-   * Create a log from a single entry's multihash
-   * @param {IPFS}   ipfs        An IPFS instance
-   * @param {string} hash        Multihash (as a Base58 encoded string) of the Entry from which to create the log from
-   * @param {Number} [length=-1] How many entries to include in the log
-   * @param {Function(hash, entry, parent, depth)} onProgressCallback
-   * @return {Promise<Log>}      New Log
-   */
-  static fromEntryHash (ipfs, hash, id, length = -1, exclude, key, keys, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(hash)) throw new Error("'hash' must be defined")
-
-    // TODO: need to verify the entries with 'key'
-    return LogIO.fromEntryHash(ipfs, hash, id, length, exclude, onProgressCallback)
-      .then((data) => new Log(ipfs, id, data.values, null, null, key, keys))
-  }
-
-  /**
-   * Create a log from a Log Snapshot JSON
-   * @param {IPFS} ipfs          An IPFS instance
-   * @param {Object} json        Log snapshot as JSON object
-   * @param {Number} [length=-1] How many entries to include in the log
-   * @param {Function(hash, entry, parent, depth)} [onProgressCallback]
-   * @return {Promise<Log>}      New Log
-   */
-  static fromJSON (ipfs, json, length = -1, key, keys, timeout, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-
-    // TODO: need to verify the entries with 'key'
-    return LogIO.fromJSON(ipfs, json, length, key, timeout, onProgressCallback)
-      .then((data) => new Log(ipfs, data.id, data.values, null, null, key, keys))
-  }
-
-  /**
-   * Create a new log from an Entry instance
-   * @param {IPFS}                ipfs          An IPFS instance
-   * @param {Entry|Array<Entry>}  sourceEntries An Entry or an array of entries to fetch a log from
-   * @param {Number}              [length=-1]   How many entries to include. Default: infinite.
-   * @param {Array<Entry|string>} [exclude]     Array of entries or hashes or entries to not fetch (foe eg. cached entries)
-   * @param {Function(hash, entry, parent, depth)} [onProgressCallback]
-   * @return {Promise<Log>}       New Log
-   */
-  static fromEntry (ipfs, sourceEntries, length = -1, exclude, onProgressCallback) {
-    if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError()
-    if (!isDefined(sourceEntries)) throw new Error("'sourceEntries' must be defined")
-
-    // TODO: need to verify the entries with 'key'
-    return LogIO.fromEntry(ipfs, sourceEntries, length, exclude, onProgressCallback)
-      .then((data) => new Log(ipfs, data.id, data.values))
-  }
-
-  /**
-   * Find heads from a collection of entries
-   *
-   * @description
-   * Finds entries that are the heads of this collection,
-   * ie. entries that are not referenced by other entries
-   *
-   * @param {Array<Entry>} Entries to search heads from
-   * @returns {Array<Entry>}
-   */
-  static findHeads (entries) {
-    var indexReducer = (res, entry, idx, arr) => {
-      var addToResult = e => res[e] = entry.hash
-      entry.next.forEach(addToResult)
-      return res
-    }
-
-    var items = entries.reduce(indexReducer, {})
-
-    var exists = e => items[e.hash] === undefined
-    var compareIds = (a, b) => a.clock.id > b.clock.id
-
-    return entries.filter(exists).sort(compareIds)
-  }
-
-  // Find entries that point to another entry that is not in the
-  // input array
-  static findTails (entries) {
-    // Reverse index { next -> entry }
-    var reverseIndex = {}
-    // Null index containing entries that have no parents (nexts)
-    var nullIndex = []
-    // Hashes for all entries for quick lookups
-    var hashes = {}
-    // Hashes of all next entries
-    var nexts = []
-
-    var addToIndex = (e) => {
-      if (e.next.length === 0) {
-        nullIndex.push(e)
-      }
-      var addToReverseIndex = (a) => {
-        /* istanbul ignore else */
-        if (!reverseIndex[a]) reverseIndex[a] = []
-        reverseIndex[a].push(e)
-      }
-
-      // Add all entries and their parents to the reverse index
-      e.next.forEach(addToReverseIndex)
-      // Get all next references
-      nexts = nexts.concat(e.next)
-      // Get the hashes of input entries
-      hashes[e.hash] = true
-    }
-
-    // Create our indices
-    entries.forEach(addToIndex)
-
-    var addUniques = (res, entries, idx, arr) => res.concat(_uniques(entries, 'hash'))
-    var exists = e => hashes[e] === undefined
-    var findFromReverseIndex = e => reverseIndex[e]
-
-    // Drop hashes that are not in the input entries
-    const tails = nexts // For every multihash in nexts:
-      .filter(exists) // Remove undefineds and nulls
-      .map(findFromReverseIndex) // Get the Entry from the reverse index
-      .reduce(addUniques, []) // Flatten the result and take only uniques
-      .concat(nullIndex) // Combine with tails the have no next refs (ie. first-in-their-chain)
-
-    return _uniques(tails, 'hash').sort(Entry.compare)
-  }
-
-  // Find the hashes to entries that are not in a collection
-  // but referenced by other entries
-  static findTailHashes (entries) {
-    var hashes = {}
-    var addToIndex = (e) => hashes[e.hash] = true
-
-    var reduceTailHashes = (res, entry, idx, arr) => {
-      var addToResult = (e) => {
-        /* istanbul ignore else */
-        if (hashes[e] === undefined) {
-          res.splice(0, 0, e)
-        }
-      }
-      entry.next.reverse().forEach(addToResult)
-      return res
-    }
-
-    entries.forEach(addToIndex)
-    return entries.reduce(reduceTailHashes, [])
-  }
-
-  /* Expose utlities, usable via Log.MemStore */
-  static get MemStore () {
-    return MemStore
-  }
-
-  static get EntryIO () {
-    return EntryIO
-  }
-
-  static get Entry () {
-    return Entry
-  }
-}
-
-module.exports = Log
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/utils/difference.js
+++ /dev/null
@@ -1,26 +0,0 @@
-'use strict'
-
-function difference (a, b, key) {
-  // Indices for quick lookups
-  var processed = {}
-  var existing = {}
-
-  // Create an index of the first collection
-  var addToIndex = e => existing[key ? e[key] : e] = true
-  a.forEach(addToIndex)
-
-  // Reduce to entries that are not in the first collection
-  var reducer = (res, entry) => {
-    var isInFirst = existing[key ? entry[key] : entry] !== undefined
-    var hasBeenProcessed = processed[key ? entry[key] : entry] !== undefined
-    if (!isInFirst && !hasBeenProcessed) {
-      res.push(entry)
-      processed[key ? entry[key] : entry] = true
-    }
-    return res
-  }
-
-  return b.reduce(reducer, [])
-}
-
-module.exports = difference
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/utils/intersection.js
+++ /dev/null
@@ -1,26 +0,0 @@
-'use strict'
-
-function intersection (a, b, key) {
-  // Indices for quick lookups
-  var processed = {}
-  var existing = {}
-
-  // Create an index of the first collection
-  var addToIndex = e => existing[key ? e[key] : e] = true
-  a.forEach(addToIndex)
-
-  // Reduce to entries that are not in the first collection
-  var reducer = (res, entry) => {
-    var isInFirst = existing[key ? entry[key] : entry] !== undefined
-    var hasBeenProcessed = processed[key ? entry[key] : entry] !== undefined
-    if (isInFirst && !hasBeenProcessed) {
-      res.push(entry)
-      processed[key ? entry[key] : entry] = true
-    }
-    return res
-  }
-
-  return b.reduce(reducer, [])
-}
-
-module.exports = intersection
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/utils/is-defined.js
+++ /dev/null
@@ -1,5 +0,0 @@
-'use strict'
-
-const isDefined = (arg) => arg !== undefined && arg !== null
-
-module.exports = isDefined
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/utils/mem-store.js
+++ /dev/null
@@ -1,36 +0,0 @@
-'use strict'
-
-class MemStore {
-  constructor () {
-    this._store = {}
-  }
-
-  async put (data) {
-    const hash = "MEM" + (Math.random() * 100000000).toString()
-    // const hash = await createMultihash(data)
-    if (!this._store) this._store = {}
-    this._store[hash] = data
-    return Promise.resolve({
-      toJSON: () => {
-        return {
-          data: data,
-          multihash: hash,
-        }
-      }
-    })
-  }
-
-  async get (key) {
-    return Promise.resolve({
-      toJSON: () => {
-        return {
-          data: this._store[key],
-          multihash: key,
-        }
-      }
-    })
-  }
-}
-
-
-module.exports = MemStore
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/src/utils/uniques.js
+++ /dev/null
@@ -1,12 +0,0 @@
-'use strict'
-
-function uniques (value, key) {
-  // Create an index of the collection
-  let uniques = {}
-  var get = e => uniques[e]
-  var addToIndex = e => uniques[key ? e[key] : e] = e
-  value.forEach(addToIndex)
-  return Object.keys(uniques).map(get)
-}
-
-module.exports = uniques
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/config/ipfs-daemon.config.js
+++ /dev/null
@@ -1,48 +0,0 @@
-module.exports = {
-  daemon1: {
-    repo: './ipfs/tests/replication/daemon1',
-    EXPERIMENTAL: {
-      pubsub: true
-    },
-    config: {
-      Addresses: {
-        API: '/ip4/127.0.0.1/tcp/0',
-        Swarm: ['/ip4/0.0.0.0/tcp/0'],
-        Gateway: '/ip4/0.0.0.0/tcp/0'
-      },
-      Bootstrap: [],
-      Discovery: {
-        MDNS: {
-          Enabled: true,
-          Interval: 10
-        },
-        webRTCStar: {
-          Enabled: false
-        }
-      },
-    },
-  },
-  daemon2: {
-    repo: './ipfs/tests/replication/daemon2',
-    EXPERIMENTAL: {
-      pubsub: true
-    },
-    config: {
-      Addresses: {
-        API: '/ip4/127.0.0.1/tcp/0',
-        Swarm: ['/ip4/0.0.0.0/tcp/0'],
-        Gateway: '/ip4/0.0.0.0/tcp/0'
-      },
-      Bootstrap: [],
-      Discovery: {
-        MDNS: {
-          Enabled: true,
-          Interval: 10
-        },
-        webRTCStar: {
-          Enabled: false
-        }
-      },
-    },
-  },
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/entry-io.spec.js
+++ /dev/null
@@ -1,174 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const Log = require('../src/log')
-const EntryIO = require('../src/entry-io')
-
-const apis = [require('ipfs')]
-
-const dataDir = './ipfs/tests/fetch'
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-let ipfs, ipfsDaemon
-
-const last = arr => arr[arr.length - 1]
-
-apis.forEach((IPFS) => {
-  describe('Entry - Persistency', function() {
-    this.timeout(20000)
-
-    before((done) => {
-      rmrf.sync(dataDir)
-      ipfs = new IPFS({ 
-        repo: new IPFSRepo(dataDir, repoConf),
-        start: true,
-        EXPERIMENTAL: {
-          pubsub: true,
-          dht: false,
-          sharding: false,
-        },
-      })
-      ipfs.on('error', done)
-      ipfs.on('ready', () => done())
-    })
-
-    after(async () => {
-      if (ipfs) 
-        await ipfs.stop()
-    })
-
-    it('log with one entry', async () => {
-      let log = new Log(ipfs, 'X')
-      await log.append('one')
-      const hash = log.values[0].hash
-      const res = await EntryIO.fetchAll(ipfs, hash, 1)
-      assert.equal(res.length, 1)
-    })
-
-    it('log with 2 entries', async () => {
-      let log = new Log(ipfs, 'X')
-      await log.append('one')
-      await log.append('two')
-      const hash = last(log.values).hash
-      const res = await EntryIO.fetchAll(ipfs, hash, 2)
-      assert.equal(res.length, 2)
-    })
-
-    it('loads max 1 entriy from a log of 2 entry', async () => {
-      let log = new Log(ipfs, 'X')
-      await log.append('one')
-      await log.append('two')
-      const hash = last(log.values).hash
-      const res = await EntryIO.fetchAll(ipfs, hash, 1)
-      assert.equal(res.length, 1)
-    })
-
-    it('log with 100 entries', async () => {
-      const count = 100
-      let log = new Log(ipfs, 'X')
-      for (let i = 0; i < count; i ++)
-        await log.append('hello' + i)
-
-      const hash = await log.toMultihash()
-      const result = await Log.fromMultihash(ipfs, hash)
-      assert.equal(result.length, count)
-    })
-
-    it('load only 42 entries from a log with 100 entries', async () => {
-      const count = 100
-      let log = new Log(ipfs, 'X')
-      let log2 = new Log(ipfs, 'X')
-      for (let i = 1; i <= count; i ++) {
-        await log.append('hello' + i)
-        if (i % 10 === 0) {
-          log2 = new Log(ipfs, log2.id, log2.values, log2.heads.concat(log.heads))
-          await log2.append('hi' + i)
-        }
-      }
-
-      const hash = await log.toMultihash()
-      const result = await Log.fromMultihash(ipfs, hash, 42)
-      assert.equal(result.length, 42)
-    })
-
-    it('load only 99 entries from a log with 100 entries', async () => {
-      const count = 100
-      let log = new Log(ipfs, 'X')
-      let log2 = new Log(ipfs, 'X')
-      let log3 = new Log(ipfs, 'X')
-      for (let i = 1; i <= count; i ++) {
-        await log.append('hello' + i)
-        if (i % 10 === 0) {
-          log2 = new Log(ipfs, log2.id, log2.values)
-          await log2.append('hi' + i)
-          log2.join(log)
-        }
-      }
-
-      const hash = await log2.toMultihash()
-      const result = await Log.fromMultihash(ipfs, hash, 99)
-      assert.equal(result.length, 99)
-    })
-
-    it('load only 10 entries from a log with 100 entries', async () => {
-      const count = 100
-      let log = new Log(ipfs, 'X')
-      let log2 = new Log(ipfs, 'X')
-      let log3 = new Log(ipfs, 'X')
-      for (let i = 1; i <= count; i ++) {
-        await log.append('hello' + i)
-        if (i % 10 === 0) {
-          log2 = new Log(ipfs, log2.id, log2.values, log2.heads)
-          await log2.append('hi' + i)
-          log2.join(log)
-        }
-        if (i % 25 === 0) {
-          log3 = new Log(ipfs, log3.id, log3.values, log3.heads.concat(log2.heads))
-          await log3.append('--' + i)
-        }
-      }
-
-      log3.join(log2)
-      const hash = await log3.toMultihash()
-      const result = await Log.fromMultihash(ipfs, hash, 10)
-      assert.equal(result.length, 10)
-    })
-
-    it('load only 10 entries and then expand to max from a log with 100 entries', async () => {
-      const count = 30
-      let log =  new Log(ipfs, 'X', null, null, null, 'A')
-      let log2 = new Log(ipfs, 'X', null, null, null, 'B')
-      let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-      for (let i = 1; i <= count; i ++) {
-        await log.append('hello' + i)
-        if (i % 10 === 0) {
-          await log2.append('hi' + i)
-          log2.join(log)
-        }
-        if (i % 25 === 0) {
-          log3 = new Log(ipfs, log3.id, log3.values, log3.heads.concat(log2.heads))
-          await log3.append('--' + i)
-        }
-      }
-
-      log3.join(log2)
-
-      const log4 = new Log(ipfs, 'X', null, null, null, 'D')
-      log4.join(log2)
-      log4.join(log3)
-
-      const values3 = log3.values.map((e) => e.payload)
-      const values4 = log4.values.map((e) => e.payload)
-
-      assert.deepEqual(values3, values4)
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/entry.spec.js
+++ /dev/null
@@ -1,259 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const Entry = require('../src/entry')
-
-const apis = [require('ipfs')]
-
-const dataDir = './ipfs/tests/entry'
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-let ipfs, ipfsDaemon
-
-apis.forEach((IPFS) => {
-
-  describe('Entry', function() {
-    this.timeout(20000)
-
-    before((done) => {
-      rmrf.sync(dataDir)
-      ipfs = new IPFS({ 
-        repo: new IPFSRepo(dataDir, repoConf),
-        EXPERIMENTAL: {
-          pubsub: true,
-          dht: false,
-          sharding: false,
-        },
-      })
-      ipfs.on('error', done)
-      ipfs.on('ready', () => done())
-    })
-
-    after(async () => {
-      if (ipfs) 
-        await ipfs.stop()
-    })
-
-    describe('create', () => {
-      it('creates a an empty entry', async () => {
-        const expectedHash = 'QmReSDagnYwVwD6uHBFtW6DRNiSw7EQSsVT7LwdqjFvW8T'
-        const entry = await Entry.create(ipfs, null, 'A', 'hello')
-        assert.equal(entry.hash, expectedHash)
-        assert.equal(entry.id, 'A')
-        assert.equal(entry.clock.id, 'A')
-        assert.equal(entry.clock.time, 0)
-        assert.equal(entry.v, 0)
-        assert.equal(entry.payload, 'hello')
-        assert.equal(entry.next.length, 0)
-        assert.equal(entry.refs.length, 0)
-      })
-
-      it('creates a entry with payload', async () => {
-        const expectedHash = 'QmTzDNUezcBsronFxR47FFD6PyjMS1HuoeR2C4P66DC7rN'
-        const payload = 'hello world'
-        const entry = await Entry.create(ipfs, null, 'A', payload)
-        assert.equal(entry.payload, payload)
-        assert.equal(entry.id, 'A')
-        assert.equal(entry.clock.id, 'A')
-        assert.equal(entry.clock.time, 0)
-        assert.equal(entry.v, 0)
-        assert.equal(entry.next.length, 0)
-        assert.equal(entry.refs.length, 0)
-        assert.equal(entry.hash, expectedHash)
-      })
-
-      it('creates a entry with payload and next', async () => {
-        const expectedHash = 'Qmct9J2udUqPf7xiXwAfP7bcubQGjfyoTVtbsfZXjziZdQ'
-        const payload1 = 'hello world'
-        const payload2 = 'hello again'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        entry1.clock.tick()
-        const entry2 = await Entry.create(ipfs, null, 'A', payload2, [entry1], entry1.clock)
-        assert.equal(entry2.payload, payload2)
-        assert.equal(entry2.next.length, 1)
-        assert.equal(entry2.refs.length, 0)
-        assert.equal(entry2.hash, expectedHash)
-        assert.equal(entry2.clock.id, 'A')
-        assert.equal(entry2.clock.time, 1)
-      })
-
-      it('`next` parameter can be an array of strings', async () => {
-        const entry1 = await Entry.create(ipfs, null, 'A', 'hello1')
-        const entry2 = await Entry.create(ipfs, null, 'A', 'hello2', [entry1.hash])
-        assert.equal(typeof entry2.next[0] === 'string', true)
-      })
-
-      it('`next` parameter can be an array of Entry instances', async () => {
-        const entry1 = await Entry.create(ipfs, null, 'A', 'hello1')
-        const entry2 = await Entry.create(ipfs, null, 'A', 'hello2', [entry1])
-        assert.equal(typeof entry2.next[0] === 'string', true)
-      })
-
-      it('`next` parameter can contain nulls and undefined objects', async () => {
-        const entry1 = await Entry.create(ipfs, null, 'A', 'hello1')
-        const entry2 = await Entry.create(ipfs, null, 'A', 'hello2', [entry1, null, undefined])
-        assert.equal(typeof entry2.next[0] === 'string', true)
-      })
-
-      it('throws an error if ipfs is not defined', async () => {
-        try {
-          const entry = await Entry.create()
-        } catch(e) {
-          assert.equal(e.message, 'Ipfs instance not defined')
-        }
-      })
-
-      it('throws an error if id is not defined', async () => {
-        try {
-          const entry = await Entry.create(ipfs)
-        } catch(e) {
-          assert.equal(e.message, 'Entry requires an id')
-        }
-      })
-
-      it('throws an error if data is not defined', async () => {
-        try {
-          const entry = await Entry.create(ipfs, null, 'A')
-        } catch(e) {
-          assert.equal(e.message, 'Entry requires data')
-        }
-      })
-
-      it('throws an error if next is not an array', async () => {
-        try {
-          const entry = await Entry.create(ipfs, null, 'A', 'hello', null)
-        } catch(e) {
-          assert.equal(e.message, '\'next\' argument is not an array')
-        }
-      })
-    })
-
-    describe('toMultihash', () => {
-      it('returns an ipfs hash', async () => {
-        const expectedHash = 'QmcnoBuewB9DEqkwrsXWvpB1btvWuRwkRpJL5B67AvvTsx'
-        const entry = await Entry.create(ipfs, null, 'A', 'hello')
-        const hash = await Entry.toMultihash(ipfs, entry)
-        assert.equal(hash, expectedHash)
-      })
-
-      it('throws an error if ipfs is not defined', async () => {
-        try {
-          const entry = await Entry.toMultihash()
-        } catch(e) {
-          assert.equal(e.message, 'Ipfs instance not defined')
-        }
-      })
-    })
-
-    describe('fromMultihash', () => {
-      it('creates a entry from ipfs hash', async () => {
-        const expectedHash = 'QmVMCywjnL1y44mi6KkqcUBd8Thqd6gRLtXfSWekX9Su8i'
-        const payload1 = 'hello world'
-        const payload2 = 'hello again'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        const entry2 = await Entry.create(ipfs, null, 'A', payload2, [entry1])
-        const final = await Entry.fromMultihash(ipfs, entry2.hash)
-        assert.equal(final.id, 'A')
-        assert.equal(final.payload, payload2)
-        assert.equal(final.next.length, 1)
-        assert.equal(final.next[0], entry1.hash)
-        assert.equal(final.refs.length, 0)
-        assert.equal(final.hash, expectedHash)
-      })
-
-      it('throws an error if ipfs is not present', async () => {
-        try {
-          const entry = await Entry.fromMultihash()
-        } catch(e) {
-          assert.equal(e.message, 'Ipfs instance not defined')
-        }
-      })
-
-      it('throws an error if hash is undefined', async () => {
-        try {
-          const entry = await Entry.fromMultihash(ipfs)
-        } catch(e) {
-          assert.equal(e.message, 'Invalid hash: undefined')
-        }
-      })
-    })
-
-    describe('isParent', () => {
-      it('returns true if entry has a child', async () => {
-        const payload1 = 'hello world'
-        const payload2 = 'hello again'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        const entry2 = await Entry.create(ipfs, null, 'A', payload2, [entry1])
-        assert.equal(Entry.isParent(entry1, entry2), true)
-      })
-
-      it('returns false if entry does not have a child', async () => {
-        const payload1 = 'hello world'
-        const payload2 = 'hello again'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        const entry2 = await Entry.create(ipfs, null, 'A', payload2)
-        const entry3 = await Entry.create(ipfs, null, 'A', payload2, [entry2])
-        assert.equal(Entry.isParent(entry1, entry2), false)
-        assert.equal(Entry.isParent(entry1, entry3), false)
-        assert.equal(Entry.isParent(entry2, entry3), true)
-      })
-    })
-
-    describe('compare', () => {
-      it('returns true if entries are the same', async () => {
-        const payload1 = 'hello world'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        const entry2 = await Entry.create(ipfs, null, 'A', payload1)
-        assert.equal(Entry.isEqual(entry1, entry2), true)
-      })
-
-      it('returns true if entries are not the same', async () => {
-        const payload1 = 'hello world1'
-        const payload2 = 'hello world2'
-        const entry1 = await Entry.create(ipfs, null, 'A', payload1)
-        const entry2 = await Entry.create(ipfs, null, 'A', payload2)
-        assert.equal(Entry.isEqual(entry1, entry2), false)
-      })
-    })
-
-    describe('isEntry', () => {
-      it('is an Entry', async () => {
-        const entry = await Entry.create(ipfs, null, 'A', 'hello')
-        assert.equal(Entry.isEntry(entry), true)
-      })
-
-      it('is not an Entry - no id', async () => {
-        const fakeEntry = { next: [], hash: 'Foo', payload: 123, seq: 0 }
-        assert.equal(Entry.isEntry(fakeEntry), false)
-      })
-
-      it('is not an Entry - no seq', async () => {
-        const fakeEntry = { next: [], hash: 'Foo', payload: 123 }
-        assert.equal(Entry.isEntry(fakeEntry), false)
-      })
-
-      it('is not an Entry - no next', async () => {
-        const fakeEntry = { id: 'A', hash: 'Foo', payload: 123, seq: 0  }
-        assert.equal(Entry.isEntry(fakeEntry), false)
-      })
-
-      it('is not an Entry - no hash', async () => {
-        const fakeEntry = { id: 'A', next: [], payload: 123, seq: 0  }
-        assert.equal(Entry.isEntry(fakeEntry), false)
-      })
-
-      it('is not an Entry - no payload', async () => {
-        const fakeEntry = { id: 'A', next: [], hash: 'Foo', seq: 0  }
-        assert.equal(Entry.isEntry(fakeEntry), false)
-      })
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/fetch-entries.test.js
+++ /dev/null
@@ -1,59 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const Log = require('../src/log')
-const EntryIO = require('../src/entry-io')
-
-const apis = [require('ipfs')]
-
-const dataDir = './ipfs/tests/fetch'
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-let ipfs, ipfsDaemon
-
-const last = arr => arr[arr.length - 1]
-
-apis.forEach((IPFS) => {
-  describe('Fetch entries', function() {
-    this.timeout(20000)
-
-    before((done) => {
-      rmrf.sync(dataDir)
-      ipfs = new IPFS({ 
-        repo: new IPFSRepo(dataDir, repoConf),
-        start: true,
-        EXPERIMENTAL: {
-          pubsub: true,
-          dht: false,
-          sharding: false,
-        },
-      })
-      ipfs.on('error', done)
-      ipfs.on('ready', () => done())
-    })
-
-    after(async () => {
-      if (ipfs) 
-        await ipfs.stop()
-    })
-
-    it('log with 10 entries', async () => {
-      const count = 100
-      let log = new Log(ipfs, 'X', )
-
-      for (let i = 1; i < count + 1; i ++)
-        await log.append('hello' + i, 8)
-
-      const result = await EntryIO.fetchAll(ipfs, log.heads.map(e => e.hash), -1, [], 2000, () => {})
-      assert.equal(result.length, count)
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/fixtures/big-log.fixture.js
+++ /dev/null
@@ -1,35 +0,0 @@
-module.exports = `DONE
-└─EOF
-  └─entryC10
-    └─entryB10
-      └─entryA10
-    └─entryC9
-      └─entryB9
-        └─entryA9
-      └─entryC8
-        └─entryB8
-          └─entryA8
-        └─entryC7
-          └─entryB7
-            └─entryA7
-          └─entryC6
-            └─entryB6
-              └─entryA6
-            └─entryC5
-              └─entryB5
-                └─entryA5
-              └─entryC4
-                └─entryB4
-                  └─entryA4
-└─3
-                └─entryC3
-                  └─entryB3
-                    └─entryA3
-  └─2
-                  └─entryC2
-                    └─entryB2
-                      └─entryA2
-    └─1
-                    └─entryC1
-                      └─entryB1
-                        └─entryA1`
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/fixtures/keystore/A
+++ /dev/null
@@ -1 +0,0 @@
-{"publicKey":"0482f63d5a2a054e4a5cd04db8e98cf79f0a884c9ff3fbafb755f8ba63e6761ac5d7d9127d2d306434e31453862a6e4585319e60ae530946427daf7dd091e09812","privateKey":"f02698b88a718bf15188fa34bc008105b231e6009ed6d72520380344b513de5f"}
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/fixtures/keystore/B
+++ /dev/null
@@ -1 +0,0 @@
-{"publicKey":"04f39cc6481b6cc5ae6a8a15f025ca361d12e2f048c96f7c4018f7c5cadf8a1ac07c7682a7b1bd933b7f941bcc040440003c02b3c024975c6f294fa147615517c3","privateKey":"9946a9c2b24ff1a2ff6091295dd44fc5dc935a5715a2b9fde7251b0a8a45c3b9"}
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/fixtures/keystore/C
+++ /dev/null
@@ -1 +0,0 @@
-{"publicKey":"0446763191b06b2106deb4f7cd1addc27c9f843bf000272cb2907a164e36a1547eaff0198893b29dfd304d97cdebdf5952ef4dc6d463539df0add2e1d38a955fca","privateKey":"03805f15cbbc26e07d99b0d488f052bb29da6b0e32720b8948671681496f01a5"}
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/log.spec.js
+++ /dev/null
@@ -1,2136 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const pMap = require('p-map')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const LogCreator = require('./utils/log-creator')
-const bigLogString = require('./fixtures/big-log.fixture.js')
-const Log = require('../src/log.js')
-const Entry = require('../src/entry')
-const Clock = require('../src/lamport-clock')
-
-const apis = [require('ipfs')]
-
-const dataDir = './ipfs/tests/log'
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-let ipfs
-
-const last = (arr) => {
-  return arr[arr.length - 1]
-}
-
-apis.forEach((IPFS) => {
-
-  describe('Log', function() {
-    this.timeout(20000)
-
-    before((done) => {
-      rmrf.sync(dataDir)
-      ipfs = new IPFS({
-        repo: new IPFSRepo(dataDir, repoConf),
-        EXPERIMENTAL: {
-          pubsub: true,
-          dht: false,
-          sharding: false,
-        },
-      })
-
-      // Use memory store for quicker tests
-      // const memstore = new MemStore()
-      // ipfs.object.put = memstore.put.bind(memstore)
-      // ipfs.object.get = memstore.get.bind(memstore)
-
-      ipfs.on('error', done)
-      ipfs.on('ready', () => done())
-    })
-
-    after(async () => {
-      if (ipfs)
-        await ipfs.stop()
-    })
-
-    describe('constructor', async () => {
-      it('creates an empty log', () => {
-        const log = new Log(ipfs)
-        assert.notEqual(log._entryIndex, null)
-        assert.notEqual(log._headsIndex, null)
-        assert.notEqual(log._id, null)
-        assert.notEqual(log.id, null)
-        assert.notEqual(log.clock, null)
-        assert.notEqual(log.values, null)
-        assert.notEqual(log.heads, null)
-        assert.notEqual(log.tails, null)
-        assert.notEqual(log.tailHashes, null)
-      })
-
-      it('creates an empty log and sets default params', () => {
-        const log = new Log(ipfs)
-        assert.notEqual(log.id, null)
-        assert.deepEqual(log.values, [])
-        assert.deepEqual(log.heads, [])
-        assert.deepEqual(log.tails, [])
-      })
-
-      it('throws an error if ImmutableDB instance is not passed as an argument', () => {
-        let err
-        try {
-          const log = new Log()
-        } catch(e) {
-          err = e
-        }
-        assert.equal(err.message, 'ImmutableDB instance not defined')
-      })
-
-      it('sets an id', () => {
-        const log = new Log(ipfs, 'ABC')
-        assert.equal(log.id, 'ABC')
-      })
-
-      it('sets the clock id', () => {
-        const log = new Log(ipfs, 'ABC', null, null, null, 'XXX')
-        assert.equal(log.id, 'ABC')
-        assert.equal(log.clock.id, 'XXX')
-      })
-
-      it('generates id string if id is not passed as an argument', () => {
-        const log = new Log(ipfs)
-        assert.equal(typeof log.id === 'string', true)
-      })
-
-      it('sets items if given as params', async () => {
-        const one = await Entry.create(ipfs, null, 'A', 'entryA', [], new Clock('A', 0))
-        const two = await Entry.create(ipfs, null, 'A', 'entryB', [], new Clock('B', 0))
-        const three = await Entry.create(ipfs, null, 'A', 'entryC', [], new Clock('C', 0))
-        const log = new Log(ipfs, 'A', [one, two, three])
-        assert.equal(log.length, 3)
-        assert.equal(log.values[0].payload, 'entryA')
-        assert.equal(log.values[1].payload, 'entryB')
-        assert.equal(log.values[2].payload, 'entryC')
-      })
-
-      it('sets heads if given as params', async () => {
-        const one = await Entry.create(ipfs, null, 'A', 'entryA')
-        const two = await Entry.create(ipfs, null, 'B', 'entryB')
-        const three = await Entry.create(ipfs, null, 'C', 'entryC')
-        const log = new Log(ipfs, 'B', [one, two, three], [three])
-        assert.equal(log.heads.length, 1)
-        assert.equal(log.heads[0].hash, three.hash)
-      })
-
-      it('finds heads if heads not given as params', async () => {
-        const one = await Entry.create(ipfs, null, 'A', 'entryA')
-        const two = await Entry.create(ipfs, null, 'B', 'entryB')
-        const three = await Entry.create(ipfs, null, 'C', 'entryC')
-        const log = new Log(ipfs, 'A', [one, two, three])
-        assert.equal(log.heads.length, 3)
-        assert.equal(log.heads[0].hash, one.hash)
-        assert.equal(log.heads[1].hash, two.hash)
-        assert.equal(log.heads[2].hash, three.hash)
-      })
-
-      it('throws an error if entries is not an array', () => {
-        let err
-        try {
-          const log = new Log(ipfs, 'A', {})
-        } catch(e) {
-          err = e
-        }
-        assert.notEqual(err, undefined)
-        assert.equal(err.message, `'entries' argument must be an array of Entry instances`)
-      })
-
-      it('throws an error if heads is not an array', () => {
-        let err
-        try {
-          const log = new Log(ipfs, 'A', [], {})
-        } catch(e) {
-          err = e
-        }
-        assert.notEqual(err, undefined)
-        assert.equal(err.message, `'heads' argument must be an array`)
-      })
-    })
-
-    describe('toString', async () => {
-      let log
-      const expectedData = 'five\n└─four\n  └─three\n    └─two\n      └─one'
-
-      beforeEach(async () => {
-        log = new Log(ipfs, 'A')
-        await log.append('one')
-        await log.append('two')
-        await log.append('three')
-        await log.append('four')
-        await log.append('five')
-      })
-
-      it('returns a nicely formatted string', () => {
-        assert.equal(log.toString(), expectedData)
-      })
-    })
-
-    describe('get', async () => {
-      let log
-
-      const expectedData = {
-        hash: 'QmamJHiANgjAhnUMjA8aUFdzzPbc7Zt375pH6jaByG3LSZ',
-        id: 'AAA',
-        payload: 'one',
-        next: [],
-        refs: [],
-        v: 0,
-        clock: {
-          id: 'AAA',
-          time: 1,
-        },
-      }
-
-      beforeEach(async () => {
-        log = new Log(ipfs, 'AAA')
-        await log.append('one')
-      })
-
-      it('returns an Entry', () => {
-        const entry = log.get(log.values[0].hash)
-        assert.deepEqual(entry, expectedData)
-      })
-
-      it('returns undefined when Entry is not in the log', () => {
-        const entry = log.get('QmFoo')
-        assert.deepEqual(entry, null)
-      })
-    })
-
-    describe('has', async () => {
-      let log
-
-      const expectedData = {
-        hash: 'QmamJHiANgjAhnUMjA8aUFdzzPbc7Zt375pH6jaByG3LSZ',
-        id: 'AAA',
-        payload: 'one',
-        next: [],
-        refs: [],
-        v: 0,
-        clock: {
-          id: 'AAA',
-          time: 1,
-        },
-      }
-
-      beforeEach(async () => {
-        log = new Log(ipfs, 'AAA')
-        await log.append('one')
-      })
-
-      it('entry exists', () => {
-        assert.notEqual(log.get(expectedData.hash), expectedData)
-      })
-
-      it('returns true if it has an Entry', () => {
-        assert.equal(log.has(expectedData), true)
-      })
-
-      it('returns true if it has an Entry, hash lookup', () => {
-        assert.equal(log.has(expectedData.hash), true)
-      })
-
-      it('returns false if it doesn\'t have the Entry', () => {
-        assert.equal(log.has('QmFoo'), false)
-      })
-    })
-
-    describe('serialize', async () => {
-      let log
-      const expectedData = {
-        id: 'AAA',
-        heads: ['QmPq5aPidmVQJkMnmExQTEouN9p56hGVqGvTmmqZLYUJQ1']
-      }
-
-      beforeEach(async () => {
-        log = new Log(ipfs, 'AAA')
-        await log.append('one')
-        await log.append('two')
-        await log.append('three')
-      })
-
-      describe('toJSON', () => {
-        it('returns the log in JSON format', () => {
-          assert.equal(JSON.stringify(log.toJSON()), JSON.stringify(expectedData))
-        })
-      })
-
-      describe('toSnapshot', () => {
-        const expectedData = {
-          id: 'AAA',
-          heads: ['QmPq5aPidmVQJkMnmExQTEouN9p56hGVqGvTmmqZLYUJQ1'],
-          values: [
-            'QmamJHiANgjAhnUMjA8aUFdzzPbc7Zt375pH6jaByG3LSZ',
-            'QmY7y4WNreeBpMEeqWUUkDeFvHuUXhvGhdTRJRXQHvsxy4',
-            'QmPq5aPidmVQJkMnmExQTEouN9p56hGVqGvTmmqZLYUJQ1',
-          ]
-        }
-
-        it('returns the log snapshot', () => {
-          const snapshot = log.toSnapshot()
-          assert.equal(snapshot.id, expectedData.id)
-          assert.equal(snapshot.heads.length, expectedData.heads.length)
-          assert.equal(snapshot.heads[0].hash, expectedData.heads[0])
-          assert.equal(snapshot.values.length, expectedData.values.length)
-          assert.equal(snapshot.values[0].hash, expectedData.values[0])
-          assert.equal(snapshot.values[1].hash, expectedData.values[1])
-          assert.equal(snapshot.values[2].hash, expectedData.values[2])
-        })
-      })
-
-      describe('toBuffer', () => {
-        it('returns the log as a Buffer', () => {
-          assert.deepEqual(log.toBuffer(), Buffer.from(JSON.stringify(expectedData)))
-        })
-      })
-
-      describe('toMultihash', async () => {
-        it('returns the log as ipfs hash', async () => {
-          const expectedHash = 'QmWQ2stJDQ2WZGF6gM3jSbfhKu6YfoEtLHasxyq69wXdLJ'
-          let log = new Log(ipfs, 'A')
-          await log.append('one')
-          const hash = await log.toMultihash()
-          assert.equal(hash, expectedHash)
-        })
-
-        it('log serialized to ipfs contains the correct data', async () => {
-          const expectedData = {
-            id: 'A',
-            heads: ['QmQQxsHn9LQ5mzs4TMBkhLGtu9wZamT3jGAD9yEZxXwUiw']
-          }
-          const expectedHash = 'QmWQ2stJDQ2WZGF6gM3jSbfhKu6YfoEtLHasxyq69wXdLJ'
-          let log = new Log(ipfs, 'A')
-          await log.append('one')
-          const hash = await log.toMultihash()
-          assert.equal(hash, expectedHash)
-          // const result = await ipfs.get(hash)
-          const result = await ipfs.object.get(hash)
-          const res = JSON.parse(result.toJSON().data.toString())
-          assert.deepEqual(res.heads, expectedData.heads)
-        })
-
-        it('throws an error if log items is empty', () => {
-          const emptyLog = new Log(ipfs)
-          let err
-          try {
-            emptyLog.toMultihash()
-          } catch (e) {
-            err = e
-          }
-          assert.notEqual(err, null)
-          assert.equal(err.message, 'Can\'t serialize an empty log')
-        })
-      })
-
-      describe('fromMultihash', async () => {
-        it('creates a log from ipfs hash - one entry', async () => {
-          const expectedData = {
-            id: 'X',
-            heads: ['Qma8M6V3fBiq4gh7vdoGU8L788mdrkCEU9Sq2iiZer8iNF']
-          }
-          let log = new Log(ipfs, 'X')
-          await log.append('one')
-          const hash = await log.toMultihash()
-          const res = await Log.fromMultihash(ipfs, hash)
-          assert.equal(JSON.stringify(res.toJSON()), JSON.stringify(expectedData))
-          assert.equal(res.length, 1)
-          assert.equal(res.values[0].payload, 'one')
-          assert.equal(res.values[0].clock.id, 'X')
-          assert.equal(res.values[0].clock.time, 1)
-        })
-
-        it('creates a log from ipfs hash - three entries', async () => {
-          const hash = await log.toMultihash()
-          const res = await Log.fromMultihash(ipfs, hash)
-          assert.equal(res.length, 3)
-          assert.equal(res.values[0].payload, 'one')
-          assert.equal(res.values[0].clock.time, 1)
-          assert.equal(res.values[1].payload, 'two')
-          assert.equal(res.values[1].clock.time, 2)
-          assert.equal(res.values[2].payload, 'three')
-          assert.equal(res.values[2].clock.time, 3)
-        })
-
-        it('has the right sequence number after creation and appending', async () => {
-          const hash = await log.toMultihash()
-          let res = await Log.fromMultihash(ipfs, hash)
-          assert.equal(res.length, 3)
-          await res.append('four')
-          assert.equal(res.length, 4)
-          assert.equal(res.values[3].payload, 'four')
-          assert.equal(res.values[3].clock.time, 4)
-        })
-
-        it('creates a log from ipfs hash that has three heads', async () => {
-          let log1 = new Log(ipfs, 'A')
-          let log2 = new Log(ipfs, 'B')
-          let log3 = new Log(ipfs, 'C')
-          await log1.append('one')
-          await log2.append('two')
-          await log3.append('three')
-          log1.join(log2)
-          log1.join(log3)
-          const hash = await log1.toMultihash()
-          const res = await Log.fromMultihash(ipfs, hash)
-          assert.equal(res.length, 3)
-          assert.equal(res.heads.length, 3)
-          assert.equal(res.heads[0].payload, 'one')
-          assert.equal(res.heads[1].payload, 'two')
-          assert.equal(res.heads[2].payload, 'three')
-        })
-
-        it('creates a log from ipfs hash up to a size limit', async () => {
-          const amount = 100
-          const size = amount / 2
-          let log = new Log(ipfs, 'A')
-          for (let i = 0; i < amount; i ++) {
-            await log.append(i.toString())
-          }
-          const hash = await log.toMultihash()
-          const res = await Log.fromMultihash(ipfs, hash, size)
-          assert.equal(res.length, size)
-        })
-
-        it('creates a log from ipfs hash up without size limit', async () => {
-          const amount = 100
-          let log = new Log(ipfs, 'A')
-          for (let i = 0; i < amount; i ++) {
-            await log.append(i.toString())
-          }
-          const hash = await log.toMultihash()
-          const res = await Log.fromMultihash(ipfs, hash, -1)
-          assert.equal(res.length, amount)
-        })
-
-        it('throws an error if ipfs is not defined', () => {
-          let err
-          try {
-            const log = Log.fromMultihash()
-          } catch (e) {
-            err = e
-          }
-          assert.notEqual(err, null)
-          assert.equal(err.message, 'ImmutableDB instance not defined')
-        })
-
-        it('throws an error if hash is not defined', () => {
-          let err
-          try {
-            const log = Log.fromMultihash(ipfs)
-          } catch (e) {
-            err = e
-          }
-          assert.notEqual(err, null)
-          assert.equal(err.message, 'Invalid hash: undefined')
-        })
-
-        it('throws an error when data from hash is not instance of Log', async () => {
-          let err
-          // const res = await ipfs.put(Buffer.from('{}'))
-          const res = await ipfs.object.put(Buffer.from('{}'))
-          try {
-            await Log.fromMultihash(ipfs, res.toJSON().multihash)
-          } catch(e) {
-            err = e
-          }
-          assert.equal(err.message, 'Given argument is not an instance of Log')
-        })
-
-        it('throws an error if data from hash is not valid JSON', async () => {
-          let err
-          // const res = await ipfs.put(Buffer.from('hello'))
-          const res = await ipfs.object.put(Buffer.from('hello'))
-          try {
-            await Log.fromMultihash(ipfs, res.toJSON().multihash)
-          } catch(e) {
-            err = e
-          }
-          assert.equal(err.message, 'Unexpected token h in JSON at position 0')
-        })
-
-        it('onProgress callback is fired for each entry', async () => {
-          const amount = 100
-          let log = new Log(ipfs, 'A')
-          for (let i = 0; i < amount; i ++) {
-            await log.append(i.toString())
-          }
-
-          const items = log.values
-          let i = 0
-          const callback = (hash, entry, depth) => {
-            assert.notEqual(entry, null)
-            assert.equal(hash, items[items.length - i - 1].hash)
-            assert.equal(entry.hash, items[items.length - i - 1].hash)
-            assert.equal(entry.payload, items[items.length - i - 1].payload)
-            assert.equal(depth - 1, i)
-            i ++
-          }
-
-          try {
-            const hash = await log.toMultihash()
-            const res = await Log.fromMultihash(ipfs, hash, -1, [], callback)
-          } catch (e) {
-            done(e)
-          }
-        })
-      })
-    })
-
-    describe('values', () => {
-      it('returns all entries in the log', async () => {
-        let log = new Log(ipfs)
-        assert.equal(log.values instanceof Array, true)
-        assert.equal(log.length, 0)
-        await log.append('hello1')
-        await log.append('hello2')
-        await log.append('hello3')
-        assert.equal(log.values instanceof Array, true)
-        assert.equal(log.length, 3)
-        assert.equal(log.values[0].payload, 'hello1')
-        assert.equal(log.values[1].payload, 'hello2')
-        assert.equal(log.values[2].payload, 'hello3')
-      })
-    })
-
-    describe('append', () => {
-      describe('append one', async () => {
-        let log
-
-        before(async () => {
-          log = new Log(ipfs, 'A')
-          await log.append("hello1")
-        })
-
-        it('added the correct amount of items', () => {
-          assert.equal(log.length, 1)
-        })
-
-        it('added the correct values', async () => {
-          log.values.forEach((entry) => {
-            assert.equal(entry.payload, 'hello1')
-          })
-        })
-
-        it('added the correct amount of next pointers', async () => {
-          log.values.forEach((entry) => {
-            assert.equal(entry.next.length, 0)
-          })
-        })
-
-        it('has the correct heads', async () => {
-          log.heads.forEach((head) => {
-            assert.equal(head.hash, log.values[0].hash)
-          })
-        })
-
-        it('updated the clocks correctly', async () => {
-          log.values.forEach((entry) => {
-            assert.equal(entry.clock.id, 'A')
-            assert.equal(entry.clock.time, 1)
-          })
-        })
-      })
-
-      describe('append 100 items to a log', async () => {
-        const amount = 100
-        const nextPointerAmount = 8
-        const refCount = 4
-
-        let log
-
-        before(async () => {
-          log = new Log(ipfs, 'A')
-          for(let i = 0; i < amount; i ++) {
-            await log.append("hello" + i, nextPointerAmount)
-            // Make sure the log has the right heads after each append
-            const values = log.values
-            assert.equal(log.heads.length, 1)
-            assert.equal(log.heads[0].hash, values[values.length - 1].hash)
-          }
-        })
-
-        it('added the correct amount of items', () => {
-          assert.equal(log.length, amount)
-        })
-
-        it('added the correct values', async () => {
-          log.values.forEach((entry, index) => {
-            assert.equal(entry.payload, 'hello' + index)
-          })
-        })
-
-        it('updated the clocks correctly', async () => {
-          log.values.forEach((entry, index) => {
-            assert.equal(entry.clock.time, index + 1)
-            assert.equal(entry.clock.id, 'A')
-          })
-        })
-
-        it('added the correct amount of next pointers', async () => {
-          log.values.slice(5, log.values.length).reverse().forEach((entry, index) => {
-            assert.equal(entry.next.length, 1)
-            assert.equal(entry.refs.length, refCount)
-          })
-        })
-      })
-    })
-
-    describe('join', () => {
-      let log1, log2, log3, log4
-
-      beforeEach(async () => {
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        log4 = new Log(ipfs, 'X', null, null, null, 'D')
-      })
-
-      it('joins logs', async () => {
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        const amount = 100
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const prev2 = last(items2)
-          const prev3 = last(items3)
-          const n1 = await Entry.create(ipfs, null, 'X', 'entryA' + i, [prev1])
-          const n2 = await Entry.create(ipfs, null, 'X', 'entryB' + i, [prev2, n1])
-          const n3 = await Entry.create(ipfs, null, 'X', 'entryC' + i, [prev3, n1, n2])
-          items1.push(n1)
-          items2.push(n2)
-          items3.push(n3)
-        }
-
-        const logA = await Log.fromEntry(ipfs, last(items2))
-        const logB = await Log.fromEntry(ipfs, last(items3))
-        assert.equal(logA.length, items2.length + items1.length)
-        assert.equal(logB.length, items3.length + items2.length + items1.length)
-
-        try {
-          logA.join(logB)
-        } catch (e) {
-          console.error(e)
-        }
-        assert.equal(logA.length, items3.length + items2.length + items1.length)
-        // The last entry, 'entryC100', should be the only head
-        // (it points to entryB100, entryB100 and entryC99)
-        assert.equal(logA.heads.length, 1)
-      })
-
-      it('throws an error if first log is not defined', async () => {
-        let err
-        try {
-          await log1.join()
-        } catch (e) {
-          err = e
-        }
-        assert.notEqual(err, null)
-        assert.equal(err.message, 'Log instance not defined')
-      })
-
-      it('throws an error if passed argument is not an instance of Log', async () => {
-        let err
-        try {
-          await log1.join({})
-        } catch(e) {
-          err = e
-        }
-        assert.notEqual(err, null)
-        assert.equal(err.message, 'Given argument is not an instance of Log')
-      })
-
-      it('joins only unique items', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        log1.join(log2)
-
-        const expectedData = [
-          'helloA1', 'helloB1', 'helloA2', 'helloB2',
-        ]
-
-        assert.equal(log1.length, 4)
-        assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-
-        const item = last(log1.values)
-        assert.equal(item.next.length, 1)
-      })
-
-      it('joins logs two ways', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        log2.join(log1)
-
-
-        const expectedData = [
-          'helloA1', 'helloB1', 'helloA2', 'helloB2',
-        ]
-
-        assert.deepEqual(log1.values.map((e) => e.hash), log2.values.map((e) => e.hash))
-        assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-        assert.deepEqual(log2.values.map((e) => e.payload), expectedData)
-      })
-
-      it('joins logs twice', async () => {
-        await log1.append('helloA1')
-        await log2.append('helloB1')
-        log2.join(log1)
-
-        await log1.append('helloA2')
-        await log2.append('helloB2')
-        log2.join(log1)
-
-        const expectedData = [
-          'helloA1', 'helloB1', 'helloA2', 'helloB2',
-        ]
-
-        assert.equal(log2.length, 4)
-        assert.deepEqual(log2.values.map((e) => e.payload), expectedData)
-      })
-
-      it('joins 2 logs two ways', async () => {
-        await log1.append('helloA1')
-        await log2.append('helloB1')
-        log2.join(log1) // Make sure we keep the original log id
-        log1.join(log2)
-
-        await log1.append('helloA2')
-        await log2.append('helloB2')
-        log2.join(log1)
-
-        const expectedData = [
-          'helloA1', 'helloB1', 'helloA2', 'helloB2',
-        ]
-
-        assert.equal(log2.length, 4)
-        assert.deepEqual(log2.values.map((e) => e.payload), expectedData)
-      })
-
-      it('joins 4 logs to one', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        await log4.append('helloD1')
-        await log4.append('helloD2')
-        log1.join(log2)
-        log1.join(log3)
-        log1.join(log4)
-
-        const expectedData = [
-          'helloA1',
-          'helloB1',
-          'helloC1',
-          'helloD1',
-          'helloA2',
-          'helloB2',
-          'helloC2',
-          'helloD2',
-        ]
-
-        assert.equal(log1.length, 8)
-        assert.deepEqual(log1.values.map(e => e.payload), expectedData)
-      })
-
-      it('joins 4 logs to one is commutative', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        await log4.append('helloD1')
-        await log4.append('helloD2')
-        log1.join(log2)
-        log1.join(log3)
-        log1.join(log4)
-        log2.join(log1)
-        log2.join(log3)
-        log2.join(log4)
-
-        assert.equal(log1.length, 8)
-        assert.deepEqual(log1.values.map(e => e.payload), log2.values.map(e => e.payload))
-      })
-
-      it('joins logs and updates clocks', async () => {
-        await log1.append('helloA1')
-        await log2.append('helloB1')
-        log2.join(log1)
-
-        assert.equal(log2.length, 2)
-        assert.equal(log1.length, 1)
-
-        await log1.append('helloA2')
-        await log2.append('helloB2')
-
-        assert.equal(log1.length, 2)
-        assert.equal(log2.length, 3)
-
-        assert.equal(log1.clock.id, 'A')
-        assert.equal(log2.clock.id, 'B')
-        assert.equal(log1.clock.time, 2)
-        assert.equal(log2.clock.time, 2)
-
-        log3.join(log1)
-
-        assert.equal(log3.id, 'X')
-        assert.equal(log3.clock.id, 'C')
-        assert.equal(log3.clock.time, 2)
-        assert.equal(log3.length, 2)
-
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        assert.equal(log3.length, 4)
-        log1.join(log3)
-        assert.equal(log1.length, 4)
-        log1.join(log2)
-        assert.equal(log1.length, 6)
-        await log4.append('helloD1')
-        await log4.append('helloD2')
-        assert.equal(log4.length, 2)
-        log4.join(log2)
-        assert.equal(log4.length, 5)
-        log4.join(log1)
-        assert.equal(log4.length, 8)
-        log4.join(log3)
-        assert.equal(log4.length, 8)
-        await log4.append('helloD3')
-        await log4.append('helloD4')
-        assert.equal(log4.length, 10)
-        log1.join(log4)
-        assert.equal(log1.length, 10)
-        log4.join(log1)
-        assert.equal(log4.length, 10)
-        await log4.append('helloD5')
-        assert.equal(log4.length, 11)
-        await log1.append('helloA5')
-        assert.equal(log1.length, 11)
-        log4.join(log1)
-        assert.equal(log4.length, 12)
-        assert.deepEqual(log4.clock.id, 'D')
-        assert.deepEqual(log4.clock.time, 7)
-        assert.equal(log4.length, 12)
-
-        await log4.append('helloD6')
-        assert.deepEqual(log4.clock.time, 8)
-
-        const expectedData = [
-          { payload: 'helloA1', id: 'X', clock: { id: 'A', time: 1} },
-          { payload: 'helloB1', id: 'X', clock: { id: 'B', time: 1} },
-          { payload: 'helloD1', id: 'X', clock: { id: 'D', time: 1} },
-          { payload: 'helloA2', id: 'X', clock: { id: 'A', time: 2} },
-          { payload: 'helloB2', id: 'X', clock: { id: 'B', time: 2} },
-          { payload: 'helloD2', id: 'X', clock: { id: 'D', time: 2} },
-          { payload: 'helloC1', id: 'X', clock: { id: 'C', time: 3} },
-          { payload: 'helloC2', id: 'X', clock: { id: 'C', time: 4} },
-          { payload: 'helloD3', id: 'X', clock: { id: 'D', time: 5} },
-          { payload: 'helloD4', id: 'X', clock: { id: 'D', time: 6} },
-          { payload: 'helloA5', id: 'X', clock: { id: 'A', time: 7} },
-          { payload: 'helloD5', id: 'X', clock: { id: 'D', time: 7} },
-          { payload: 'helloD6', id: 'X', clock: { id: 'D', time: 8} },
-        ]
-
-        const transformed = log4.values.map((e) => {
-          return { payload: e.payload, id: e.id, clock: e.clock }
-        })
-
-        assert.equal(log4.length, 13)
-        assert.deepEqual(transformed, expectedData)
-      })
-
-      it('joins logs from 4 logs', async () => {
-        await log1.append('helloA1')
-        log1.join(log2)
-        await log2.append('helloB1')
-        log2.join(log1)
-        await log1.append('helloA2')
-        await log2.append('helloB2')
-
-        log1.join(log3)
-        assert.equal(log1.id, 'X')
-        assert.equal(log1.clock.id, 'A')
-        assert.equal(log1.clock.time, 2)
-
-        log3.join(log1)
-        assert.equal(log3.id, 'X')
-        assert.equal(log3.clock.id, 'C')
-        assert.equal(log3.clock.time, 2)
-
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log1.join(log3)
-        log1.join(log2)
-        await log4.append('helloD1')
-        await log4.append('helloD2')
-        log4.join(log2)
-        log4.join(log1)
-        log4.join(log3)
-        await log4.append('helloD3')
-        await log4.append('helloD4')
-
-        assert.equal(log4.clock.id, 'D')
-        assert.equal(log4.clock.time, 6)
-
-        const expectedData = [
-          'helloA1',
-          'helloB1',
-          'helloD1',
-          'helloA2',
-          'helloB2',
-          'helloD2',
-          'helloC1',
-          'helloC2',
-          'helloD3',
-          'helloD4',
-        ]
-
-        assert.equal(log4.length, 10)
-        assert.deepEqual(log4.values.map((e) => e.payload), expectedData)
-      })
-
-      describe('takes length as an argument', async () => {
-        beforeEach(async () => {
-          await log1.append('helloA1')
-          await log1.append('helloA2')
-          await log2.append('helloB1')
-          await log2.append('helloB2')
-        })
-
-        it('joins only specified amount of entries - one entry', async () => {
-          await log1.join(log2, 1)
-
-          const expectedData = [
-            'helloB2',
-          ]
-          const lastEntry = last(log1.values)
-
-          assert.equal(log1.length, 1)
-          assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-          assert.equal(lastEntry.next.length, 1)
-        })
-
-        it('joins only specified amount of entries - two entries', async () => {
-          await log1.join(log2, 2)
-
-          const expectedData = [
-            'helloA2', 'helloB2',
-          ]
-          const lastEntry = last(log1.values)
-
-          assert.equal(log1.length, 2)
-          assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-          assert.equal(lastEntry.next.length, 1)
-        })
-
-        it('joins only specified amount of entries - three entries', async () => {
-          await log1.join(log2, 3)
-
-          const expectedData = [
-            'helloB1', 'helloA2', 'helloB2',
-          ]
-          const lastEntry = last(log1.values)
-
-          assert.equal(log1.length, 3)
-          assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-          assert.equal(lastEntry.next.length, 1)
-        })
-
-        it('joins only specified amount of entries - (all) four entries', async () => {
-          await log1.join(log2, 4)
-
-          const expectedData = [
-            'helloA1', 'helloB1', 'helloA2', 'helloB2',
-          ]
-          const lastEntry = last(log1.values)
-
-          assert.equal(log1.length, 4)
-          assert.deepEqual(log1.values.map((e) => e.payload), expectedData)
-          assert.equal(lastEntry.next.length, 1)
-        })
-      })
-    })
-
-    describe('fromEntry', () => {
-      it('creates a log from an entry', async () => {
-        let fixture = await LogCreator.createLog1(ipfs)
-        let data = fixture.log
-
-        let log = await Log.fromEntry(ipfs, data.heads)
-        assert.equal(log.id, data.heads[0].id)
-        assert.equal(log.length, 16)
-        assert.deepEqual(log.values.map(e => e.payload), fixture.expectedData)
-      })
-
-      it('keeps the original heads', async () => {
-        let fixture = await LogCreator.createLog1(ipfs)
-        let data = fixture.log
-
-        let log1 = await Log.fromEntry(ipfs, data.heads, data.heads.length)
-        assert.equal(log1.id, data.heads[0].id)
-        assert.equal(log1.length, data.heads.length)
-        assert.equal(log1.values[0].payload, 'entryC0')
-        assert.equal(log1.values[1].payload, 'entryA10')
-
-        let log2 = await Log.fromEntry(ipfs, data.heads, 4)
-        assert.equal(log2.id, data.heads[0].id)
-        assert.equal(log2.length, 4)
-        assert.equal(log2.values[0].payload, 'entryC0')
-        assert.equal(log2.values[1].payload, 'entryA8')
-        assert.equal(log2.values[2].payload, 'entryA9')
-        assert.equal(log2.values[3].payload, 'entryA10')
-
-        let log3 = await Log.fromEntry(ipfs, data.heads, 7)
-        assert.equal(log3.id, data.heads[0].id)
-        assert.equal(log3.length, 7)
-        assert.equal(log3.values[0].payload, 'entryB5')
-        assert.equal(log3.values[1].payload, 'entryA6')
-        assert.equal(log3.values[2].payload, 'entryC0')
-        assert.equal(log3.values[3].payload, 'entryA7')
-        assert.equal(log3.values[4].payload, 'entryA8')
-        assert.equal(log3.values[5].payload, 'entryA9')
-        assert.equal(log3.values[6].payload, 'entryA10')
-      })
-
-      it('onProgress callback is fired for each entry', async () => {
-        const log1 = new Log(ipfs, 'A')
-        let items1 = []
-        const amount = 100
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const n1 = await Entry.create(ipfs, null, 'A', 'entryA' + i, [prev1])
-          items1.push(n1)
-        }
-
-        let i = 0
-        let prevDepth = 0
-        const callback = (hash, entry, depth) => {
-          assert.notEqual(entry, null)
-          assert.equal(hash, items1[items1.length - i - 1].hash)
-          assert.equal(entry.hash, items1[items1.length - i - 1].hash)
-          assert.equal(entry.payload, items1[items1.length - i - 1].payload)
-          assert.equal(depth - 1, i)
-
-          i ++
-          prevDepth = depth
-        }
-
-        const a = await Log.fromEntry(ipfs, last(items1), -1, [], callback)
-      })
-
-      it('retrieves partial log from an entry hash', async () => {
-        const log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        const log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        const log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        const amount = 100
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const prev2 = last(items2)
-          const prev3 = last(items3)
-          const n1 = await Entry.create(ipfs, null, 'A', 'entryA' + i, [prev1])
-          const n2 = await Entry.create(ipfs, null, 'B', 'entryB' + i, [prev2, n1])
-          const n3 = await Entry.create(ipfs, null, 'C', 'entryC' + i, [prev3, n2])
-          items1.push(n1)
-          items2.push(n2)
-          items3.push(n3)
-        }
-
-        // limit to 10 entries
-        const a = await Log.fromEntry(ipfs, last(items1), 10)
-        assert.equal(a.length, 10)
-
-        // limit to 42 entries
-        const b = await Log.fromEntry(ipfs, last(items1), 42)
-        assert.equal(b.length, 42)
-      })
-
-      it('throws an error if trying to create a log from a hash of an entry', async () => {
-        const log1 = new Log(ipfs, 'A')
-        let items1 = []
-        const amount = 5
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const n1 = await Entry.create(ipfs, null, 'A', 'entryA' + i, [prev1])
-          items1.push(n1)
-        }
-
-        let err
-        try {
-          await Log.fromEntry(ipfs, last(items1).hash, 1)
-        } catch (e) {
-          err = e
-        }
-        assert.equal(err.message, `'sourceEntries' argument must be an array of Entry instances or a single Entry`)
-      })
-
-      describe('fetches a log', () => {
-        const amount = 100
-
-        let log1
-        let log2
-        let log3
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        let result
-
-        beforeEach(async () => {
-          log1 = new Log(ipfs, 'X', null, null, null, 'A')
-          log2 = new Log(ipfs, 'X', null, null, null, 'B')
-          log3 = new Log(ipfs, 'X', null, null, null, 'C')
-          items1 = []
-          items2 = []
-          items3 = []
-          for(let i = 1; i <= amount; i ++) {
-            const prev1 = last(items1)
-            const prev2 = last(items2)
-            const prev3 = last(items3)
-            const n1 = await Entry.create(ipfs, null, log1.id, 'entryA' + i, [prev1], log1.clock)
-            const n2 = await Entry.create(ipfs, null, log2.id, 'entryB' + i, [prev2, n1], log2.clock)
-            const n3 = await Entry.create(ipfs, null, log3.id, 'entryC' + i, [prev3, n2], log3.clock)
-            log1.clock.tick()
-            log2.clock.tick()
-            log3.clock.tick()
-            log1.clock.merge(log2.clock)
-            log1.clock.merge(log3.clock)
-            log2.clock.merge(log1.clock)
-            log2.clock.merge(log3.clock)
-            log3.clock.merge(log1.clock)
-            log3.clock.merge(log2.clock)
-            items1.push(n1)
-            items2.push(n2)
-            items3.push(n3)
-          }
-        })
-
-        it('returns all entries - no excluded entries', async () => {
-          const a = await Log.fromEntry(ipfs, last(items1))
-          assert.equal(a.length, amount)
-          assert.equal(a.values[0].hash, items1[0].hash)
-        })
-
-        it('returns all entries - including excluded entries', async () => {
-          // One entry
-          const a = await Log.fromEntry(ipfs, last(items1), -1, [items1[0]])
-          assert.equal(a.length, amount)
-          assert.equal(a.values[0].hash, items1[0].hash)
-
-          // All entries
-          const b = await Log.fromEntry(ipfs, last(items1), -1, items1)
-          assert.equal(b.length, amount)
-          assert.equal(b.values[0].hash, items1[0].hash)
-        })
-      })
-
-      it('retrieves full log from an entry hash', async () => {
-        const log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        const log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        const log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        const amount = 10
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const prev2 = last(items2)
-          const prev3 = last(items3)
-          const n1 = await Entry.create(ipfs, null, 'X', 'entryA' + i, [prev1])
-          const n2 = await Entry.create(ipfs, null, 'X', 'entryB' + i, [prev2, n1])
-          const n3 = await Entry.create(ipfs, null, 'X', 'entryC' + i, [prev3, n2])
-          items1.push(n1)
-          items2.push(n2)
-          items3.push(n3)
-        }
-
-        const a = await Log.fromEntry(ipfs, [last(items1)], amount)
-        assert.equal(a.length, amount)
-
-        const b = await Log.fromEntry(ipfs, [last(items2)], amount * 2)
-        assert.equal(b.length, amount * 2)
-
-        const c = await Log.fromEntry(ipfs, [last(items3)], amount * 3)
-        assert.equal(c.length, amount * 3)
-      })
-
-      it('retrieves full log from an entry hash 2', async () => {
-        const log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        const log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        const log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        const amount = 10
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const prev2 = last(items2)
-          const prev3 = last(items3)
-          const n1 = await Entry.create(ipfs, null, 'X', 'entryA' + i, [prev1])
-          const n2 = await Entry.create(ipfs, null, 'X', 'entryB' + i, [prev2, n1])
-          const n3 = await Entry.create(ipfs, null, 'X', 'entryC' + i, [prev3, n1, n2])
-          items1.push(n1)
-          items2.push(n2)
-          items3.push(n3)
-        }
-
-        const a = await Log.fromEntry(ipfs, last(items1), amount)
-        assert.equal(a.length, amount)
-
-        const b = await Log.fromEntry(ipfs, last(items2), amount * 2)
-        assert.equal(b.length, amount * 2)
-
-        const c = await Log.fromEntry(ipfs, last(items3), amount * 3)
-        assert.equal(c.length, amount * 3)
-      })
-
-      it('retrieves full log from an entry hash 3', async () => {
-        let log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        let log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let items1 = []
-        let items2 = []
-        let items3 = []
-        const amount = 10
-        for(let i = 1; i <= amount; i ++) {
-          const prev1 = last(items1)
-          const prev2 = last(items2)
-          const prev3 = last(items3)
-          log1.clock.tick()
-          log2.clock.tick()
-          log3.clock.tick()
-          const n1 = await Entry.create(ipfs, null, 'X', 'entryA' + i, [prev1], log1.clock)
-          const n2 = await Entry.create(ipfs, null, 'X', 'entryB' + i, [prev2, n1], log2.clock)
-          const n3 = await Entry.create(ipfs, null, 'X', 'entryC' + i, [prev3, n1, n2], log3.clock)
-          log1.clock.merge(log2.clock)
-          log1.clock.merge(log3.clock)
-          log2.clock.merge(log1.clock)
-          log2.clock.merge(log3.clock)
-          log3.clock.merge(log1.clock)
-          log3.clock.merge(log2.clock)
-          items1.push(n1)
-          items2.push(n2)
-          items3.push(n3)
-        }
-
-        const a = await Log.fromEntry(ipfs, last(items1), amount)
-        assert.equal(a.length, amount)
-
-        const itemsInB = [
-          'entryA1',
-          'entryB1',
-          'entryA2',
-          'entryB2',
-          'entryA3',
-          'entryB3',
-          'entryA4',
-          'entryB4',
-          'entryA5',
-          'entryB5',
-          'entryA6',
-          'entryB6',
-          'entryA7',
-          'entryB7',
-          'entryA8',
-          'entryB8',
-          'entryA9',
-          'entryB9',
-          'entryA10',
-          'entryB10'
-        ]
-
-        const b = await Log.fromEntry(ipfs, last(items2), amount * 2)
-        assert.equal(b.length, amount * 2)
-        assert.deepEqual(itemsInB, b.values.map((e) => e.payload))
-
-        let c = await Log.fromEntry(ipfs, last(items3), amount * 3)
-        await c.append('EOF')
-        assert.equal(c.length, amount * 3 + 1)
-
-        const tmp = [
-          'entryA1',
-          'entryB1',
-          'entryC1',
-          'entryA2',
-          'entryB2',
-          'entryC2',
-          'entryA3',
-          'entryB3',
-          'entryC3',
-          'entryA4',
-          'entryB4',
-          'entryC4',
-          'entryA5',
-          'entryB5',
-          'entryC5',
-          'entryA6',
-          'entryB6',
-          'entryC6',
-          'entryA7',
-          'entryB7',
-          'entryC7',
-          'entryA8',
-          'entryB8',
-          'entryC8',
-          'entryA9',
-          'entryB9',
-          'entryC9',
-          'entryA10',
-          'entryB10',
-          'entryC10',
-          'EOF'
-        ]
-        assert.deepEqual(c.values.map(e => e.payload), tmp)
-
-        let logX = new Log(ipfs, 'X') // make sure logX comes after A, B and C
-        await logX.append('1')
-        await logX.append('2')
-        await logX.append('3')
-        const d = await Log.fromEntry(ipfs, last(logX.values))
-
-        c.join(d)
-        d.join(c)
-
-        await c.append('DONE')
-        await d.append('DONE')
-        const f = await Log.fromEntry(ipfs, last(c.values), -1, [])
-        const g = await Log.fromEntry(ipfs, last(d.values), -1, [])
-
-        assert.equal(f.toString(), bigLogString)
-        assert.equal(g.toString(), bigLogString)
-      })
-
-      it('retrieves full log of randomly joined log', async () => {
-        let log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        let log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-
-        for(let i = 1; i <= 5; i ++) {
-          await log1.append('entryA' + i)
-        }
-
-        for(let i = 1; i <= 5; i ++) {
-          await log2.append('entryB' + i)
-        }
-
-        log3.join(log1)
-        log3.join(log2)
-
-        for(let i = 6; i <= 10; i ++) {
-          await log1.append('entryA' + i)
-        }
-
-        log1.join(log3)
-
-        for(let i = 11; i <= 15; i ++) {
-          await log1.append('entryA' + i)
-        }
-
-        const expectedData = [
-          'entryA1', 'entryB1', 'entryA2', 'entryB2',
-          'entryA3', 'entryB3', 'entryA4', 'entryB4',
-          'entryA5', 'entryB5',
-          'entryA6', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-          'entryA11', 'entryA12', 'entryA13', 'entryA14', 'entryA15'
-        ]
-
-        assert.deepEqual(log1.values.map(e => e.payload), expectedData)
-      })
-
-      it('retrieves randomly joined log deterministically', async () => {
-        let logA = new Log(ipfs, 'X', null, null, null, 'A')
-        let logB = new Log(ipfs, 'X', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let log  = new Log(ipfs, 'X', null, null, null, 'D')
-
-        for(let i = 1; i <= 5; i ++) {
-          await logA.append('entryA' + i)
-        }
-
-        for(let i = 1; i <= 5; i ++) {
-          await logB.append('entryB' + i)
-        }
-
-        log3.join(logA)
-        log3.join(logB)
-
-        for(let i = 6; i <= 10; i ++) {
-          await logA.append('entryA' + i)
-        }
-
-        log.join(log3)
-        await log.append('entryC0')
-        log.join(logA, 16)
-
-        const expectedData = [
-          'entryA1', 'entryB1', 'entryA2', 'entryB2',
-          'entryA3', 'entryB3', 'entryA4', 'entryB4',
-          'entryA5', 'entryB5',
-          'entryA6',
-          'entryC0', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(log.values.map(e => e.payload), expectedData)
-      })
-
-      it('sorts', async () => {
-        let testLog = await LogCreator.createLog1(ipfs)
-        let log = testLog.log
-        const expectedData = testLog.expectedData
-
-        const expectedData2 = [
-          'entryA1', 'entryB1', 'entryA2', 'entryB2',
-          'entryA3', 'entryB3', 'entryA4', 'entryB4',
-          'entryA5', 'entryB5',
-          'entryA6', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        const expectedData3 = [
-          'entryA1', 'entryB1', 'entryA2', 'entryB2',
-          'entryA3', 'entryB3', 'entryA4', 'entryB4',
-          'entryA5', 'entryB5', 'entryA6', 'entryC0',
-          'entryA7', 'entryA8', 'entryA9',
-        ]
-
-        const expectedData4 = [
-          'entryA1', 'entryB1', 'entryA2', 'entryB2',
-          'entryA3', 'entryB3', 'entryA4', 'entryB4',
-          'entryA5', 'entryA6', 'entryC0', 'entryA7',
-          'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        let fetchOrder = log.values.slice().sort(Entry.compare)
-        assert.deepEqual(fetchOrder.map(e => e.payload), expectedData)
-
-        let reverseOrder = log.values.slice().reverse().sort(Entry.compare)
-        assert.deepEqual(fetchOrder, reverseOrder)
-
-        let hashOrder = log.values.slice().sort((a, b) => a.hash > b.hash).sort(Entry.compare)
-        assert.deepEqual(fetchOrder, hashOrder)
-
-        let randomOrder2 = log.values.slice().sort((a, b) => 0.5 - Math.random()).sort(Entry.compare)
-        assert.deepEqual(fetchOrder, randomOrder2)
-
-        // partial data
-        let partialLog = log.values.filter(e => e.payload !== 'entryC0').sort(Entry.compare)
-        assert.deepEqual(partialLog.map(e => e.payload), expectedData2)
-
-        let partialLog2 = log.values.filter(e => e.payload !== 'entryA10').sort(Entry.compare)
-        assert.deepEqual(partialLog2.map(e => e.payload), expectedData3)
-
-        let partialLog3 = log.values.filter(e => e.payload !== 'entryB5').sort(Entry.compare)
-        assert.deepEqual(partialLog3.map(e => e.payload), expectedData4)
-      })
-
-      it('sorts deterministically from random order', async () => {
-        let testLog = await LogCreator.createLog1(ipfs)
-        let log = testLog.log
-        const expectedData = testLog.expectedData
-
-        let fetchOrder = log.values.slice().sort(Entry.compare)
-        assert.deepEqual(fetchOrder.map(e => e.payload), expectedData)
-
-        let sorted
-        for (let i = 0; i < 1000; i ++) {
-          const randomOrder = log.values.slice().sort((a, b) => 0.5 - Math.random())
-          sorted = randomOrder.sort(Entry.compare)
-          assert.deepEqual(sorted.map(e => e.payload), expectedData)
-        }
-      })
-
-      it('sorts entries correctly', async () => {
-        let testLog = await LogCreator.createLog100_2(ipfs)
-        let log = testLog.log
-        const expectedData = testLog.expectedData
-        assert.deepEqual(log.values.map(e => e.payload), expectedData)
-      })
-
-      it('retrieves partially joined log deterministically - single next pointer', async () => {
-        const nextPointerAmount = 0
-
-        let logA = new Log(ipfs, 'X', null, null, null, 'A')
-        let logB = new Log(ipfs, 'X', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let log  = new Log(ipfs, 'X', null, null, null, 'D')
-
-        for(let i = 1; i <= 5; i ++) {
-          await logA.append('entryA' + i, nextPointerAmount)
-        }
-
-        for(let i = 1; i <= 5; i ++) {
-          await logB.append('entryB' + i, nextPointerAmount)
-        }
-
-        log3.join(logA)
-        log3.join(logB)
-
-        for(let i = 6; i <= 10; i ++) {
-          await logA.append('entryA' + i, nextPointerAmount)
-        }
-
-        log.join(log3)
-        await log.append('entryC0', nextPointerAmount)
-
-        log.join(logA)
-
-        const mh = await log.toMultihash()
-
-        // First 5
-        let res = await Log.fromMultihash(ipfs, mh, 5)
-
-        const first5 = [
-          'entryC0', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(res.values.map(e => e.payload), first5)
-
-        // First 11
-        res = await Log.fromMultihash(ipfs, mh, 11)
-
-        const first11 = [
-          'entryB3', 'entryA4', 'entryB4', 'entryA5', 'entryB5',
-          'entryA6',
-          'entryC0', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(res.values.map(e => e.payload), first11)
-
-        // All but one
-        res = await Log.fromMultihash(ipfs, mh, 16 - 1)
-
-        const all = [
-          'entryB1', /* excl */ 'entryA2', 'entryB2', 'entryA3', 'entryB3',
-          'entryA4', 'entryB4', 'entryA5', 'entryB5',
-          'entryA6',
-          'entryC0', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(res.values.map(e => e.payload), all)
-      })
-
-      it('retrieves partially joined log deterministically - multiple next pointers', async () => {
-        const nextPointersAmount = 64
-
-        let logA = new Log(ipfs, 'X', null, null, null, 'A')
-        let logB = new Log(ipfs, 'X', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        let log  = new Log(ipfs, 'X', null, null, null, 'D')
-
-        for(let i = 1; i <= 5; i ++) {
-          await logA.append('entryA' + i, nextPointersAmount)
-        }
-
-        for(let i = 1; i <= 5; i ++) {
-          await logB.append('entryB' + i, nextPointersAmount)
-        }
-
-        log3.join(logA)
-        log3.join(logB)
-
-        for(let i = 6; i <= 10; i ++) {
-          await logA.append('entryA' + i, nextPointersAmount)
-        }
-
-        log.join(log3)
-        await log.append('entryC0', nextPointersAmount)
-
-        log.join(logA)
-
-        const first5 = [
-          'entryA6', 'entryC0', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        // assert.deepEqual(log.values.map(e => e.payload).slice(-5), first5)
-
-        const mh = await log.toMultihash()
-
-        // First 6
-        let res = await Log.fromMultihash(ipfs, mh, 5)
-        assert.deepEqual(res.values.map(e => e.payload), first5)
-
-        // First 11
-        res = await Log.fromMultihash(ipfs, mh, 11)
-
-        const first11 = [
-             'entryB3', 'entryA4', 'entryB4', 'entryA5', 'entryB5',
-             'entryA6',
-             'entryC0',
-             'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(res.values.map(e => e.payload), first11)
-
-        // All but one
-        res = await Log.fromMultihash(ipfs, mh, 16 - 1)
-
-        assert.equal(res.values.length, 15)
-        const all = [
-          /* excl */ 'entryB1', 'entryA2', 'entryB2', 'entryA3', 'entryB3',
-          'entryA4', 'entryB4', 'entryA5', 'entryB5',
-          'entryA6',
-          'entryC0', 'entryA7', 'entryA8', 'entryA9', 'entryA10',
-        ]
-
-        assert.deepEqual(res.values.map(e => e.payload), all)
-      })
-
-      it('throws an error if ipfs is not defined', async () => {
-        let err
-        try {
-          await Log.fromEntry()
-        } catch (e) {
-          err = e
-        }
-        assert.notEqual(err, null)
-        assert.equal(err.message, 'ImmutableDB instance not defined')
-      })
-    })
-
-    describe('heads', () => {
-      it('finds one head after one entry', async () => {
-        let log1 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        assert.equal(log1.heads.length, 1)
-      })
-
-      it('finds one head after two entries', async () => {
-        let log1 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        assert.equal(log1.heads.length, 1)
-      })
-
-      it('log contains the head entry', async () => {
-        let log1 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        assert.deepEqual(log1.get(log1.heads[0].hash), log1.heads[0])
-      })
-
-      it('finds head after a join and append', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-
-        log2.join(log1)
-        await log2.append('helloB2')
-        const expectedHead = last(log2.values)
-
-        assert.equal(log2.heads.length, 1)
-        assert.deepEqual(log2.heads[0].hash, expectedHead.hash)
-      })
-
-      it('finds two heads after a join', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        const expectedHead1 = last(log1.values)
-
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        const expectedHead2 = last(log2.values)
-
-        log1.join(log2)
-
-        const heads = log1.heads
-        assert.equal(heads.length, 2)
-        assert.equal(heads[0].hash, expectedHead1.hash)
-        assert.equal(heads[1].hash, expectedHead2.hash)
-      })
-
-      it('finds two heads after two joins', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-
-        log1.join(log2)
-
-        await log2.append('helloB3')
-
-        await log1.append('helloA3')
-        await log1.append('helloA4')
-        const expectedHead2 = last(log2.values)
-        const expectedHead1 = last(log1.values)
-
-        log1.join(log2)
-
-        const heads = log1.heads
-        assert.equal(heads.length, 2)
-        assert.equal(heads[0].hash, expectedHead1.hash)
-        assert.equal(heads[1].hash, expectedHead2.hash)
-      })
-
-      it('finds two heads after three joins', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        let log3 = new Log(ipfs, 'A')
-
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        await log1.append('helloA3')
-        await log1.append('helloA4')
-        const expectedHead1 = last(log1.values)
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log2.join(log3)
-        await log2.append('helloB3')
-        const expectedHead2 = last(log2.values)
-        log1.join(log2)
-
-        const heads = log1.heads
-        assert.equal(heads.length, 2)
-        assert.equal(heads[0].hash, expectedHead1.hash)
-        assert.equal(heads[1].hash, expectedHead2.hash)
-      })
-
-      it('finds three heads after three joins', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        let log3 = new Log(ipfs, 'A')
-
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        await log1.append('helloA3')
-        await log1.append('helloA4')
-        const expectedHead1 = last(log1.values)
-        await log3.append('helloC1')
-        await log2.append('helloB3')
-        await log3.append('helloC2')
-        const expectedHead2 = last(log2.values)
-        const expectedHead3 = last(log3.values)
-        log1.join(log2)
-        log1.join(log3)
-
-        const heads = log1.heads
-        assert.equal(heads.length, 3)
-        assert.deepEqual(heads[0].hash, expectedHead1.hash)
-        assert.deepEqual(heads[1].hash, expectedHead2.hash)
-        assert.deepEqual(heads[2].hash, expectedHead3.hash)
-      })
-    })
-
-    describe('tails', () => {
-      it('returns a tail', async () => {
-        let log1 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        assert.equal(log1.tails.length, 1)
-      })
-
-      it('tail is a Entry', async () => {
-        let log1 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        assert.equal(Entry.isEntry(log1.tails[0]), true)
-      })
-
-      it('returns tail entries', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log2.append('helloB1')
-        log1.join(log2)
-        assert.equal(log1.tails.length, 2)
-        assert.equal(Entry.isEntry(log1.tails[0]), true)
-        assert.equal(Entry.isEntry(log1.tails[1]), true)
-      })
-
-      it('returns tail hashes', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2, 2)
-        assert.equal(log1.tailHashes.length, 2)
-      })
-
-      it('returns no tail hashes if all entries point to empty nexts', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log2.append('helloB1')
-        log1.join(log2)
-        assert.equal(log1.tailHashes.length, 0)
-      })
-
-      it('returns tails after loading a partial log', async () => {
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'A')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log1.join(log2)
-        const log4 = await Log.fromEntry(ipfs, log1.heads, 2)
-        const tails = await log4.tails()
-        const values = await log4.values()
-        assert.equal(log4.length, 2)
-        assert.equal(tails.length, 2)
-        assert.equal(tails[0].hash, values[1].hash)
-        assert.equal(tails[1].hash, values[0].hash)
-      })
-
-      it('returns tails sorted by id', async () => {
-        let log1 = new Log(ipfs, 'XX', null, null, null, 'X')
-        let log2 = new Log(ipfs, 'XX', null, null, null, 'B')
-        let log3 = new Log(ipfs, 'XX', null, null, null, 'A')
-        let log4 = new Log(ipfs, 'XX', null, null, null, 'Y')
-        await log1.append('helloX1')
-        await log2.append('helloB1')
-        await log3.append('helloA1')
-        log3.join(log1)
-        log3.join(log2)
-        log4.join(log3)
-        assert.equal(log4.tails.length, 3)
-        assert.equal(log4.tails[0].id, 'XX')
-        assert.equal(log4.tails[0].clock.id, 'A')
-        assert.equal(log4.tails[1].clock.id, 'B')
-        assert.equal(log4.tails[2].clock.id, 'X')
-      })
-    })
-
-
-    describe('References', () => {
-      it('creates entries with references', async () => {
-        const amount = 64
-        const maxReferenceDistance = 2
-        let log1 = new Log(ipfs, 'A')
-        let log2 = new Log(ipfs, 'B')
-        let log3 = new Log(ipfs, 'C')
-        let log4 = new Log(ipfs, 'D')
-
-        for (let i = 0; i < amount; i ++) {
-          await log1.append(i.toString(), maxReferenceDistance)
-        }
-
-        for (let i = 0; i < amount * 2; i ++) {
-          await log2.append(i.toString(), Math.pow(maxReferenceDistance, 2))
-        }
-
-        for (let i = 0; i < amount * 3; i ++) {
-          await log3.append(i.toString(), Math.pow(maxReferenceDistance, 3))
-        }
-
-        for (let i = 0; i < amount * 4; i ++) {
-          await log4.append(i.toString(), Math.pow(maxReferenceDistance, 4))
-        }
-
-        assert.equal(log1.values[log1.length - 1].next.length, 1)
-        assert.equal(log2.values[log2.length - 1].next.length, 1)
-        assert.equal(log3.values[log3.length - 1].next.length, 1)
-        assert.equal(log4.values[log4.length - 1].next.length, 1)
-        assert.equal(log1.values[log1.length - 1].refs.length, 2)
-        assert.equal(log2.values[log2.length - 1].refs.length, 3)
-        assert.equal(log3.values[log3.length - 1].refs.length, 4)
-        assert.equal(log4.values[log4.length - 1].refs.length, 5)
-      })
-
-      const inputs = [
-        { amount: 1, referenceCount: 1, refLength: 0 },
-        { amount: 1, referenceCount: 2, refLength: 0 },
-        { amount: 2, referenceCount: 1, refLength: 1 },
-        { amount: 2, referenceCount: 2, refLength: 1 },
-        { amount: 3, referenceCount: 2, refLength: 2 },
-        { amount: 3, referenceCount: 4, refLength: 2 },
-        { amount: 4, referenceCount: 2, refLength: 2 },
-        { amount: 4, referenceCount: 4, refLength: 3 },
-        { amount: 32, referenceCount: 4, refLength: 3 },
-        { amount: 32, referenceCount: 8, refLength: 4 },
-        { amount: 32, referenceCount: 16, refLength: 5 },
-        { amount: 18, referenceCount: 32, refLength: 6 },
-        { amount: 128, referenceCount: 32, refLength: 6 },
-        { amount: 64, referenceCount: 64, refLength: 7 },
-        { amount: 65, referenceCount: 64, refLength: 7 },
-        { amount: 128, referenceCount: 64, refLength: 7 },
-        { amount: 128, referenceCount: 1, refLength: 1 },
-        { amount: 128, referenceCount: 2, refLength: 2 },
-        { amount: 256, referenceCount: 1, refLength: 1 },
-        { amount: 256, referenceCount: 256, refLength: 8 },
-        { amount: 256, referenceCount: 1024, refLength: 8 },
-      ]
-
-      inputs.forEach(input => {
-        it(`has ${input.refLength} references, max distance ${input.referenceCount}, total of ${input.amount} entries`, async () => {
-          const test = async (amount, referenceCount, refLength) => {
-            let log1 = new Log(ipfs, 'A')
-            for (let i = 0; i < amount; i ++) {
-              await log1.append((i + 1).toString(), referenceCount)
-            }
-
-            assert.equal(log1.values.length, input.amount)
-            assert.equal(log1.values[log1.length - 1].clock.time, input.amount)
-
-            for (let k = 0; k < input.amount; k ++) {
-              const idx = log1.length - k - 1
-              assert.equal(log1.values[idx].clock.time, idx + 1)
-
-              // Check the first ref (distance 1)
-              if (log1.values[idx].refs.length > 0)
-                assert.equal(log1.values[idx].refs[0], log1.values[idx - 1].hash)
-
-              // Check the second ref (distance 2)
-              if (log1.values[idx].refs.length > 1)
-                assert.equal(log1.values[idx].refs[1], log1.values[idx - 2].hash)
-
-              // Check the third ref (distance 4)
-              if (log1.values[idx].refs.length > 2 && idx > referenceCount)
-                assert.equal(log1.values[idx].refs[2], log1.values[idx - 4].hash)
-
-              // Check the fourth ref (distance 8)
-              if (log1.values[idx].refs.length > 3 && idx > referenceCount)
-                assert.equal(log1.values[idx].refs[3], log1.values[idx - 8].hash)
-
-              // Check the fifth ref (distance 16)
-              if (log1.values[idx].refs.length > 4 && idx > referenceCount)
-                assert.equal(log1.values[idx].refs[4], log1.values[idx - 16].hash)
-
-              // Check the reference of each entry
-              if (idx > referenceCount)
-                assert.equal(log1.values[idx].refs.length, refLength)
-            }
-          }
-
-          await test(input.amount, input.referenceCount, input.refLength)
-        })
-      })
-    })
-
-    describe('is a CRDT', () => {
-      let log1, log2, log3
-
-      beforeEach(async () => {
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-      })
-
-      it('join is associative', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-
-        // a + (b + c)
-        log2.join(log3)
-        log1.join(log2)
-
-        const res1 = log1.values.slice()//.map((e) => e.hash).join(",")
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-
-        // (a + b) + c
-        log1.join(log2)
-        log3.join(log1)
-
-        const res2 = log3.values.slice()//.map((e) => e.hash).join(",")
-
-        // associativity: a + (b + c) == (a + b) + c
-        const len = 6//(46 + 1) * 6- 1 // 46 == ipfs hash, +1 == .join(","), * 4 == number of items, -1 == last item doesn't get a ',' from .join
-        assert.equal(res1.length, len)
-        assert.equal(res2.length, len)
-        assert.deepEqual(res1, res2)
-      })
-
-      it('join is commutative', async () => {
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-
-        // b + a
-        log2.join(log1)
-        const res1 = log2.values.slice()//.map((e) => e.hash).join(",")
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-
-        // a + b
-        log1.join(log2)
-        const res2 = log1.values.slice()//.map((e) => e.hash).join(",")
-
-        // commutativity: a + b == b + a
-        // const len = (46 + 1) * 4 - 1 // 46 == ipfs hash length, +1 == .join(","), * 4 == number of items, -1 == last item doesn't get a ',' from .join
-        assert.equal(res1.length, 4)
-        assert.equal(res2.length, 4)
-        assert.deepEqual(res1, res2)
-      })
-
-      it('multiple joins are commutative', async () => {
-        // b + a == a + b
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log2.join(log1)
-        const resA1 = log2.toString()
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        const resA2 = log1.toString()
-
-        assert.equal(resA1, resA2)
-
-        // a + b == b + a
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log1.join(log2)
-        const resB1 = log1.toString()
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        log2.join(log1)
-        const resB2 = log2.toString()
-
-        assert.equal(resB1, resB2)
-
-        // a + c == c + a
-        log1 = new Log(ipfs, 'A', null, null, null, 'A')
-        log3 = new Log(ipfs, 'A', null, null, null, 'C')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log3.join(log1)
-        const resC1 = log3.toString()
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log1.join(log3)
-        const resC2 = log1.toString()
-
-        assert.equal(resC1, resC2)
-
-        // c + b == b + c
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log3.join(log2)
-        const resD1 = log3.toString()
-
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log2.join(log3)
-        const resD2 = log2.toString()
-
-        assert.equal(resD1, resD2)
-
-        // a + b + c == c + b + a
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log1.join(log2)
-        log1.join(log3)
-        const logLeft = log1.toString()
-
-        log1 = new Log(ipfs, 'X', null, null, null, 'A')
-        log2 = new Log(ipfs, 'X', null, null, null, 'B')
-        log3 = new Log(ipfs, 'X', null, null, null, 'C')
-        await log1.append('helloA1')
-        await log1.append('helloA2')
-        await log2.append('helloB1')
-        await log2.append('helloB2')
-        await log3.append('helloC1')
-        await log3.append('helloC2')
-        log3.join(log2)
-        log3.join(log1)
-        const logRight = log3.toString()
-
-        assert.equal(logLeft, logRight)
-      })
-
-      it('join is idempotent', async () => {
-        let logA = new Log(ipfs, 'X')
-        await logA.append('helloA1')
-        await logA.append('helloA2')
-        await logA.append('helloA3')
-
-        // idempotence: a + a = a
-        logA.join(logA)
-        assert.equal(logA.length, 3)
-      })
-    })
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/mocha.opts
+++ /dev/null
@@ -1,4 +0,0 @@
---reporter spec
---colors
---recursive
---exit
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/replicate.spec.js
+++ /dev/null
@@ -1,201 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const config = require('./config/ipfs-daemon.config')
-const Log = require('../src/log.js')
-const MemStore = require('../src/utils/mem-store')
-
-const apis = [require('ipfs')]
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-const channel = 'XXX'
-
-// Shared database name
-const waitForPeers = (ipfs, channel) => {
-  return new Promise((resolve, reject) => {
-    console.log("Waiting for peers...")
-    const interval = setInterval(() => {
-      ipfs.pubsub.peers(channel)
-        .then((peers) => {
-          if (peers.length > 0) {
-            console.log("Found peers, running tests...")
-            clearInterval(interval)
-            resolve()
-          }
-        })
-        .catch(reject)
-    }, 200)
-  })
-}
-
-apis.forEach((IPFS) => {
-
-  describe('ipfs-log - Replication', function() {
-    this.timeout(40000)
-
-    let ipfs1, ipfs2, client1, client2, db1, db2, id1, id2
-
-    before(function (done) {
-      rmrf.sync(config.daemon1.repo)
-      rmrf.sync(config.daemon2.repo)
-
-      config.damon1 = Object.assign({}, config.daemon1, { repo: new IPFSRepo(config.daemon1.repo, repoConf) })
-      ipfs1 = new IPFS(config.daemon1)
-      ipfs1.on('error', done)
-      ipfs1.on('ready', () => {
-        ipfs1.id()
-          .then((id) => id1 = id.id)
-          .then(() => {
-            config.damon2 = Object.assign({}, config.daemon2, { repo: new IPFSRepo(config.daemon2.repo, repoConf) })
-            ipfs2 = new IPFS(config.daemon2)
-            ipfs2.on('error', done)
-            ipfs2.on('ready', () => {
-              ipfs2.id()
-                .then((id) => id2 = id.id)
-                .then(async () => {
-
-                  // Use memory store for quicker tests
-                  const memstore = new MemStore()
-                  ipfs1.object.put = memstore.put.bind(memstore)
-                  ipfs1.object.get = memstore.get.bind(memstore)
-                  ipfs2.object.put = memstore.put.bind(memstore)
-                  ipfs2.object.get = memstore.get.bind(memstore)
-
-                  // Connect the peers manually to speed up test times
-                  await ipfs2.swarm.connect(ipfs1._peerInfo.multiaddrs._multiaddrs[0].toString())
-                  await ipfs1.swarm.connect(ipfs2._peerInfo.multiaddrs._multiaddrs[0].toString())
-                  done()
-                })
-            })
-          })
-      })
-    })
-
-    after(async () => {
-      if (ipfs1) 
-        await ipfs1.stop()
-
-      if (ipfs2) 
-        await ipfs2.stop()
-    })
-
-    describe('replicates logs deterministically', function() {
-      const amount = 128 + 1
-
-      let log1, log2, input1, input2
-      let buffer1 = []
-      let buffer2 = []
-      let processing = 0
-
-      const handleMessage = async (message) => {
-        if (id1 === message.from)
-          return
-        buffer1.push(message.data.toString())
-        processing ++
-        const exclude = log1.values.map((e) => e.hash)
-        process.stdout.write('\r')
-        process.stdout.write(`> Buffer1: ${buffer1.length} - Buffer2: ${buffer2.length}`)
-        const log = await Log.fromMultihash(ipfs1, message.data.toString())
-        log1.join(log)
-        processing --
-      }
-
-      const handleMessage2 = async (message) => {
-        if (id2 === message.from)
-          return
-        buffer2.push(message.data.toString())
-        processing ++
-        process.stdout.write('\r')
-        process.stdout.write(`> Buffer1: ${buffer1.length} - Buffer2: ${buffer2.length}`)
-        const exclude = log2.values.map((e) => e.hash)
-        const log = await Log.fromMultihash(ipfs2, message.data.toString())
-        log2.join(log)
-        processing --
-      }
-
-      beforeEach((done) => {
-        log1 = new Log(ipfs1, 'A', null, null, null, 'peerA')
-        log2 = new Log(ipfs2, 'A', null, null, null, 'peerB')
-        input1 = new Log(ipfs1, 'A', null, null, null, 'peerA')
-        input2 = new Log(ipfs2, 'A', null, null, null, 'peerB')
-        ipfs1.pubsub.subscribe(channel, handleMessage, (err) => {
-          if (err) 
-            return done(err)
-          ipfs2.pubsub.subscribe(channel, handleMessage2, (err) => {
-            if (err) 
-              done(err)
-            else 
-              done()
-          })
-        })
-      })
-
-      it('replicates logs', (done) => {
-        waitForPeers(ipfs1, channel)
-          .then(async () => {
-            for(let i = 1; i <= amount; i ++) {
-              await input1.append("A" + i)
-              await input2.append("B" + i)
-              const mh1 = await input1.toMultihash()
-              const mh2 = await input2.toMultihash()
-              await ipfs1.pubsub.publish(channel, Buffer.from(mh1))
-              await ipfs2.pubsub.publish(channel, Buffer.from(mh2))
-            }
-
-            console.log("\nAll messages sent")
-
-            const whileProcessingMessages = (timeoutMs) => {
-              return new Promise((resolve, reject) => {
-                setTimeout(() => reject(new Error('timeout')), timeoutMs)
-                const timer = setInterval(() => {
-                  if (buffer1.length + buffer2.length === amount * 2
-                      && processing === 0) {
-                    console.log("\nAll messages received")
-                    clearInterval(timer)
-                    resolve()
-                  }
-                }, 200)
-              })
-            }
-
-            console.log("Waiting for all to process")
-            try {
-              const timeout = 30000
-              await whileProcessingMessages(timeout)
-
-              let result = new Log(ipfs1, 'A', null, null, null, 'peerA')
-              result.join(log1)
-              result.join(log2)
-
-              assert.equal(buffer1.length, amount)
-              assert.equal(buffer2.length, amount)
-              assert.equal(result.length, amount * 2)
-              assert.equal(log1.length, amount)
-              assert.equal(log2.length, amount)
-              assert.equal(result.values[0].payload, 'A1')
-              assert.equal(result.values[1].payload, 'B1')
-              assert.equal(result.values[2].payload, 'A2')
-              assert.equal(result.values[3].payload, 'B2')
-              assert.equal(result.values[99].payload, 'B50')
-              assert.equal(result.values[100].payload, 'A51')
-              assert.equal(result.values[198].payload, 'A100')
-              assert.equal(result.values[199].payload, 'B100')
-              done()
-            } catch(e) {
-              done(e)
-            }
-
-          })
-          .catch(done)
-      })
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/signed-log.spec.js
+++ /dev/null
@@ -1,266 +0,0 @@
-'use strict'
-
-const assert = require('assert')
-const rmrf = require('rimraf')
-const IPFSRepo = require('ipfs-repo')
-const DatastoreLevel = require('datastore-level')
-const Keystore = require('orbit-db-keystore')
-const Log = require('../src/log.js')
-
-const apis = [require('ipfs')]
-
-const dataDir = './ipfs/tests/log'
-
-const repoConf = {
-  storageBackends: {
-    blocks: DatastoreLevel,
-  },
-}
-
-const ipfsConf = { 
-  repo: new IPFSRepo(dataDir, repoConf),
-  EXPERIMENTAL: {
-    pubsub: true,
-    dht: false,
-    sharding: false,
-  },
-}
-
-let ipfs, key1, key2, key3
-
-const last = (arr) => {
-  return arr[arr.length - 1]
-}
-
-apis.forEach((IPFS) => {
-  describe('Signed Log', function() {
-    this.timeout(10000)
-
-    const keystore = Keystore.create('./test/fixtures/keystore')
-
-    before((done) => {
-      rmrf.sync(dataDir)
-      key1 = keystore.getKey('A')
-      key2 = keystore.getKey('B')
-      key3 = keystore.getKey('C')
-      ipfs = new IPFS(ipfsConf)
-      ipfs.keystore = keystore 
-      ipfs.on('error', done)
-      ipfs.on('ready', () => done())
-    })
-
-    after(async () => {
-      if (ipfs) 
-        await ipfs.stop()
-    })
-
-    it('creates a signed log', () => {
-      const log = new Log(ipfs, 'A', null, null, null, key1)
-      assert.notEqual(log.id, null)
-      assert.deepEqual(log._key, key1)
-      assert.deepEqual(log._keys, [])
-    })
-
-    it('takes an array of write-access public keys as an argument', () => {
-      const log = new Log(ipfs, 'A', null, null, null, key1, [key2.getPublic('hex'), key3.getPublic('hex')])
-      assert.notEqual(log.id, null)
-      assert.deepEqual(log._key, key1)
-      assert.deepEqual(log._keys, [key2.getPublic('hex'), key3.getPublic('hex')])
-    })
-
-    it('takes a single write-access public key as an argument', () => {
-      const log = new Log(ipfs, 'A', null, null, null, key1, key2.getPublic('hex'))
-      assert.notEqual(log.id, null)
-      assert.deepEqual(log._key, key1)
-      assert.deepEqual(log._keys, [key2.getPublic('hex')])
-    })
-
-    it('entries contain a signature and a public signing key', async () => {
-      const log = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex')])
-      await log.append('one')
-      assert.notEqual(log.values[0].sig, null)
-      assert.equal(log.values[0].key, key1.getPublic('hex'))
-    })
-
-    it('doesn\'t sign entries when key is not defined', async () => {
-      const log = new Log(ipfs, 'A')
-      await log.append('one')
-      assert.equal(log.values[0].sig, null)
-      assert.equal(log.values[0].key, null)
-    })
-
-    it('allows only the owner to write when write-access keys are defined', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex')])
-      const log2 = new Log(ipfs, 'B', null, null, null, key2)
-
-      let err
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err, 'Error: Not allowed to write')
-    })
-
-    it('allows only the specified keys to write when write-access keys are defined', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, [key1.getPublic('hex'), key2.getPublic('hex')])
-
-      let err
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-        throw e
-      }
-      assert.equal(err, null)
-      assert.equal(log1.id, 'A')
-      assert.equal(log1.values.length, 2)
-      assert.equal(log1.values[0].payload, 'one')
-      assert.equal(log1.values[1].payload, 'two')
-    })
-
-    it('allows others than the owner to write', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key2.getPublic('hex')])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, [key2.getPublic('hex')])
-
-      let err
-      try {
-        await log2.append('one')
-        await log2.append('two')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-        throw e
-      }
-      assert.equal(err, null)
-      assert.equal(log1.id, 'A')
-      assert.equal(log1.values.length, 2)
-      assert.equal(log1.values[0].payload, 'one')
-      assert.equal(log1.values[1].payload, 'two')
-    })
-
-    it('allows anyone to write', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, ['*'])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, ['*'])
-
-      let err
-      try {
-        await log2.append('one')
-        await log2.append('two')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-        throw e
-      }
-      assert.equal(err, null)
-      assert.equal(log1.id, 'A')
-      assert.equal(log1.values.length, 2)
-      assert.equal(log1.values[0].payload, 'one')
-      assert.equal(log1.values[1].payload, 'two')
-    })
-
-    it('doesn\'t join logs with different IDs ', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, ['*'])
-      const log2 = new Log(ipfs, 'B', null, null, null, key1, ['*'])
-
-      let err
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        await log2.append('three')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-        throw e
-      }
-      assert.equal(err, null)
-      assert.equal(log1.id, 'A')
-      assert.equal(log1.values.length, 1)
-      assert.equal(log1.values[0].payload, 'one')
-    })
-
-    it('doesn\'t allows the owner to write if write-keys defines non-owner key', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key2.getPublic('hex')])
-
-      let err
-      try {
-        await log1.append('one')
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err, 'Error: Not allowed to write')
-    })
-
-    it('allows nobody to write when write-access keys are not defined', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [])
-
-      let err
-      try {
-        await log1.append('one')
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err.toString(), 'Error: Not allowed to write')
-    })
-
-    it('throws an error if log is signed but trying to merge with an entry that doesn\'t have public signing key', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, [key1.getPublic('hex'), key2.getPublic('hex')])
-
-      let err
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        delete log2.values[0].key
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err, 'Error: Entry doesn\'t have a public key')
-    })
-
-    it('throws an error if log is signed but trying to merge an entry that doesn\'t have a signature', async () => {
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, [key1.getPublic('hex'), key2.getPublic('hex')])
-
-      let err
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        delete log2.values[0].sig
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err, 'Error: Entry doesn\'t have a signature')
-    })
-
-    it('throws an error if log is signed but the signature doesn\'t verify', async () => {
-
-      const replaceAt = (str, index, replacement) => {
-        return str.substr(0, index) + replacement+ str.substr(index + replacement.length)
-      }
-
-      const log1 = new Log(ipfs, 'A', null, null, null, key1, [key1.getPublic('hex'), key2.getPublic('hex')])
-      const log2 = new Log(ipfs, 'A', null, null, null, key2, [key1.getPublic('hex'), key2.getPublic('hex')])
-      let err
-
-      try {
-        await log1.append('one')
-        await log2.append('two')
-        log2.values[0].sig = replaceAt(log2.values[0].sig, 0, 'X')
-        await log1.join(log2)
-      } catch (e) {
-        err = e.toString()
-      }
-      assert.equal(err, `Error: Invalid signature in entry '${log2.values[0].hash}'`)
-      assert.equal(log1.values.length, 1)
-      assert.equal(log1.values[0].payload, 'one')
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/utils/log-creator.js
+++ /dev/null
@@ -1,68 +0,0 @@
-'use strict'
-
-const Entry = require('../../src/entry')
-const Log = require('../../src/log.js')
-
-class LogCreator {
-  static async createLog1 (ipfs) {
-    const create = async () => {
-      let logA = new Log(ipfs, 'X', null, null, null, 'A')
-      let logB = new Log(ipfs, 'X', null, null, null, 'B')
-      let log3 = new Log(ipfs, 'X', null, null, null, '3')
-      let log  = new Log(ipfs, 'X', null, null, null, 'log')
-
-      for(let i = 1; i <= 5; i ++) {
-        await logA.append('entryA' + i)
-      }
-      for(let i = 1; i <= 5; i ++) {
-        await logB.append('entryB' + i)
-      }
-      log3.join(logA)
-      log3.join(logB)
-      for(let i = 6; i <= 10; i ++) {
-        await logA.append('entryA' + i)
-      }
-      log.join(log3)
-      await log.append('entryC0')
-      log.join(logA)
-      return log
-    }
-
-    const expectedData = [ 
-      'entryA1', 'entryB1', 'entryA2', 'entryB2', 'entryA3', 'entryB3',
-      'entryA4', 'entryB4', 'entryA5', 'entryB5', 
-      'entryA6',
-      'entryC0',
-      'entryA7', 'entryA8', 'entryA9', 'entryA10',
-    ]
-
-    const log = await create()
-    return { log: log, expectedData: expectedData }
-  }
-
-  static async createLog100_2 (ipfs) {
-    const amount = 100
-
-    let expectedData = []
-
-    const create = async () => {
-      let logA = new Log(ipfs, 'X', null, null, null, 'A')
-      let logB = new Log(ipfs, 'X', null, null, null, 'B')
-      let log  = new Log(ipfs, 'X', null, null, null, 'log')
-      for(let i = 1; i <= amount; i ++) {
-        await logA.append('entryA' + i)
-        logB.join(logA)
-        await logB.append('entryB' + i)
-        logA.join(logB)
-        expectedData.push('entryA' + i)
-        expectedData.push('entryB' + i)
-      }
-      return logA
-    }
-
-    const log = await create()
-    return { log: log, expectedData: expectedData }
-  }
-}
-
-module.exports = LogCreator
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/test/utils/mem-store.js
+++ /dev/null
@@ -1,91 +0,0 @@
-'use strict'
-
-const multihashing = require('multihashing-async')
-const mh = require('multihashes')
-
-const defaultHashAlg = 'sha2-256'
-
-const defaultFormat = { format: 'dag-cbor', hashAlg: defaultHashAlg }
-
-/* ImmutableDB using IPLD (through IPFS) */
-class IPLDStore {
-  constructor (ipfs) {
-    // super()
-    this._ipfs = ipfs
-  }
-
-  async put (value) {
-    const cid = await this._ipfs.dag.put(value, defaultFormat)
-    return cid.toBaseEncodedString()
-  }
-
-  async get (key) {
-    const result = await this._ipfs.dag.get(key)
-    return result.value
-  }
-}
-
-const createMultihash = (data, hashAlg) => {
-  return new Promise((resolve, reject) => {
-    multihashing(data, hashAlg || defaultHashAlg, (err, multihash) => {
-      if (err)
-        return reject(err)
-
-      resolve(mh.toB58String(multihash))
-    })
-  })
-}
-
-// const LRU = require('lru')
-// const ImmutableDB = require('./immutabledb-interface')
-// const createMultihash = require('./create-multihash')
-
-/* Memory store using an LRU cache */
-class MemStore {
-  constructor () {
-    this._store = {}//new LRU(1000)
-  }
-
-  async put (value) {
-    const data = value//new Buffer(JSON.stringify(value))
-    const hash = "" + Math.random()%1000 + "--"//await createMultihash(data)
-    // console.log(this._store)
-    // this._store.set(hash, data)
-    if (!this._store) this._store = {}
-    // console.log(this._store)
-    // console.log(hash, data)
-    this._store[hash] = data
-    // return hash
-    return {
-      toJSON: () => {
-        return {
-          data: value,
-          multihash: hash,
-        }
-      }
-    }
-  }
-
-  async get (key) {
-    // const data = this._store.get(key)
-    const data = this._store[key]
-
-    // if (data) {
-    //   const value = JSON.parse(data)
-    //   return value
-    // }
-
-    // return data
-    return {
-      toJSON: () => {
-        return {
-          data: this._store[key],
-          multihash: key,
-        }
-      }
-    }
-  }
-}
-
-
-module.exports = MemStore
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/webpack.config.js
+++ /dev/null
@@ -1,35 +0,0 @@
-'use strict'
-
-const path = require('path')
-const Uglify = require('uglifyjs-webpack-plugin')
-
-module.exports = {
-  entry: './src/log.js',
-  output: {
-    libraryTarget: 'var',
-    library: 'Log',
-    filename: './dist/ipfslog.min.js'
-  },
-  target: 'web',
-  devtool: 'sourcemap',
-  node: {
-    console: false,
-    Buffer: true
-  },
-  plugins: [
-    new Uglify(),
-  ],
-  resolve: {
-    modules: [
-      'node_modules',
-      path.resolve(__dirname, '../node_modules')
-    ]
-  },
-  resolveLoader: {
-    modules: [
-      'node_modules',
-      path.resolve(__dirname, '../node_modules')
-    ],
-    moduleExtensions: ['-loader']
-  },
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/ipfs-log/webpack.example.config.js
+++ /dev/null
@@ -1,59 +0,0 @@
-'use strict'
-
-const Uglify = require('uglifyjs-webpack-plugin')
-const path = require('path')
-
-const uglifyOptions = {
-  uglifyOptions: {
-    mangle: false,
-  },
-}
-
-module.exports = {
-  entry: './examples/browser/index.js',
-  output: {
-    filename: './examples/browser/bundle.js'
-  },
-  target: 'web',
-  node: {
-    console: false,
-    process: 'mock',
-    Buffer: true
-  },
-  plugins: [
-    new Uglify(uglifyOptions),
-  ],
-  externals: {
-    fs: '{}',
-  },
-  resolve: {
-    modules: [
-      'node_modules',
-      path.resolve(__dirname, '../node_modules')
-    ],
-    alias: {
-      // These are needed because node-libs-browser depends on outdated
-      // versions
-      //
-      // Can be dropped once https://github.com/devongovett/browserify-zlib/pull/18
-      // is shipped
-      zlib: 'browserify-zlib',
-      // Can be dropped once https://github.com/webpack/node-libs-browser/pull/41
-      // is shipped
-      http: 'stream-http',
-    }
-  },
-  resolveLoader: {
-    modules: [
-      'node_modules',
-      path.resolve(__dirname, '../node_modules')
-    ],
-    moduleExtensions: ['-loader']
-  },
-  module: {
-    rules: [{
-      test: /\.json$/,
-      loader: 'json-loader'
-    }]
-  }
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/is-fullwidth-code-point/index.js
+++ /dev/null
@@ -1,46 +0,0 @@
-'use strict';
-/* eslint-disable yoda */
-module.exports = x => {
-	if (Number.isNaN(x)) {
-		return false;
-	}
-
-	// code points are derived from:
-	// http://www.unix.org/Public/UNIDATA/EastAsianWidth.txt
-	if (
-		x >= 0x1100 && (
-			x <= 0x115f ||  // Hangul Jamo
-			x === 0x2329 || // LEFT-POINTING ANGLE BRACKET
-			x === 0x232a || // RIGHT-POINTING ANGLE BRACKET
-			// CJK Radicals Supplement .. Enclosed CJK Letters and Months
-			(0x2e80 <= x && x <= 0x3247 && x !== 0x303f) ||
-			// Enclosed CJK Letters and Months .. CJK Unified Ideographs Extension A
-			(0x3250 <= x && x <= 0x4dbf) ||
-			// CJK Unified Ideographs .. Yi Radicals
-			(0x4e00 <= x && x <= 0xa4c6) ||
-			// Hangul Jamo Extended-A
-			(0xa960 <= x && x <= 0xa97c) ||
-			// Hangul Syllables
-			(0xac00 <= x && x <= 0xd7a3) ||
-			// CJK Compatibility Ideographs
-			(0xf900 <= x && x <= 0xfaff) ||
-			// Vertical Forms
-			(0xfe10 <= x && x <= 0xfe19) ||
-			// CJK Compatibility Forms .. Small Form Variants
-			(0xfe30 <= x && x <= 0xfe6b) ||
-			// Halfwidth and Fullwidth Forms
-			(0xff01 <= x && x <= 0xff60) ||
-			(0xffe0 <= x && x <= 0xffe6) ||
-			// Kana Supplement
-			(0x1b000 <= x && x <= 0x1b001) ||
-			// Enclosed Ideographic Supplement
-			(0x1f200 <= x && x <= 0x1f251) ||
-			// CJK Unified Ideographs Extension B .. Tertiary Ideographic Plane
-			(0x20000 <= x && x <= 0x3fffd)
-		)
-	) {
-		return true;
-	}
-
-	return false;
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/is-fullwidth-code-point/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/is-fullwidth-code-point/readme.md
+++ /dev/null
@@ -1,39 +0,0 @@
-# is-fullwidth-code-point [![Build Status](https://travis-ci.org/sindresorhus/is-fullwidth-code-point.svg?branch=master)](https://travis-ci.org/sindresorhus/is-fullwidth-code-point)
-
-> Check if the character represented by a given [Unicode code point](https://en.wikipedia.org/wiki/Code_point) is [fullwidth](https://en.wikipedia.org/wiki/Halfwidth_and_fullwidth_forms)
-
-
-## Install
-
-```
-$ npm install --save is-fullwidth-code-point
-```
-
-
-## Usage
-
-```js
-const isFullwidthCodePoint = require('is-fullwidth-code-point');
-
-isFullwidthCodePoint('谢'.codePointAt());
-//=> true
-
-isFullwidthCodePoint('a'.codePointAt());
-//=> false
-```
-
-
-## API
-
-### isFullwidthCodePoint(input)
-
-#### input
-
-Type: `number`
-
-[Code point](https://en.wikipedia.org/wiki/Code_point) of a character.
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/locate-path/index.js
+++ /dev/null
@@ -1,24 +0,0 @@
-'use strict';
-const path = require('path');
-const pathExists = require('path-exists');
-const pLocate = require('p-locate');
-
-module.exports = (iterable, opts) => {
-	opts = Object.assign({
-		cwd: process.cwd()
-	}, opts);
-
-	return pLocate(iterable, el => pathExists(path.resolve(opts.cwd, el)), opts);
-};
-
-module.exports.sync = (iterable, opts) => {
-	opts = Object.assign({
-		cwd: process.cwd()
-	}, opts);
-
-	for (const el of iterable) {
-		if (pathExists.sync(path.resolve(opts.cwd, el))) {
-			return el;
-		}
-	}
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/locate-path/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/locate-path/readme.md
+++ /dev/null
@@ -1,99 +0,0 @@
-# locate-path [![Build Status](https://travis-ci.org/sindresorhus/locate-path.svg?branch=master)](https://travis-ci.org/sindresorhus/locate-path)
-
-> Get the first path that exists on disk of multiple paths
-
-
-## Install
-
-```
-$ npm install --save locate-path
-```
-
-
-## Usage
-
-Here we find the first file that exists on disk, in array order.
-
-```js
-const locatePath = require('locate-path');
-
-const files = [
-	'unicorn.png',
-	'rainbow.png', // only this one actually exists on disk
-	'pony.png'
-];
-
-locatePath(files).then(foundPath => {
-	console.log(foundPath);
-	//=> 'rainbow'
-});
-```
-
-
-## API
-
-### locatePath(input, [options])
-
-Returns a `Promise` for the first path that exists or `undefined` if none exists.
-
-#### input
-
-Type: `Iterable<string>`
-
-Paths to check.
-
-#### options
-
-Type: `Object`
-
-##### concurrency
-
-Type: `number`<br>
-Default: `Infinity`<br>
-Minimum: `1`
-
-Number of concurrently pending promises.
-
-##### preserveOrder
-
-Type: `boolean`<br>
-Default: `true`
-
-Preserve `input` order when searching.
-
-Disable this to improve performance if you don't care about the order.
-
-##### cwd
-
-Type: `string`<br>
-Default: `process.cwd()`
-
-Current working directory.
-
-### locatePath.sync(input, [options])
-
-Returns the first path that exists or `undefined` if none exists.
-
-#### input
-
-Type: `Iterable<string>`
-
-Paths to check.
-
-#### options
-
-Type: `Object`
-
-##### cwd
-
-Same as above.
-
-
-## Related
-
-- [path-exists](https://github.com/sindresorhus/path-exists) - Check if a path exists
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-limit/index.js
+++ /dev/null
@@ -1,42 +0,0 @@
-'use strict';
-const pTry = require('p-try');
-
-module.exports = concurrency => {
-	if (concurrency < 1) {
-		throw new TypeError('Expected `concurrency` to be a number from 1 and up');
-	}
-
-	const queue = [];
-	let activeCount = 0;
-
-	const next = () => {
-		activeCount--;
-
-		if (queue.length > 0) {
-			queue.shift()();
-		}
-	};
-
-	return fn => new Promise((resolve, reject) => {
-		const run = () => {
-			activeCount++;
-
-			pTry(fn).then(
-				val => {
-					resolve(val);
-					next();
-				},
-				err => {
-					reject(err);
-					next();
-				}
-			);
-		};
-
-		if (activeCount < concurrency) {
-			run();
-		} else {
-			queue.push(run);
-		}
-	});
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-limit/license
+++ /dev/null
@@ -1,9 +0,0 @@
-MIT License
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-limit/readme.md
+++ /dev/null
@@ -1,69 +0,0 @@
-# p-limit [![Build Status](https://travis-ci.org/sindresorhus/p-limit.svg?branch=master)](https://travis-ci.org/sindresorhus/p-limit)
-
-> Run multiple promise-returning & async functions with limited concurrency
-
-
-## Install
-
-```
-$ npm install p-limit
-```
-
-
-## Usage
-
-```js
-const pLimit = require('p-limit');
-
-const limit = pLimit(1);
-
-const input = [
-	limit(() => fetchSomething('foo')),
-	limit(() => fetchSomething('bar')),
-	limit(() => doSomething())
-];
-
-(async () => {
-	// Only one promise is run at once
-	const result = await Promise.all(input);
-	console.log(result);
-})();
-```
-
-
-## API
-
-### pLimit(concurrency)
-
-Returns a `limit` function.
-
-#### concurrency
-
-Type: `number`<br>
-Minimum: `1`
-
-Concurrency limit.
-
-### limit(fn)
-
-Returns the promise returned by calling `fn`.
-
-#### fn
-
-Type: `Function`
-
-Promise-returning/async function.
-
-
-## Related
-
-- [p-queue](https://github.com/sindresorhus/p-queue) - Promise queue with concurrency control
-- [p-throttle](https://github.com/sindresorhus/p-throttle) - Throttle promise-returning & async functions
-- [p-debounce](https://github.com/sindresorhus/p-debounce) - Debounce promise-returning & async functions
-- [p-all](https://github.com/sindresorhus/p-all) - Run promise-returning & async functions concurrently with optional limited concurrency
-- [More…](https://github.com/sindresorhus/promise-fun)
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-locate/index.js
+++ /dev/null
@@ -1,31 +0,0 @@
-'use strict';
-const pLimit = require('p-limit');
-
-class EndError extends Error {
-	constructor(value) {
-		super();
-		this.value = value;
-	}
-}
-
-// the input can also be a promise, so we `Promise.all()` them both
-const finder = el => Promise.all(el).then(val => val[1] === true && Promise.reject(new EndError(val[0])));
-
-module.exports = (iterable, tester, opts) => {
-	opts = Object.assign({
-		concurrency: Infinity,
-		preserveOrder: true
-	}, opts);
-
-	const limit = pLimit(opts.concurrency);
-
-	// start all the promises concurrently with optional limit
-	const items = Array.from(iterable).map(el => [el, limit(() => Promise.resolve(el).then(tester))]);
-
-	// check the promises either serially or concurrently
-	const checkLimit = pLimit(opts.preserveOrder ? 1 : Infinity);
-
-	return Promise.all(items.map(el => checkLimit(() => finder(el))))
-		.then(() => {})
-		.catch(err => err instanceof EndError ? err.value : Promise.reject(err));
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-locate/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-locate/readme.md
+++ /dev/null
@@ -1,86 +0,0 @@
-# p-locate [![Build Status](https://travis-ci.org/sindresorhus/p-locate.svg?branch=master)](https://travis-ci.org/sindresorhus/p-locate)
-
-> Get the first fulfilled promise that satisfies the provided testing function
-
-Think of it like an async version of [`Array#find`](https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Array/find).
-
-
-## Install
-
-```
-$ npm install --save p-locate
-```
-
-
-## Usage
-
-Here we find the first file that exists on disk, in array order.
-
-```js
-const pathExists = require('path-exists');
-const pLocate = require('p-locate');
-
-const files = [
-	'unicorn.png',
-	'rainbow.png', // only this one actually exists on disk
-	'pony.png'
-];
-
-pLocate(files, file => pathExists(file)).then(foundPath => {
-	console.log(foundPath);
-	//=> 'rainbow'
-});
-```
-
-*The above is just an example. Use [`locate-path`](https://github.com/sindresorhus/locate-path) if you need this.*
-
-
-## API
-
-### pLocate(input, tester, [options])
-
-Returns a `Promise` that is fulfilled when `tester` resolves to `true` or the iterable is done, or rejects if any of the promises reject. The fulfilled value is the current iterable value or `undefined` if `tester` never resolved to `true`.
-
-#### input
-
-Type: `Iterable<Promise|any>`
-
-#### tester(element)
-
-Type: `Function`
-
-Expected to return a `Promise<boolean>` or boolean.
-
-#### options
-
-Type: `Object`
-
-##### concurrency
-
-Type: `number`<br>
-Default: `Infinity`<br>
-Minimum: `1`
-
-Number of concurrently pending promises returned by `tester`.
-
-##### preserveOrder
-
-Type: `boolean`<br>
-Default: `true`
-
-Preserve `input` order when searching.
-
-Disable this to improve performance if you don't care about the order.
-
-
-## Related
-
-- [p-map](https://github.com/sindresorhus/p-map) - Map over promises concurrently
-- [p-filter](https://github.com/sindresorhus/p-filter) - Filter promises concurrently
-- [p-any](https://github.com/sindresorhus/p-any) - Wait for any promise to be fulfilled
-- [More…](https://github.com/sindresorhus/promise-fun)
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-try/index.js
+++ /dev/null
@@ -1,4 +0,0 @@
-'use strict';
-module.exports = cb => new Promise(resolve => {
-	resolve(cb());
-});
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-try/license
+++ /dev/null
@@ -1,21 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/p-try/readme.md
+++ /dev/null
@@ -1,38 +0,0 @@
-# p-try [![Build Status](https://travis-ci.org/sindresorhus/p-try.svg?branch=master)](https://travis-ci.org/sindresorhus/p-try)
-
-> [`Promise#try()`](https://github.com/ljharb/proposal-promise-try) [ponyfill](https://ponyfill.com) - Starts a promise chain
-
-[How is it useful?](http://cryto.net/~joepie91/blog/2016/05/11/what-is-promise-try-and-why-does-it-matter/)
-
-
-## Install
-
-```
-$ npm install --save p-try
-```
-
-
-## Usage
-
-```js
-const pTry = require('p-try');
-
-pTry(() => {
-	return synchronousFunctionThatMightThrow();
-}).then(value => {
-	console.log(value);
-}).catch(error => {
-	console.error(error);
-});
-```
-
-
-## Related
-
-- [p-finally](https://github.com/sindresorhus/p-finally) - `Promise#finally()` ponyfill - Invoked when the promise is settled regardless of outcome
-- [More…](https://github.com/sindresorhus/promise-fun)
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/.circleci/config.yml
+++ /dev/null
@@ -1,55 +0,0 @@
-# Javascript Node CircleCI 2.0 configuration file
-#
-# Check https://circleci.com/docs/2.0/language-javascript/ for more details
-#
-version: 2
-jobs:
-  test:
-    docker:
-      # specify the version you desire here
-      - image: circleci/node:8.11.3
-
-      # Specify service dependencies here if necessary
-      # CircleCI maintains a library of pre-built images
-      # documented at https://circleci.com/docs/2.0/circleci-images/
-      # - image: circleci/mongo:3.4.4
-
-    working_directory: ~/repo
-
-    steps:
-      - checkout
-
-      # Download and cache dependencies
-      - restore_cache:
-          keys:
-          - v1-dependencies-{{ checksum "package.json" }}
-          # fallback to using the latest cache if no exact match is found
-          - v1-dependencies-
-
-      - run: npm install
-
-      - save_cache:
-          paths:
-            - node_modules
-          key: v1-dependencies-{{ checksum "package.json" }}
-
-#      - run: npm test
-      - run: npm run coverage
-
-workflows:
-  version: 2
-  commit:
-    jobs:
-      - test
-
-  nightly:
-    triggers:
-      - schedule:
-          cron: "0 0 * * *"
-          filters:
-            branches:
-              only:
-                - master
-
-    jobs:
-      - test
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/LICENSE.md
+++ /dev/null
@@ -1,21 +0,0 @@
-MIT License
-
-Copyright (c) 2018 Kia Rahimian
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-SOFTWARE.
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/README.md
+++ /dev/null
@@ -1,42 +0,0 @@
-# Record Resolver
-
-[![MIT License](http://img.shields.io/badge/license-MIT-blue.svg?style=flat)](LICENSE) [![JavaScript Style Guide](https://img.shields.io/badge/code_style-standard-brightgreen.svg)](https://standardjs.com) [![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg?style=flat)](https://github.com/RichardLitt/standard-readme)
-
-> Resolver for Record.
-
-## Install
-```
-npm install
-```
-
-## Usage
-### CLI
-```
-wip
-```
-
-### Module
-```js
-const resolver = require('resolver')
-const url = 'http://www.youtube.com/watch?v=iODdvJGpfIA'
-
-resolver(url, (err, info) => {
-  if (err) {
-     console.log(err)
-     return
-  }
-
-  console.log(info)
-})
-```
-or use with await inside an async function
-```js
-const resolver = require('resolver')
-
-try {
-  const url = 'http://www.youtube.com/watch?v=iODdvJGpfIA'
-  const info = await resolver(url)
-} catch (e) {
-  console.log(e)
-}
-```
\ No newline at end of file
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/bin/index.js
+++ /dev/null
@@ -1,16 +0,0 @@
-#!/usr/bin/env node
-
-const argv = require('yargs').argv
-const resolver = require('../')
-
-const run = async (url) => {
-  try {
-    const result = await resolver(url)
-    console.log(result)
-  } catch (e) {
-    console.log(e)
-  }
-}
-
-const url = argv.u || argv.url || process.argv[2]
-run(url)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/errors/index.js
+++ /dev/null
@@ -1,6 +0,0 @@
-'use strict'
-
-exports.ERR_NOT_VALID_URL = 'ERR_NOT_VALID_URL'
-exports.ERR_MISSING_URL = 'ERR_MISSING_URL'
-exports.ERR_NOT_SUITABLE_URL = 'ERR_NOT_SUITABLE_URL'
-exports.ERR_NOT_STREAMABLE = 'ERR_NOT_STREAMABLE'
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/index.js
+++ /dev/null
@@ -1,90 +0,0 @@
-const youtubedl = require('youtube-dl')
-const extend = require('deep-extend')
-const promisify = require('promisify-es6')
-
-const ERRORS = require('./errors')
-const resolvers = require('./resolvers')
-
-function isURL (text) {
-  var pattern = '^(https?:\\/\\/)?' + // protocol
-	'((([a-z\\d]([a-z\\d-]*[a-z\\d])*)\\.)+[a-z]{2,}|' + // domain name
-	'((\\d{1,3}\\.){3}\\d{1,3}))' + // OR ip (v4) address
-	'(?::\\d{2,5})?' + // port
-	'(?:/[^\\s]*)?$'; // path
-
-  var re = new RegExp(pattern, 'i');
-  return re.test(text);
-}
-
-const defaults = {
-  resolver: null
-}
-
-const getResolver = (name) => {
-  return resolvers.find((resolver) => {
-    return resolver._name === name
-  })
-}
-
-module.exports = promisify(async (url, opts = {}, callback) => {
-
-  if (typeof opts === 'function') {
-    callback = opts
-    opts = {}
-  }
-
-  if (!url) {
-    return callback(Object.assign(new Error('missing url'), {
-      code: ERRORS.ERR_MISSING_URL,
-      url: url
-    }))
-  }
-
-  if (!isURL(url)) {
-    return callback(Object.assign(new Error('not a valid url'), {
-      code: ERRORS.ERR_NOT_VALID_URL,
-      url: url
-    }))
-  }
-
-  const options = extend(defaults, opts)
-
-  if (options.useYTDL) {
-    return youtubedl.getInfo(url, null, (err, info) => {
-      if (err) throw err
-
-      if (!Array.isArray(info)) {
-        info = [info]
-      }
-
-      callback(null, info)
-    })
-  }
-
-  const rs = options.resolver ? getResolver(options.resolver) : resolvers
-
-  const resolver = rs.find((resolver) => {
-    return resolver.suitable(url)
-  })
-
-  if (!resolver) {
-    return callback(Object.assign(new Error('not a suitable url'), {
-      code: ERRORS.ERR_NOT_SUITABLE_URL,
-      url: url
-    }))
-  }
-
-  try {
-    let result = await resolver.extract(url)
-
-    if (!Array.isArray(result)) {
-      result = [result]
-    }
-
-    callback(null, result)
-  } catch (e) {
-    callback(e)
-  }
-})
-
-module.exports.errors = ERRORS
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/node_modules/deep-extend/CHANGELOG.md
+++ /dev/null
@@ -1,46 +0,0 @@
-Changelog
-=========
-
-v0.6.0
-------
-
-- Updated "devDependencies" versions to fix vulnerability alerts
-- Dropped support of io.js and node.js v0.12.x and lower since new versions of
-  "devDependencies" couldn't work with those old node.js versions
-  (minimal supported version of node.js now is v4.0.0)
-
-v0.5.1
-------
-
-- Fix prototype pollution vulnerability (thanks to @mwakerman for the PR)
-- Avoid using deprecated Buffer API (thanks to @ChALkeR for the PR)
-
-v0.5.0
-------
-
-- Auto-testing provided by Travis CI;
-- Support older Node.JS versions (`v0.11.x` and `v0.10.x`);
-- Removed tests files from npm package.
-
-v0.4.2
-------
-
-- Fix for `null` as an argument.
-
-v0.4.1
-------
-
-- Removed test code from <b>npm</b> package
-  ([see pull request #21](https://github.com/unclechu/node-deep-extend/pull/21));
-- Increased minimal version of Node from `0.4.0` to `0.12.0`
-  (because can't run tests on lesser version anyway).
-
-v0.4.0
-------
-
-- **WARNING!** Broken backward compatibility with `v0.3.x`;
-- Fixed bug with extending arrays instead of cloning;
-- Deep cloning for arrays;
-- Check for own property;
-- Fixed some documentation issues;
-- Strict JS mode.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/node_modules/deep-extend/LICENSE
+++ /dev/null
@@ -1,20 +0,0 @@
-The MIT License (MIT)
-
-Copyright (c) 2013-2018, Viacheslav Lotsmanov
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of
-this software and associated documentation files (the "Software"), to deal in
-the Software without restriction, including without limitation the rights to
-use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
-the Software, and to permit persons to whom the Software is furnished to do so,
-subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
-FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
-COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
-IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
-CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/node_modules/deep-extend/README.md
+++ /dev/null
@@ -1,91 +0,0 @@
-Deep Extend
-===========
-
-Recursive object extending.
-
-[![Build Status](https://api.travis-ci.org/unclechu/node-deep-extend.svg?branch=master)](https://travis-ci.org/unclechu/node-deep-extend)
-
-[![NPM](https://nodei.co/npm/deep-extend.png?downloads=true&downloadRank=true&stars=true)](https://nodei.co/npm/deep-extend/)
-
-Install
--------
-
-```bash
-$ npm install deep-extend
-```
-
-Usage
------
-
-```javascript
-var deepExtend = require('deep-extend');
-var obj1 = {
-  a: 1,
-  b: 2,
-  d: {
-    a: 1,
-    b: [],
-    c: { test1: 123, test2: 321 }
-  },
-  f: 5,
-  g: 123,
-  i: 321,
-  j: [1, 2]
-};
-var obj2 = {
-  b: 3,
-  c: 5,
-  d: {
-    b: { first: 'one', second: 'two' },
-    c: { test2: 222 }
-  },
-  e: { one: 1, two: 2 },
-  f: [],
-  g: (void 0),
-  h: /abc/g,
-  i: null,
-  j: [3, 4]
-};
-
-deepExtend(obj1, obj2);
-
-console.log(obj1);
-/*
-{ a: 1,
-  b: 3,
-  d:
-   { a: 1,
-     b: { first: 'one', second: 'two' },
-     c: { test1: 123, test2: 222 } },
-  f: [],
-  g: undefined,
-  c: 5,
-  e: { one: 1, two: 2 },
-  h: /abc/g,
-  i: null,
-  j: [3, 4] }
-*/
-```
-
-Unit testing
-------------
-
-```bash
-$ npm test
-```
-
-Changelog
----------
-
-[CHANGELOG.md](./CHANGELOG.md)
-
-Any issues?
------------
-
-Please, report about issues
-[here](https://github.com/unclechu/node-deep-extend/issues).
-
-License
--------
-
-[MIT](./LICENSE)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/node_modules/deep-extend/index.js
+++ /dev/null
@@ -1 +0,0 @@
-module.exports = require('./lib/deep-extend');
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/node_modules/deep-extend/lib/deep-extend.js
+++ /dev/null
@@ -1,150 +0,0 @@
-/*!
- * @description Recursive object extending
- * @author Viacheslav Lotsmanov <lotsmanov89@gmail.com>
- * @license MIT
- *
- * The MIT License (MIT)
- *
- * Copyright (c) 2013-2018 Viacheslav Lotsmanov
- *
- * Permission is hereby granted, free of charge, to any person obtaining a copy of
- * this software and associated documentation files (the "Software"), to deal in
- * the Software without restriction, including without limitation the rights to
- * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
- * the Software, and to permit persons to whom the Software is furnished to do so,
- * subject to the following conditions:
- *
- * The above copyright notice and this permission notice shall be included in all
- * copies or substantial portions of the Software.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
- * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
- * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
- * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
- * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
- */
-
-'use strict';
-
-function isSpecificValue(val) {
-	return (
-		val instanceof Buffer
-		|| val instanceof Date
-		|| val instanceof RegExp
-	) ? true : false;
-}
-
-function cloneSpecificValue(val) {
-	if (val instanceof Buffer) {
-		var x = Buffer.alloc
-			? Buffer.alloc(val.length)
-			: new Buffer(val.length);
-		val.copy(x);
-		return x;
-	} else if (val instanceof Date) {
-		return new Date(val.getTime());
-	} else if (val instanceof RegExp) {
-		return new RegExp(val);
-	} else {
-		throw new Error('Unexpected situation');
-	}
-}
-
-/**
- * Recursive cloning array.
- */
-function deepCloneArray(arr) {
-	var clone = [];
-	arr.forEach(function (item, index) {
-		if (typeof item === 'object' && item !== null) {
-			if (Array.isArray(item)) {
-				clone[index] = deepCloneArray(item);
-			} else if (isSpecificValue(item)) {
-				clone[index] = cloneSpecificValue(item);
-			} else {
-				clone[index] = deepExtend({}, item);
-			}
-		} else {
-			clone[index] = item;
-		}
-	});
-	return clone;
-}
-
-function safeGetProperty(object, property) {
-	return property === '__proto__' ? undefined : object[property];
-}
-
-/**
- * Extening object that entered in first argument.
- *
- * Returns extended object or false if have no target object or incorrect type.
- *
- * If you wish to clone source object (without modify it), just use empty new
- * object as first argument, like this:
- *   deepExtend({}, yourObj_1, [yourObj_N]);
- */
-var deepExtend = module.exports = function (/*obj_1, [obj_2], [obj_N]*/) {
-	if (arguments.length < 1 || typeof arguments[0] !== 'object') {
-		return false;
-	}
-
-	if (arguments.length < 2) {
-		return arguments[0];
-	}
-
-	var target = arguments[0];
-
-	// convert arguments to array and cut off target object
-	var args = Array.prototype.slice.call(arguments, 1);
-
-	var val, src, clone;
-
-	args.forEach(function (obj) {
-		// skip argument if isn't an object, is null, or is an array
-		if (typeof obj !== 'object' || obj === null || Array.isArray(obj)) {
-			return;
-		}
-
-		Object.keys(obj).forEach(function (key) {
-			src = safeGetProperty(target, key); // source value
-			val = safeGetProperty(obj, key); // new value
-
-			// recursion prevention
-			if (val === target) {
-				return;
-
-			/**
-			 * if new value isn't object then just overwrite by new value
-			 * instead of extending.
-			 */
-			} else if (typeof val !== 'object' || val === null) {
-				target[key] = val;
-				return;
-
-			// just clone arrays (and recursive clone objects inside)
-			} else if (Array.isArray(val)) {
-				target[key] = deepCloneArray(val);
-				return;
-
-			// custom cloning and overwrite for specific objects
-			} else if (isSpecificValue(val)) {
-				target[key] = cloneSpecificValue(val);
-				return;
-
-			// overwrite by new value if source isn't object or array
-			} else if (typeof src !== 'object' || src === null || Array.isArray(src)) {
-				target[key] = deepExtend({}, val);
-				return;
-
-			// source value and new value is objects both, extending...
-			} else {
-				target[key] = deepExtend(src, val);
-				return;
-			}
-		});
-	});
-
-	return target;
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/audiomack.js
+++ /dev/null
@@ -1,116 +0,0 @@
-const { request } = require('../utils')
-const Resolver = require('./resolver')
-
-const { SoundcloudResolver } = require('./soundcloud')
-
-class AudiomackResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Audiomack'
-    this._valid_url = /^https?:\/\/(?:www\.)?audiomack\.com\/song\/([\w\/-]+)/i
-  }
-
-  async extract (url) {
-    const re_result = this._valid_url.exec(url)
-    const id = re_result[1]
-    const audiomack_url = `http://www.audiomack.com/api/music/url/song/${id}?extended=1&_=${new Date().getTime()}`
-    const { body } = await request({ url: audiomack_url, json: true })
-
-    const sr = new SoundcloudResolver()
-    if (sr.suitable(body.url)) {
-      return await sr.extract(url)
-    }
-
-    return super.extract({
-      id: body.id,
-      extractor: this._name,
-      url: body.url,
-      webpage_url: url,
-      fulltitle: body.title,
-      duration: body.duration
-    })
-  }
-}
-
-class AudiomackEmbedResolver extends AudiomackResolver {
-  constructor() {
-    super()
-    this._valid_url = /https?:\/\/(?:www\.)?audiomack\.com\/embed4(?:\-thin|\-large)?\/([\w\/-]+)/i
-  }
-}
-
-class AudiomackAlbumResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Audiomack:album'
-    this._valid_url = /^https?:\/\/(?:www\.)?audiomack\.com\/album\/([\w\/-]+)/i
-  }
-
-  async extract (url) {
-    let count = 0
-    let entries = []
-    let tracks_remaining = true
-
-    const re_result = this._valid_url.exec(url)
-    const id = re_result[1]
-
-    while (tracks_remaining) {
-      const audiomack_url = `http://www.audiomack.com/api/music/url/album/${id}/${count}/?extended=1&_=${new Date().getTime()}`
-      const response = await request({ url: audiomack_url, json: true })
-
-      const { body } = response
-
-      if (!body.id) {
-        tracks_remaining = false
-        continue
-      }
-
-      const sr = new SoundcloudResolver()
-
-      if (!body.url) {
-        count++
-        continue
-      }
-
-      let item
-      if (sr.suitable(body.url)) {
-        item = await sr.extract(url)
-      } else {
-        const permalink_re = /^https?:\/\/(?:music\.)?audiomack\.com\/albums\/([\w-]+)\/(?:[\w-]+)\/([\w\/-]+)/ig
-        const permalink_re_result = permalink_re.exec(body.url)
-        const artist = permalink_re_result[1]
-        const song_title = permalink_re_result[2]
-        const permalink = `https://audiomack.com/song/${artist}/${song_title}`
-
-        item = {
-          id: body.id,
-          extractor: this._name,
-          url: body.url,
-          fulltitle: body.title,
-          webpage_url: permalink,
-          duration: body.duration
-        }
-        entries.push(item)
-      }
-
-      count++
-    }
-
-    // TODO: extend with defaults
-    return entries
-  }
-}
-
-class AudiomackAlbumEmbedResolver extends AudiomackAlbumResolver {
-  constructor () {
-    super()
-    this._valid_url = /https?:\/\/(?:www\.)?audiomack\.com\/embed4-album\/([\w\/-]+)/i
-  }
-}
-
-module.exports.default = [
-  AudiomackResolver,
-  AudiomackEmbedResolver,
-  AudiomackAlbumResolver,
-  AudiomackAlbumEmbedResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/bandcamp.js
+++ /dev/null
@@ -1,125 +0,0 @@
-const cheerio = require('cheerio')
-const URI = require('urijs')
-
-const { request } = require('../utils')
-const Resolver = require('./resolver')
-
-const ERRORS = require('../errors')
-
-async function getTrackInfo (url) {
-  const { body } = await request(url)
-  const trackInfo = /trackinfo: (.+),\s*?\n/gi.exec(body)[1]
-  return { trackInfo, body }
-}
-
-class BandcampResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Bandcamp'
-    this._valid_url = /^https?:\/\/.*?\.bandcamp\.com\/track\/([^\/?#&]+)/i
-  }
-
-  async extract (url) {
-    const { trackInfo, body } = await getTrackInfo(url)
-
-    // TODO: handle pages with free download page link
-
-    if (!trackInfo) {
-      throw Object.assign(new Error('Not Streamable', {
-        code: ERRORS.ERR_NOT_STREAMABLE,
-        url: url
-      }))
-    }
-
-    const $ = cheerio.load(body)
-    const thumbnail = $('meta[property="og:image"]').attr('content')
-
-    const tracks = JSON.parse(trackInfo)
-
-    const hostname = new URI(url).hostname()
-    const permalink = `http://${hostname}${tracks[0].title_link}`
-
-    // TODO: grab formats and sort
-    const file = tracks[0].file
-    const file_url = new URI(file[Object.keys(file)[0]]).absoluteTo('http://').toString()
-
-    return super.extract({
-      id: tracks[0].id,
-      extractor: this._name,
-      fulltitle: tracks[0].title,
-      url: file_url,
-      webpage_url: permalink,
-      duration: tracks[0].duration,
-      thumbnail: thumbnail
-    })
-  }
-}
-
-class BandcampAlbumResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Bandcamp:album'
-    this._valid_url = /^https?:\/\/(?:([^.]+)\.)?bandcamp\.com(?:\/album\/([^\/?#&]+))?/i
-  }
-
-  async extract (url) {
-    const { trackInfo, body } = await getTrackInfo(url)
-
-    // TODO: handle pages with free download page link
-
-    if (!trackInfo) {
-      throw Object.assign(new Error('Not Streamable', {
-        code: ERRORS.ERR_NOT_STREAMABLE,
-        url: url
-      }))
-    }
-
-    const $ = cheerio.load(body)
-    const thumbnail = $('meta[property="og:image"]').attr('content')
-
-    const tracks = JSON.parse(trackInfo)
-    let entries = []
-
-    const hostname = new URI(url).hostname()
-
-    tracks.forEach((track) => {
-      const file = track.file
-      const file_url = new URI(file[Object.keys(file)[0]]).absoluteTo('http://').toString()
-
-      const permalink = `http://${hostname}${track.title_link}`
-
-      entries.push(super.extract({
-        id: tracks[0].id,
-        extractor: this._name,
-        fulltitle: tracks[0].title,
-        url: file_url,
-        duration: tracks[0].duration,
-        webpage_url: permalink,
-        thumbnail: thumbnail
-      }))
-    })
-
-    return entries
-  }
-}
-
-class BandcampWeeklyResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Bandcamp:weekly'
-    this._valid_url = /^https?:\/\/(?:www\.)?bandcamp\.com\/?\?(?:.*?&)?show=(\d+)/i
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-module.exports.default = [
-  BandcampResolver,
-  BandcampAlbumResolver,
-  BandcampWeeklyResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/eighttracks.js
+++ /dev/null
@@ -1,66 +0,0 @@
-const async = require('async')
-
-const { request } = require('../utils')
-const Resolver = require('./resolver')
-
-class EighttracksResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = '8tracks'
-    this._valid_url = /^https?:\/\/8tracks\.com\/([^\/]+)\/([^\/#]+)(?:#.*)?$/i
-  }
-
-  async extract (url) {
-    const response = await request(url)
-    const mix = JSON.parse(/PAGE.mix = (.*?);\n/gi.exec(response.body)[1])
-    const session = Math.floor(Math.random() * (1000000000 - 0 + 1) + 0).toString()
-    let next_url = `http://8tracks.com/sets/${session}/play?player=sm&format=jsonh&mix_id=${mix.id}`
-
-    let avg_song_duration = parseInt(mix.duration, 10) / mix.tracks_count
-
-    if (avg_song_duration <= 0) {
-      avg_song_duration = 300
-    }
-
-    let tracks = []
-
-    for (let i=0; i < mix.tracks_count; i++) {
-      //TODO: retry a couple times on error and sleep based on avg_song_duration
-      const { body } = await request({ url: next_url, json: true })
-
-      const track_data = body.set.track
-      next_url = `http://8tracks.com/sets/${session}/next?player=sm&format=jsonh&mix_id=${mix.id}&track_id=${track_data.id}`
-      const track = super.extract({
-        id: track_data.id,
-        extractor: this._name,
-        url: track_data.track_file_stream_url,
-        webpage_url: track_data.url,
-        fulltitle: `${track_data.performer} - ${track_data.name}`
-      })
-      tracks.push(track)
-    }
-
-    return tracks
-  }
-}
-
-class EighttracksSongResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = '8tracks:song'
-    this._valid_url = /^https?:\/\/8tracks\.com\/(?:songs|tracks)\/([\d]+)\/?$/
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-
-    // TODO: get link to shortist playlist
-    // TODO: get playlist => filter by track id
-  }
-}
-
-module.exports.default = [
-  EighttracksResolver,
-  EighttracksSongResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/hypem.js
+++ /dev/null
@@ -1,33 +0,0 @@
-const { request } = require('../utils')
-const Resolver = require('./resolver')
-
-class HypemResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Hypem'
-    this._valid_url = /^https?:\/\/(?:www\.)?hypem\.com\/track\/([^\/]+)/i
-  }
-
-  async extract (url) {
-
-    const hypem_url = url + '?' + encodeURIComponent({'ax': 1, 'ts': Date.now()})
-    const { body } = await request(hypem_url)
-
-    const html_tracks = /<script type="application\/json" id="displayList-data">\s*(.*?)\s*<\/script>/.exec(body)[1]
-
-    const track = JSON.parse(html_tracks).tracks[0]
-    const serve_url = `http://hypem.com/serve/source/${track.id}/${track.key}`
-    const track_response = await request({ url: serve_url, json: true })
-    const stream_url = track_response.body.url
-
-    return super.extract({
-      id: track.id,
-      extractor: this._name,
-      url: stream_url,
-      webpage_url: url,
-      fulltitle: track.song
-    })
-  }
-}
-
-module.exports.default = [HypemResolver]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/index.js
+++ /dev/null
@@ -1,28 +0,0 @@
-const fs = require('fs')
-
-let Resolvers = []
-let resolvers = []
-
-const audiomackResolvers = require('./audiomack').default
-Resolvers = Resolvers.concat(audiomackResolvers)
-const bandcampResolvers = require('./bandcamp').default
-Resolvers = Resolvers.concat(bandcampResolvers)
-const eighttracksResolvers = require('./eighttracks').default
-Resolvers = Resolvers.concat(eighttracksResolvers)
-const hypemResolvers = require('./hypem').default
-Resolvers = Resolvers.concat(hypemResolvers)
-const mixcloudResolvers = require('./mixcloud').default
-Resolvers = Resolvers.concat(mixcloudResolvers)
-const soundcloudResolvers = require('./soundcloud').default
-Resolvers = Resolvers.concat(soundcloudResolvers)
-const youtubeResolvers = require('./youtube').default
-Resolvers = Resolvers.concat(youtubeResolvers)
-const vimeoResolvers = require('./vimeo').default
-Resolvers = Resolvers.concat(vimeoResolvers)
-
-Resolvers.forEach((Resolver) => {
-  const resolver = new Resolver()
-  resolvers.push(resolver)
-})
-
-module.exports = resolvers
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/mixcloud.js
+++ /dev/null
@@ -1,161 +0,0 @@
-const { request } = require('../utils')
-const Resolver = require('./resolver')
-
-const ERRORS = require('../errors')
-
-function xorStrings(key,input){
-  let output = ''
-  for (let i=0; i<input.length; i++) {
-    var c = input.charCodeAt(i)
-    var k = key.charCodeAt(i % key.length)
-    output += String.fromCharCode(c ^ k)
-  }
-
-  return output
-}
-
-const getNestedObject = (nestedObj, pathArr) => {
-  return pathArr.reduce((obj, key) =>
-    (obj && obj[key] !== 'undefined') ? obj[key] : undefined, nestedObj);
-}
-
-class MixcloudResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Mixcloud'
-    this._valid_url = /^https?:\/\/(?:(?:www|beta|m)\.)?mixcloud\.com\/([^\/]+)\/(?!stream|uploads|favorites|listens|playlists)([^\/]+)/ig
-  }
-
-  async extract (url) {
-    const re_result = this._valid_url.exec(url)
-
-    const response = await request(url)
-    let encrypted_play_info = /m-play-info="([^"]+)"/.exec(response.body)
-
-    let info_json
-
-    if (encrypted_play_info) {
-      encrypted_play_info = new Buffer(encrypted_play_info, 'base64').toString('ascii')
-    } else {
-      const json_re = /<script id="relay-data" type="text\/x-mixcloud">([^<]+)<\/script>/i
-      const json_re_result = json_re.exec(response.body)
-      let full_info_json = JSON.parse(json_re_result[1].replace(/&quot;/g, '"'))
-
-
-      full_info_json.forEach((item) => {
-        const item_data = getNestedObject(item, ['cloudcast', 'data', 'cloudcastLookup'])
-        if (getNestedObject(item_data, ['streamInfo', 'url'])) {
-          info_json = item_data
-        }
-      })
-    }
-
-    const js_url_re = /<script[^>]+\bsrc=["\"](https:\/\/(?:www\.)?mixcloud\.com\/media\/(?:js2\/www_js_4|js\/www)\.[^>]+\.js)/i
-    const js_url = js_url_re.exec(response.body)[1]
-    const js_response = await request(js_url)
-
-    let kps, kpa_target, key
-
-    if (encrypted_play_info) {
-      kps = ['{"stream_url":']
-      kpa_target = encrypted_play_info
-    } else {
-      kps = ['https://', 'http://']
-      kpa_target = new Buffer(info_json.streamInfo.url, 'base64').toString('ascii')
-    }
-
-    kps.forEach((kp) => {
-      const partial_key = xorStrings(kpa_target, kp)
-      const escaped_partial_key = partial_key.replace(/[|\\{}()[\]^$+*?.]/g, '\\$&')
-
-      const quotes = ["'",'"']
-      quotes.forEach((quote) => {
-        const key_re = new RegExp(`${quote}(${escaped_partial_key}[^${quote}]*)${quote}`)
-        const re_result = key_re.exec(js_response.body)
-        if (re_result) {
-          key = re_result[1]
-        }
-      })
-    })
-
-    if (encrypted_play_info) {
-      const play_info = JSON.parse(xorStrings(key, encrypted_play_info))
-
-      if (!play_info.stream_url) {
-        throw Object.assign(new Error('Not Streamable', {
-          code: ERRORS.ERR_NOT_STREAMABLE,
-          url: url
-        }))
-      }
-
-      const uploader_id_re = /\s+"profile": "([^"]+)",/i
-      const title_re = /m-title="([^"]+)"/i
-      const thumbnail_re = /m-thumbnail-url="([^"]+)"/i
-
-      return super.extract({
-        extractor: this._name,
-        url: play_info.stream_url,
-        webpage_url: url
-      })
-
-    } else {
-
-      const format_url = info_json.streamInfo['url']
-      const format_url_decoded = new Buffer(format_url, 'base64').toString('ascii')
-      const decrypted_url = xorStrings(key, format_url_decoded)
-
-      const picture_root = getNestedObject(info_json, ['picture', 'urlRoot'])
-      const thumbnail = `https://thumbnailer.mixcloud.com/unsafe/600x600/${picture_root}`
-
-      return super.extract({
-        id: `${info_json.owner.username}-${info_json.slug}`,
-        extractor: this._name,
-        thumbnail: thumbnail,
-        fulltitle: info_json.name,
-        webpage_url: `https://www.mixcloud.com/${info_json.owner.username}/${info_json.slug}`,
-        url: decrypted_url
-      })
-
-      /* const url_keys = ['url', 'hlsUrl', 'dashUrl']
-       * url_keys.forEach((url_key) => {
-       *   const format_url = info_json.streamInfo[url_key]
-       *   console.log(format_url)
-
-       *   const format_url_decoded = new Buffer(format_url, 'base64').toString('ascii')
-       *   const decrypted = xorStrings(key, format_url_decoded)
-       *   console.log(decrypted)
-       * })
-       */
-    }
-  }
-}
-
-class MixcloudPlaylistResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Mixcloud:playlist'
-    this._valid_url = /^https?:\/\/(?:www\.)?mixcloud\.com\/([^\/]+)\/playlists\/([^\/]+)\/?$/ig
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-class MixcloudUserResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Mixcloud:user'
-    this._valid_url = /^https?:\/\/(?:www\.)?mixcloud\.com\/([^\/]+)\/(uploads|favorites|listens)?\/?$/ig
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-module.exports.default = [
-  MixcloudResolver,
-  MixcloudPlaylistResolver,
-  MixcloudUserResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/resolver.js
+++ /dev/null
@@ -1,28 +0,0 @@
-const extend = require('deep-extend')
-
-const defaultInfo = {
-  id: null,
-  extractor: null,
-  url: null,
-  fulltitle: null,
-  webpage_url: null,
-  thumbnail: null,
-  duration: null
-}
-
-class Resolver {
-  constructor () {
-
-  }
-
-  suitable (url) {
-    return this._valid_url.test(url)
-  }
-
-  extract (info) {
-    return extend(defaultInfo, info)
-  }
-
-}
-
-module.exports = Resolver
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/soundcloud.js
+++ /dev/null
@@ -1,279 +0,0 @@
-const URI = require('urijs')
-
-const { request } = require('../utils')
-const ERRORS = require('../errors')
-const Resolver = require('./resolver')
-
-let _CLIENT_ID
-
-const _resolveUrl = (url) => {
-  return `https://api.soundcloud.com/resolve.json?url=${url}&client_id=${_CLIENT_ID}`
-}
-
-const _streamUrl = (url, token) => {
-  return new URI(url).query((data) => {
-    data.client_id = _CLIENT_ID
-
-    if (token) {
-      data.secret_token = token
-    }
-  }).toString()
-}
-
-const _getClientId = async () => {
-  const { body } = await request({
-    url: 'https://soundcloud.com/',
-    maxAttempts: 2
-  })
-
-  const appjs_re = /\ssrc="(https:\/\/a-v2.sndcdn.com\/assets\/app-[A-Za-z0-9-]*.js)"><\/script>/
-  const appjs_url = body.match(appjs_re)[1]
-  const appjs_response = await request({ url: appjs_url, maxAttempts: 2 })
-
-  const client_id_re = /client_id:"([0-9A-Za-z]{32})"/
-  const CLIENT_ID = appjs_response.body.match(client_id_re)[1]
-
-  return CLIENT_ID
-}
-
-
-class SoundcloudResolver extends Resolver {
-  constructor () {
-    super()
-    this._CLIENT_ID
-    this._name = 'Soundcloud'
-    this._valid_url = new RegExp(
-      '^(?:https?:\/\/)?' +
-      '(?:(?:(?:www\\.|m\\.)?soundcloud\\.com\/' +
-      '(?!stations\/track)' +
-      '([\\w\\d-]+)\/' +
-      '(?!(?:tracks|sets(?:\/.+?)?|reposts|likes|spotlight)\/?(?:$|[?#]))' +
-      '([\\w\\d-]+)\/?' +
-      '([^?]+?)?(?:[?].*)?$)' +
-      '|(?:api\\.soundcloud\.com\/tracks\/(\\d+)' +
-      '(?:\/?\\?secret_token=([^&]+))?)' +
-      '|((?:w|player|p.)\\.soundcloud\\.com\/player\/?.*?url=.*))', 'i')
-  }
-
-  async extract (url) {
-    if (!_CLIENT_ID) {
-      _CLIENT_ID = await _getClientId()
-    }
-
-    const re_result = this._valid_url.exec(url)
-    const track_id = re_result[4]
-    let info_json_url, token
-
-    if (track_id) {
-      info_json_url = `https://api.soundcloud.com/tracks/${track_id}.json?client_id=${_CLIENT_ID}`
-      token = re_result[5]
-      if (token) {
-        info_json_url += `&secret_token=${token}`
-      }
-    } else if (re_result[6]) {
-      const query = new URI(url).query(true)
-
-      const real_url = query.url
-
-      if (query['secret_token']) {
-        real_url += `?secret_token=${query['secret_token']}`
-      }
-
-      if (this.suitable(real_url)) {
-        info_json_url = _streamUrl(real_url)
-      } else {
-
-        const spR = new SoundcloudPlaylistResolver()
-        if (spR.suitable(real_url)) {
-          return spR.extract(real_url)
-        }
-
-        const ssR = new SoundcloudSetResolver()
-        if (ssR.suitable(real_url)) {
-          return ssR.extract(real_url)
-        }
-
-        throw Object.assign(new Error('not a suitable url'), {
-          code: ERRORS.ERR_NOT_SUITABLE_URL,
-          url: real_url
-        })
-      }
-    } else {
-      const uploader = re_result[1]
-      const slug_title = re_result[2]
-      token = re_result[3]
-
-      let resolve_title = `${uploader}/${slug_title}`
-      if (token) {
-        resolve_title += `/${token}`
-      }
-
-      const url = `https://soundcloud.com/${resolve_title}`
-      info_json_url = _resolveUrl(url)
-    }
-
-    const { body } = await request({
-      url: info_json_url,
-      json: true
-    })
-
-    // TODO: handle CLIENT_ID related 401s & 403s
-
-    /* let qs = {
-     *   client_id: _CLIENT_ID
-     * }
-
-     * if (token) {
-     *   qs['secret_token'] = token
-     * }
-
-     * const stream_response = await request({
-     *   url: `https://api.soundcloud.com/i1/tracks/${body.id}/streams`,
-     *   qs: qs,
-     *   json: true
-     * }) */
-
-    const thumbnail = body.artwork_url ? body.artwork_url.replace('-large', '-t500x500') : null
-
-    return super.extract({
-      id: body.id,
-      thumbnail: thumbnail,
-      url: body.stream_url ? _streamUrl(body.stream_url, token) : null,
-      duration: parseInt(body.duration / 1000, 10),
-      fulltitle: body.title,
-      webpage_url: body.permalink_url,
-      extractor: this._name
-    })
-  }
-}
-
-class SoundcloudSetResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Soundcloud:set'
-    this._valid_url = /https?:\/\/(?:(?:www|m)\.)?soundcloud\.com\/([\w\d-]+)\/sets\/([\w\d-]+)(?:\/([^?\/]+))?/i
-  }
-
-  async extract (url) {
-    if (!_CLIENT_ID) {
-      _CLIENT_ID = await _getClientId()
-    }
-
-    const re_result = this._valid_url.exec(url)
-    const uploader = re_result[1]
-    const slug_title = re_result[2]
-    let full_title = `${uploader}/sets/${slug_title}`
-    let s_url = `https://soundcloud.com/${uploader}/sets/${slug_title}`
-
-    const token = re_result[3]
-    if (token) {
-      full_title += '/' + token
-      s_url += '/' + token
-    }
-
-    const resolve_url = _resolveUrl(s_url)
-    const { body } = await request({ url: resolve_url, json: true })
-
-    let entries = []
-
-    body.tracks.forEach((track) => {
-      const thumbnail = track.artwork_url ?
-                        track.artwork_url.replace('-large', '-t500x500') : null
-
-      entries.push({
-        id: track.id,
-        thumbnail: thumbnail,
-        duration: parseInt(track.duration / 1000, 10),
-        fulltitle: track.title,
-        extractor: this._name,
-        webpage_url: track.permalink_url,
-        url: _streamUrl(track.stream_url)
-      })
-    })
-
-    return entries
-  }
-}
-
-class SoundcloudUserResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Soundcloud:user'
-    this._valid_url = /https?:\/\/(?:(?:www|m)\.)?soundcloud\.com\/([^\/]+)(?:\/(tracks|sets|reposts|likes|spotlight))?\/?(?:[?#].*)?$/i
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-class SoundcloudPlaylistResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Soundcloud:playlist'
-    this._valid_url = /https?:\/\/api\.soundcloud\.com\/playlists\/([0-9]+)(?:\/?\?secret_token=([^&]+?))?$/i
-  }
-
-  async extract (url) {
-    if (!_CLIENT_ID) {
-      _CLIENT_ID = await _getClientId()
-    }
-
-    const re_result = this._valid_url.exec(url)
-    const playlist_id = re_result[1]
-    let base_url = `https://api.soundcloud.com/playlists/${playlist_id}.json?`
-    const token = re_result[2]
-    if (token) {
-      base_url += `secret_token=${token}`
-    }
-
-    base_url = _streamUrl(base_url)
-
-    const { body } = await request({ url: base_url, json: true })
-
-    let entries = []
-
-    body.tracks.forEach((track) => {
-      const thumbnail = track.artwork_url ?
-                        track.artwork_url.replace('-large', '-t500x500') : null
-
-      entries.push({
-        id: track.id,
-        thumbnail: thumbnail,
-        duration: parseInt(track.duration / 1000, 10),
-        fulltitle: track.title,
-        webpage_url: track.permalink_url,
-        extractor: this._name,
-        url: _streamUrl(track.stream_url)
-      })
-    })
-
-    return entries
-  }
-}
-
-class SoundcloudTrackStationResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._name = 'Soundcloud:trackstation'
-    this._valid_url = /https?:\/\/(?:(?:www|m)\.)?soundcloud\.com\/stations\/track\/[^\/]+\/([^\/?#&]+)/i
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-module.exports.SoundcloudResolver = SoundcloudResolver
-
-module.exports.default = [
-  SoundcloudResolver,
-  SoundcloudSetResolver,
-  SoundcloudUserResolver,
-  SoundcloudTrackStationResolver,
-  SoundcloudPlaylistResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/vimeo.js
+++ /dev/null
@@ -1,15 +0,0 @@
-const Resolver = require('./resolver')
-
-class VimeoResolver extends Resolver {
-  constructor () {
-    super()
-
-    this._valid_url = /vimeo/
-  }
-
-  async extract (url) {
-    throw new Error('Not Implemented')
-  }
-}
-
-module.exports.default = [VimeoResolver]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/resolvers/youtube.js
+++ /dev/null
@@ -1,110 +0,0 @@
-const ytdl = require('ytdl-core')
-
-const Resolver = require('./resolver')
-
-const playlist_re = '(?:PL|LL|EC|UU|FL|RD|UL|TL)[0-9A-Za-z-_]{10,}'
-const SUPPORTED_TYPES = [
-    'audio/mpeg',
-    'audio/mp3',
-    'audio/MPA',
-    'audio/mpa-robust',
-    'audio/mp4',
-    'audio/aac',
-    'audio/x-m4a',
-    'audio/MP4A-LATM',
-    'audio/mpeg4-generic',
-    'audio/ogg',
-    'audio/wav',
-    'audio/wave',
-    'audio/x-wav'
-]
-
-// sorted from worst to best
-const YTDL_AUDIO_ENCODINGS = [
-    'mp3',
-    'aac',
-    'vorbis',
-    'wav'
-]
-
-class YoutubeResolver extends Resolver {
-  constructor () {
-    super()
-    this._name = 'Youtube'
-
-    this._valid_url = new RegExp(
-      '(' +
-      '(?:https?:\/\/|\/\/)' +
-      '(?:(?:(?:(?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\\.com\/|' +
-      '(?:www\\.)?deturl\\.com\/www\\.youtube\\.com\/|' +
-      '(?:www\\.)?pwnyoutube\\.com\/|' +
-      '(?:www\\.)?hooktube\\.com\/|' +
-      '(?:www\\.)?yourepeat\\.com\/|' +
-      'tube\\.majestyc\\.net\/|' +
-      'youtube\\.googleapis\\.com\/)' +
-      '(?:.*?\\#\/)?' +
-      '(?:' +
-      '(?:(?:v|embed|e)\/(?!videoseries))' +
-      '|(?:' +
-      '(?:(?:watch|movie)(?:_popup)?(?:\\.php)?\/?)?' +
-      '(?:\\?|\\#!?)' +
-      '(?:.*?[&;])??' +
-      'v=' +
-      ')' +
-      '))' +
-      '|(?:' +
-      'youtu\\.be|' +
-      'vid\\.plus|' +
-      'zwearz\\.com\/watch|' +
-      ')\/' +
-      '|(?:www\\.)?cleanvideosearch\\.com\/media\/action\/yt\/watch\\?videoId=' +
-      ')' +
-      ')?' +
-      '([0-9A-Za-z_-]{11})' +
-      '(?!.*?\\blist=' +
-      '(?:' +
-      `%(${playlist_re})s|` +
-      'WL' +
-      ')' +
-      ')', 'i')
-    //'(?(1).+)?', 'i')
-  }
-
-  async extract (url) {
-    const re_result = this._valid_url.exec(url)
-    const video_id = re_result[2]
-
-    const info = await ytdl.getInfo(video_id)
-    let bestFormat
-
-    const formats = info.formats.filter((f) => {
-      if (!f.type) return false
-
-      const idx = f.type.indexOf(';')
-      const type = idx > -1 ? f.type.substr(0, idx) : f.type
-      return SUPPORTED_TYPES.indexOf(type) > -1
-    })
-
-    for (let i = 0; i < formats.length; i += 1) {
-      let format = formats[i]
-
-      if (bestFormat == null || format.audioBitrate > bestFormat.audioBitrate || (format.audioBitrate === bestFormat.audioBitrate && YTDL_AUDIO_ENCODINGS.indexOf(format.audioEncoding) > YTDL_AUDIO_ENCODINGS.indexOf(bestFormat.audioEncoding))) {
-	bestFormat = format;
-      }
-    }
-
-    return super.extract({
-      id: info.video_id,
-      extractor: this._name,
-      fulltitle: info.title,
-      url: bestFormat ? bestFormat.url : null,
-      webpage_url: info.video_url,
-      duration: parseInt(info.length_seconds, 10),
-      thumbnail: info.thumbnail_url
-    })
-  }
-}
-
-module.exports.default = [
-  YoutubeResolver
-]
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/8tracks.js
+++ /dev/null
@@ -1,54 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('8tracks Tests', () => {
-
-  const etracks_url = 'http://8tracks.com/larecreative/jeux-d-eau'
-  describe(`8tracks Track Test: ${etracks_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(etracks_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a 8tracks mix', () => {
-      result.should.have.length(9)
-    })
-
-    it('identify 8tracks id', () => {
-      result[0].id.should.equal(8765819)
-    })
-
-    it('identify extractor as 8tracks', () => {
-      result[0].extractor.should.equal('8tracks')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.equal('http://cft.8tracks.com/tf/033/632/313/Ymxy31.48k.v3.m4a')
-    })
-
-    /* it('identify thumbnail', () => {
-     *   result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-     * })
-     */
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('Gomez - Bone Tired')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://8tracks.com/tracks/8765819')
-    })
-
-    /* it('identify duration', () => {
-     *   result[0]._duration_raw.should.equal(389)
-     * })
-     */
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/audiomack.js
+++ /dev/null
@@ -1,54 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Audiomack Tests', () => {
-
-  const audiomack_url = 'http://www.audiomack.com/song/roosh-williams/extraordinary'
-  describe(`Audiomack Track Test: ${audiomack_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(audiomack_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single audiomack track', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify audiomack id', () => {
-      result[0].id.should.equal(310086)
-    })
-
-    it('identify extractor as audiomack', () => {
-      result[0].extractor.should.equal('Audiomack')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    /* it('identify thumbnail', () => {
-     *   result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-     * })
-     */
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('Extraordinary')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://www.audiomack.com/song/roosh-williams/extraordinary')
-    })
-
-    /* it('identify duration', () => {
-     *   result[0]._duration_raw.should.equal(389)
-     * })
-     */
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/audiomack_album.js
+++ /dev/null
@@ -1,54 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Audiomack Album Tests', () => {
-
-  const audiomack_url = 'https://audiomack.com/album/rapwisedotcom/ai-youngboy'
-  describe(`Audiomack Album Test: ${audiomack_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(audiomack_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify an audiomack album', () => {
-      result.should.have.length(15)
-    })
-
-    it('identify audiomack id', () => {
-      result[0].id.should.equal(3245616)
-    })
-
-    it('identify extractor as Audiomack:album', () => {
-      result[0].extractor.should.equal('Audiomack:album')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    /* it('identify thumbnail', () => {
-     *   result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-     * })
-     */
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('AI YoungBoy - Trappin')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('https://audiomack.com/song/rapwisedotcom/trappin')
-    })
-
-    /* it('identify duration', () => {
-     *   result[0]._duration_raw.should.equal(389)
-     * })
-     */
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/bandcamp.js
+++ /dev/null
@@ -1,53 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Bandcamp Tests', () => {
-
-  const bandcamp_url = 'http://youtube-dl.bandcamp.com/track/youtube-dl-test-song'
-  describe(`Bandcamp Track Test: ${bandcamp_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(bandcamp_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single bandcamp track', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify bandcamp id', () => {
-      result[0].id.should.equal(1812978515)
-    })
-
-    it('identify extractor as Bandcamp', () => {
-      result[0].extractor.should.equal('Bandcamp')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://f4.bcbits.com/img/a3216802731_5.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('youtube-dl  "\'/\\ä↭ - youtube-dl test song "\'/\\ä↭')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://youtube-dl.bandcamp.com/track/youtube-dl-test-song')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(9.8485)
-    })
-
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/bandcamp_album.js
+++ /dev/null
@@ -1,53 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Bandcamp Album Tests', () => {
-
-  const bandcamp_url = 'http://blazo.bandcamp.com/album/jazz-format-mixtape-vol-1'
-  describe(`Bandcamp Album Test: ${bandcamp_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(bandcamp_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a 22 bandcamp tracks', () => {
-      result.should.have.length(22)
-    })
-
-    it('identify bandcamp id', () => {
-      result[0].id.should.equal(1353101989)
-    })
-
-    it('identify extractor as Bandcamp:album', () => {
-      result[0].extractor.should.equal('Bandcamp:album')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://f4.bcbits.com/img/a1721150828_5.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('Intro')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://blazo.bandcamp.com/track/nujabes-the-final-view')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(19.335)
-    })
-
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/hypem.js
+++ /dev/null
@@ -1,54 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Hypem Tests', () => {
-
-  const hypem_url = 'https://hypem.com/track/hm5b/Busy+P+-+To+Protect+And+Entertain+(Crookers+Remix)'
-  describe(`Hypem Track Test: ${hypem_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(hypem_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single hypem track', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify hypem id', () => {
-      result[0].id.should.equal('hm5b')
-    })
-
-    it('identify extractor as hypem', () => {
-      result[0].extractor.should.equal('Hypem')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.equal('http://livingears.com/music/LivingEarsRadio/042410/To Protect And Entertain Crookers.mp3')
-    })
-
-    /* it('identify thumbnail', () => {
-     *   result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-     * })
-     */
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('To Protect And Entertain (Crookers Remix...')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('https://hypem.com/track/hm5b/Busy+P+-+To+Protect+And+Entertain+(Crookers+Remix)')
-    })
-
-    /* it('identify duration', () => {
-     *   result[0]._duration_raw.should.equal(389)
-     * })
-     */
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/mixcloud.js
+++ /dev/null
@@ -1,53 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Mixcloud Tests', () => {
-
-  const mixcloud_url = 'https://www.mixcloud.com/johndigweed/transitions-with-john-digweed-and-chymera/'
-  describe(`Mixcloud Mix Test: ${mixcloud_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(mixcloud_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single mixcloud mix', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify mixcloud id', () => {
-      result[0].id.should.equal('johndigweed-transitions-with-john-digweed-and-chymera')
-    })
-
-    it('identify extractor as Mixcloud', () => {
-      result[0].extractor.should.equal('Mixcloud')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://thumbnailer.mixcloud.com/unsafe/600x600/extaudio/8/7/5/b/76c0-c2b0-4dbb-86a8-7b3fa43c77b4.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('Transitions with John Digweed and Chymera')
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('https://www.mixcloud.com/johndigweed/transitions-with-john-digweed-and-chymera')
-    })
-
-    /* it('identify duration', () => {
-     *   result[0]._duration_raw.should.equal(6938)
-     * })
-     */
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/soundcloud.js
+++ /dev/null
@@ -1,53 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Soundcloud Tests', () => {
-
-  const soundcloud_url = 'http://soundcloud.com/skrillex/with-you-friends-long-drive'
-  describe(`Soundcloud Track Test: ${soundcloud_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(soundcloud_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single soundcloud track', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify soundcloud id', () => {
-      result[0].id.should.equal(21792171)
-    })
-
-    it('identify extractor as soundcloud', () => {
-      result[0].extractor.should.equal('Soundcloud')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('WITH YOU, FRIENDS (LONG DRIVE)')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(389)
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('https://soundcloud.com/skrillex/with-you-friends-long-drive')
-    })
-
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/soundcloud_playlist.js
+++ /dev/null
@@ -1,53 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Soundcloud Playlist Tests', () => {
-
-  const soundcloud_url = 'https://api.soundcloud.com/playlists/4110309'
-  describe(`Soundcloud Playlist Test: ${soundcloud_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(soundcloud_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a soundcloud set', () => {
-      result.should.have.length(6)
-    })
-
-    it('identify soundcloud id', () => {
-      result[0].id.should.equal(83411137)
-    })
-
-    it('identify extractor as soundcloud', () => {
-      result[0].extractor.should.equal('Soundcloud:playlist')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000043059968-sy1bg1-t500x500.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('TILT Brass Band improv - Sak Passé? (2003)')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(122)
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://soundcloud.com/non-site_records/tilt-improv_sak-passe_030812')
-    })
-
-  })
-
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/soundcloud_set.js
+++ /dev/null
@@ -1,51 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Soundcloud Set Tests', () => {
-
-  const soundcloud_url = 'http://soundcloud.com/skrillex/sets/scary-monsters-and-nice'
-  describe(`Soundcloud Set Test: ${soundcloud_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(soundcloud_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a soundcloud set', () => {
-      result.should.have.length(9)
-    })
-
-    it('identify soundcloud id', () => {
-      result[0].id.should.equal(21792165)
-    })
-
-    it('identify extractor as soundcloud', () => {
-      result[0].extractor.should.equal('Soundcloud:set')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://i1.sndcdn.com/artworks-000008793437-pgni6l-t500x500.jpg')
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('ROCK N\' ROLL (WILL TAKE YOU TO THE MOUNTAIN)')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(284)
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('http://soundcloud.com/skrillex/rock-n-roll-will-take-you-to')
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/url.js
+++ /dev/null
@@ -1,31 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-const resolverErrors = require('../').errors
-
-describe('Url Tests', () => {
-  it('catch invalid urls', (done) => {
-    const url = 's'
-    resolver(url, (err, info) => {
-      if (!err) {
-        return done('Did not throw invalid url error')
-      }
-
-      err.code.should.equal(resolverErrors.ERR_NOT_VALID_URL)
-      done()
-    })
-  })
-
-  it('catch empty urls', (done) => {
-    const url = ''
-    resolver(url, (err, info) => {
-      if (!err) {
-        return done('Did not throw empty url error')
-      }
-
-      err.code.should.equal(resolverErrors.ERR_MISSING_URL)
-      done()
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/test/youtube.js
+++ /dev/null
@@ -1,51 +0,0 @@
-const chai = require('chai')
-
-const should = chai.should()
-const resolver = require('../')
-
-describe('Youtube Tests', () => {
-
-  const video_url = 'http://www.youtube.com/watch?v=iODdvJGpfIA'
-  describe(`Youtube Video Test: ${video_url}`, () => {
-    let result
-
-    before((done) => {
-      resolver(video_url, (err, info) => {
-        result = info
-        done(err)
-      })
-    })
-
-    it('identify a single video', () => {
-      result.should.have.length(1)
-    })
-
-    it('identify youtube video id', () => {
-      result[0].id.should.equal('iODdvJGpfIA')
-    })
-
-    it('identify extractor as youtube', () => {
-      result[0].extractor.should.equal('Youtube')
-    })
-
-    it('identify thumbnail', () => {
-      result[0].thumbnail.should.equal('https://i.ytimg.com/vi/iODdvJGpfIA/default.jpg')
-    })
-
-    it('identify stream url', () => {
-      result[0].url.should.exist
-    })
-
-    it('identify title', () => {
-      result[0].fulltitle.should.equal('Fake Blood - Mars (Original Mix)')
-    })
-
-    it('identify duration', () => {
-      result[0].duration.should.equal(262)
-    })
-
-    it('identify webpage url', () => {
-      result[0].webpage_url.should.equal('https://www.youtube.com/watch?v=iODdvJGpfIA')
-    })
-  })
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/utils/index.js
+++ /dev/null
@@ -1 +0,0 @@
-module.exports.request = require('./request')
deleted file mode 100644
--- a/node_modules/record-node/node_modules/record-resolver/utils/request.js
+++ /dev/null
@@ -1,10 +0,0 @@
-const promisify = require('promisify-es6')
-const request = require('requestretry').defaults({
-  jar: true,
-  maxAttempts: 3,
-  rejectUnauthorized: false
-})
-
-module.exports = promisify((opts, callback) => {
-  request(opts, callback)
-})
deleted file mode 100644
--- a/node_modules/record-node/node_modules/string-width/index.js
+++ /dev/null
@@ -1,36 +0,0 @@
-'use strict';
-const stripAnsi = require('strip-ansi');
-const isFullwidthCodePoint = require('is-fullwidth-code-point');
-
-module.exports = str => {
-	if (typeof str !== 'string' || str.length === 0) {
-		return 0;
-	}
-
-	str = stripAnsi(str);
-
-	let width = 0;
-
-	for (let i = 0; i < str.length; i++) {
-		const code = str.codePointAt(i);
-
-		// Ignore control characters
-		if (code <= 0x1F || (code >= 0x7F && code <= 0x9F)) {
-			continue;
-		}
-
-		// Ignore combining characters
-		if (code >= 0x300 && code <= 0x36F) {
-			continue;
-		}
-
-		// Surrogates
-		if (code > 0xFFFF) {
-			i++;
-		}
-
-		width += isFullwidthCodePoint(code) ? 2 : 1;
-	}
-
-	return width;
-};
deleted file mode 100644
--- a/node_modules/record-node/node_modules/string-width/license
+++ /dev/null
@@ -1,9 +0,0 @@
-MIT License
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/string-width/readme.md
+++ /dev/null
@@ -1,42 +0,0 @@
-# string-width [![Build Status](https://travis-ci.org/sindresorhus/string-width.svg?branch=master)](https://travis-ci.org/sindresorhus/string-width)
-
-> Get the visual width of a string - the number of columns required to display it
-
-Some Unicode characters are [fullwidth](https://en.wikipedia.org/wiki/Halfwidth_and_fullwidth_forms) and use double the normal width. [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code) are stripped and doesn't affect the width.
-
-Useful to be able to measure the actual width of command-line output.
-
-
-## Install
-
-```
-$ npm install string-width
-```
-
-
-## Usage
-
-```js
-const stringWidth = require('string-width');
-
-stringWidth('古');
-//=> 2
-
-stringWidth('\u001b[1m古\u001b[22m');
-//=> 2
-
-stringWidth('a');
-//=> 1
-```
-
-
-## Related
-
-- [string-width-cli](https://github.com/sindresorhus/string-width-cli) - CLI for this module
-- [string-length](https://github.com/sindresorhus/string-length) - Get the real length of a string
-- [widest-line](https://github.com/sindresorhus/widest-line) - Get the visual width of the widest line in a string
-
-
-## License
-
-MIT © [Sindre Sorhus](https://sindresorhus.com)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/strip-ansi/index.js
+++ /dev/null
@@ -1,4 +0,0 @@
-'use strict';
-const ansiRegex = require('ansi-regex');
-
-module.exports = input => typeof input === 'string' ? input.replace(ansiRegex(), '') : input;
deleted file mode 100644
--- a/node_modules/record-node/node_modules/strip-ansi/license
+++ /dev/null
@@ -1,9 +0,0 @@
-MIT License
-
-Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/strip-ansi/readme.md
+++ /dev/null
@@ -1,39 +0,0 @@
-# strip-ansi [![Build Status](https://travis-ci.org/chalk/strip-ansi.svg?branch=master)](https://travis-ci.org/chalk/strip-ansi)
-
-> Strip [ANSI escape codes](https://en.wikipedia.org/wiki/ANSI_escape_code)
-
-
-## Install
-
-```
-$ npm install strip-ansi
-```
-
-
-## Usage
-
-```js
-const stripAnsi = require('strip-ansi');
-
-stripAnsi('\u001B[4mUnicorn\u001B[0m');
-//=> 'Unicorn'
-```
-
-
-## Related
-
-- [strip-ansi-cli](https://github.com/chalk/strip-ansi-cli) - CLI for this module
-- [has-ansi](https://github.com/chalk/has-ansi) - Check if a string has ANSI escape codes
-- [ansi-regex](https://github.com/chalk/ansi-regex) - Regular expression for matching ANSI escape codes
-- [chalk](https://github.com/chalk/chalk) - Terminal string styling done right
-
-
-## Maintainers
-
-- [Sindre Sorhus](https://github.com/sindresorhus)
-- [Josh Junon](https://github.com/qix-)
-
-
-## License
-
-MIT
deleted file mode 100644
--- a/node_modules/record-node/node_modules/y18n/LICENSE
+++ /dev/null
@@ -1,13 +0,0 @@
-Copyright (c) 2015, Contributors
-
-Permission to use, copy, modify, and/or distribute this software for any purpose
-with or without fee is hereby granted, provided that the above copyright notice
-and this permission notice appear in all copies.
-
-THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
-REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
-FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
-INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
-OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
-TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF
-THIS SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/y18n/README.md
+++ /dev/null
@@ -1,91 +0,0 @@
-# y18n
-
-[![Build Status][travis-image]][travis-url]
-[![Coverage Status][coveralls-image]][coveralls-url]
-[![NPM version][npm-image]][npm-url]
-[![js-standard-style][standard-image]][standard-url]
-
-The bare-bones internationalization library used by yargs.
-
-Inspired by [i18n](https://www.npmjs.com/package/i18n).
-
-## Examples
-
-_simple string translation:_
-
-```js
-var __ = require('y18n').__
-
-console.log(__('my awesome string %s', 'foo'))
-```
-
-output:
-
-`my awesome string foo`
-
-_pluralization support:_
-
-```js
-var __n = require('y18n').__n
-
-console.log(__n('one fish %s', '%d fishes %s', 2, 'foo'))
-```
-
-output:
-
-`2 fishes foo`
-
-## JSON Language Files
-
-The JSON language files should be stored in a `./locales` folder.
-File names correspond to locales, e.g., `en.json`, `pirate.json`.
-
-When strings are observed for the first time they will be
-added to the JSON file corresponding to the current locale.
-
-## Methods
-
-### require('y18n')(config)
-
-Create an instance of y18n with the config provided, options include:
-
-* `directory`: the locale directory, default `./locales`.
-* `updateFiles`: should newly observed strings be updated in file, default `true`.
-* `locale`: what locale should be used.
-* `fallbackToLanguage`: should fallback to a language-only file (e.g. `en.json`)
-  be allowed if a file matching the locale does not exist (e.g. `en_US.json`),
-  default `true`.
-
-### y18n.\_\_(str, arg, arg, arg)
-
-Print a localized string, `%s` will be replaced with `arg`s.
-
-### y18n.\_\_n(singularString, pluralString, count, arg, arg, arg)
-
-Print a localized string with appropriate pluralization. If `%d` is provided
-in the string, the `count` will replace this placeholder.
-
-### y18n.setLocale(str)
-
-Set the current locale being used.
-
-### y18n.getLocale()
-
-What locale is currently being used?
-
-### y18n.updateLocale(obj)
-
-Update the current locale with the key value pairs in `obj`.
-
-## License
-
-ISC
-
-[travis-url]: https://travis-ci.org/yargs/y18n
-[travis-image]: https://img.shields.io/travis/yargs/y18n.svg
-[coveralls-url]: https://coveralls.io/github/yargs/y18n
-[coveralls-image]: https://img.shields.io/coveralls/yargs/y18n.svg
-[npm-url]: https://npmjs.org/package/y18n
-[npm-image]: https://img.shields.io/npm/v/y18n.svg
-[standard-image]: https://img.shields.io/badge/code%20style-standard-brightgreen.svg
-[standard-url]: https://github.com/feross/standard
deleted file mode 100644
--- a/node_modules/record-node/node_modules/y18n/index.js
+++ /dev/null
@@ -1,172 +0,0 @@
-var fs = require('fs')
-var path = require('path')
-var util = require('util')
-
-function Y18N (opts) {
-  // configurable options.
-  opts = opts || {}
-  this.directory = opts.directory || './locales'
-  this.updateFiles = typeof opts.updateFiles === 'boolean' ? opts.updateFiles : true
-  this.locale = opts.locale || 'en'
-  this.fallbackToLanguage = typeof opts.fallbackToLanguage === 'boolean' ? opts.fallbackToLanguage : true
-
-  // internal stuff.
-  this.cache = {}
-  this.writeQueue = []
-}
-
-Y18N.prototype.__ = function () {
-  var args = Array.prototype.slice.call(arguments)
-  var str = args.shift()
-  var cb = function () {} // start with noop.
-
-  if (typeof args[args.length - 1] === 'function') cb = args.pop()
-  cb = cb || function () {} // noop.
-
-  if (!this.cache[this.locale]) this._readLocaleFile()
-
-  // we've observed a new string, update the language file.
-  if (!this.cache[this.locale][str] && this.updateFiles) {
-    this.cache[this.locale][str] = str
-
-    // include the current directory and locale,
-    // since these values could change before the
-    // write is performed.
-    this._enqueueWrite([this.directory, this.locale, cb])
-  } else {
-    cb()
-  }
-
-  return util.format.apply(util, [this.cache[this.locale][str] || str].concat(args))
-}
-
-Y18N.prototype._enqueueWrite = function (work) {
-  this.writeQueue.push(work)
-  if (this.writeQueue.length === 1) this._processWriteQueue()
-}
-
-Y18N.prototype._processWriteQueue = function () {
-  var _this = this
-  var work = this.writeQueue[0]
-
-  // destructure the enqueued work.
-  var directory = work[0]
-  var locale = work[1]
-  var cb = work[2]
-
-  var languageFile = this._resolveLocaleFile(directory, locale)
-  var serializedLocale = JSON.stringify(this.cache[locale], null, 2)
-
-  fs.writeFile(languageFile, serializedLocale, 'utf-8', function (err) {
-    _this.writeQueue.shift()
-    if (_this.writeQueue.length > 0) _this._processWriteQueue()
-    cb(err)
-  })
-}
-
-Y18N.prototype._readLocaleFile = function () {
-  var localeLookup = {}
-  var languageFile = this._resolveLocaleFile(this.directory, this.locale)
-
-  try {
-    localeLookup = JSON.parse(fs.readFileSync(languageFile, 'utf-8'))
-  } catch (err) {
-    if (err instanceof SyntaxError) {
-      err.message = 'syntax error in ' + languageFile
-    }
-
-    if (err.code === 'ENOENT') localeLookup = {}
-    else throw err
-  }
-
-  this.cache[this.locale] = localeLookup
-}
-
-Y18N.prototype._resolveLocaleFile = function (directory, locale) {
-  var file = path.resolve(directory, './', locale + '.json')
-  if (this.fallbackToLanguage && !this._fileExistsSync(file) && ~locale.lastIndexOf('_')) {
-    // attempt fallback to language only
-    var languageFile = path.resolve(directory, './', locale.split('_')[0] + '.json')
-    if (this._fileExistsSync(languageFile)) file = languageFile
-  }
-  return file
-}
-
-// this only exists because fs.existsSync() "will be deprecated"
-// see https://nodejs.org/api/fs.html#fs_fs_existssync_path
-Y18N.prototype._fileExistsSync = function (file) {
-  try {
-    return fs.statSync(file).isFile()
-  } catch (err) {
-    return false
-  }
-}
-
-Y18N.prototype.__n = function () {
-  var args = Array.prototype.slice.call(arguments)
-  var singular = args.shift()
-  var plural = args.shift()
-  var quantity = args.shift()
-
-  var cb = function () {} // start with noop.
-  if (typeof args[args.length - 1] === 'function') cb = args.pop()
-
-  if (!this.cache[this.locale]) this._readLocaleFile()
-
-  var str = quantity === 1 ? singular : plural
-  if (this.cache[this.locale][singular]) {
-    str = this.cache[this.locale][singular][quantity === 1 ? 'one' : 'other']
-  }
-
-  // we've observed a new string, update the language file.
-  if (!this.cache[this.locale][singular] && this.updateFiles) {
-    this.cache[this.locale][singular] = {
-      one: singular,
-      other: plural
-    }
-
-    // include the current directory and locale,
-    // since these values could change before the
-    // write is performed.
-    this._enqueueWrite([this.directory, this.locale, cb])
-  } else {
-    cb()
-  }
-
-  // if a %d placeholder is provided, add quantity
-  // to the arguments expanded by util.format.
-  var values = [str]
-  if (~str.indexOf('%d')) values.push(quantity)
-
-  return util.format.apply(util, values.concat(args))
-}
-
-Y18N.prototype.setLocale = function (locale) {
-  this.locale = locale
-}
-
-Y18N.prototype.getLocale = function () {
-  return this.locale
-}
-
-Y18N.prototype.updateLocale = function (obj) {
-  if (!this.cache[this.locale]) this._readLocaleFile()
-
-  for (var key in obj) {
-    this.cache[this.locale][key] = obj[key]
-  }
-}
-
-module.exports = function (opts) {
-  var y18n = new Y18N(opts)
-
-  // bind all functions to y18n, so that
-  // they can be used in isolation.
-  for (var key in y18n) {
-    if (typeof y18n[key] === 'function') {
-      y18n[key] = y18n[key].bind(y18n)
-    }
-  }
-
-  return y18n
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs-parser/CHANGELOG.md
+++ /dev/null
@@ -1,300 +0,0 @@
-# Change Log
-
-All notable changes to this project will be documented in this file. See [standard-version](https://github.com/conventional-changelog/standard-version) for commit guidelines.
-
-<a name="9.0.2"></a>
-## [9.0.2](https://github.com/yargs/yargs-parser/compare/v9.0.1...v9.0.2) (2018-01-20)
-
-
-### Bug Fixes
-
-* nargs was still aggressively consuming too many arguments ([9b28aad](https://github.com/yargs/yargs-parser/commit/9b28aad))
-
-
-
-<a name="9.0.1"></a>
-## [9.0.1](https://github.com/yargs/yargs-parser/compare/v9.0.0...v9.0.1) (2018-01-20)
-
-
-### Bug Fixes
-
-* nargs was consuming too many arguments ([4fef206](https://github.com/yargs/yargs-parser/commit/4fef206))
-
-
-
-<a name="9.0.0"></a>
-# [9.0.0](https://github.com/yargs/yargs-parser/compare/v8.1.0...v9.0.0) (2018-01-20)
-
-
-### Features
-
-* narg arguments no longer consume flag arguments ([#114](https://github.com/yargs/yargs-parser/issues/114)) ([60bb9b3](https://github.com/yargs/yargs-parser/commit/60bb9b3))
-
-
-### BREAKING CHANGES
-
-* arguments of form --foo, -abc, will no longer be consumed by nargs
-
-
-
-<a name="8.1.0"></a>
-# [8.1.0](https://github.com/yargs/yargs-parser/compare/v8.0.0...v8.1.0) (2017-12-20)
-
-
-### Bug Fixes
-
-* allow null config values ([#108](https://github.com/yargs/yargs-parser/issues/108)) ([d8b14f9](https://github.com/yargs/yargs-parser/commit/d8b14f9))
-* ensure consistent parsing of dot-notation arguments ([#102](https://github.com/yargs/yargs-parser/issues/102)) ([c9bd79c](https://github.com/yargs/yargs-parser/commit/c9bd79c))
-* implement [@antoniom](https://github.com/antoniom)'s fix for camel-case expansion ([3087e1d](https://github.com/yargs/yargs-parser/commit/3087e1d))
-* only run coercion functions once, despite aliases. ([#76](https://github.com/yargs/yargs-parser/issues/76)) ([#103](https://github.com/yargs/yargs-parser/issues/103)) ([507aaef](https://github.com/yargs/yargs-parser/commit/507aaef))
-* scientific notation circumvented bounds check ([#110](https://github.com/yargs/yargs-parser/issues/110)) ([3571f57](https://github.com/yargs/yargs-parser/commit/3571f57))
-* tokenizer should ignore spaces at the beginning of the argString ([#106](https://github.com/yargs/yargs-parser/issues/106)) ([f34ead9](https://github.com/yargs/yargs-parser/commit/f34ead9))
-
-
-### Features
-
-* make combining arrays a configurable option ([#111](https://github.com/yargs/yargs-parser/issues/111)) ([c8bf536](https://github.com/yargs/yargs-parser/commit/c8bf536))
-* merge array from arguments with array from config ([#83](https://github.com/yargs/yargs-parser/issues/83)) ([806ddd6](https://github.com/yargs/yargs-parser/commit/806ddd6))
-
-
-
-<a name="8.0.0"></a>
-# [8.0.0](https://github.com/yargs/yargs-parser/compare/v7.0.0...v8.0.0) (2017-10-05)
-
-
-### Bug Fixes
-
-* Ignore multiple spaces between arguments. ([#100](https://github.com/yargs/yargs-parser/issues/100)) ([d137227](https://github.com/yargs/yargs-parser/commit/d137227))
-
-
-### Features
-
-* allow configuration of prefix for boolean negation ([#94](https://github.com/yargs/yargs-parser/issues/94)) ([00bde7d](https://github.com/yargs/yargs-parser/commit/00bde7d))
-* reworking how numbers are parsed ([#104](https://github.com/yargs/yargs-parser/issues/104)) ([fba00eb](https://github.com/yargs/yargs-parser/commit/fba00eb))
-
-
-### BREAKING CHANGES
-
-* strings that fail `Number.isSafeInteger()` are no longer coerced into numbers. 
-
-
-
-<a name="7.0.0"></a>
-# [7.0.0](https://github.com/yargs/yargs-parser/compare/v6.0.1...v7.0.0) (2017-05-02)
-
-
-### Chores
-
-* revert populate-- logic ([#91](https://github.com/yargs/yargs-parser/issues/91)) ([6003e6d](https://github.com/yargs/yargs-parser/commit/6003e6d))
-
-
-### BREAKING CHANGES
-
-* populate-- now defaults to false.
-
-
-
-<a name="6.0.1"></a>
-## [6.0.1](https://github.com/yargs/yargs-parser/compare/v6.0.0...v6.0.1) (2017-05-01)
-
-
-### Bug Fixes
-
-* default '--' to undefined when not provided; this is closer to the array API ([#90](https://github.com/yargs/yargs-parser/issues/90)) ([4e739cc](https://github.com/yargs/yargs-parser/commit/4e739cc))
-
-
-
-<a name="6.0.0"></a>
-# [6.0.0](https://github.com/yargs/yargs-parser/compare/v4.2.1...v6.0.0) (2017-05-01)
-
-
-### Bug Fixes
-
-* environment variables should take precedence over config file ([#81](https://github.com/yargs/yargs-parser/issues/81)) ([76cee1f](https://github.com/yargs/yargs-parser/commit/76cee1f))
-* parsing hints should apply for dot notation keys ([#86](https://github.com/yargs/yargs-parser/issues/86)) ([3e47d62](https://github.com/yargs/yargs-parser/commit/3e47d62))
-
-
-### Chores
-
-* upgrade to newest version of camelcase ([#87](https://github.com/yargs/yargs-parser/issues/87)) ([f1903aa](https://github.com/yargs/yargs-parser/commit/f1903aa))
-
-
-### Features
-
-* add -- option which allows arguments after the -- flag to be returned separated from positional arguments ([#84](https://github.com/yargs/yargs-parser/issues/84)) ([2572ca8](https://github.com/yargs/yargs-parser/commit/2572ca8))
-* when parsing stops, we now populate "--" by default ([#88](https://github.com/yargs/yargs-parser/issues/88)) ([cd666db](https://github.com/yargs/yargs-parser/commit/cd666db))
-
-
-### BREAKING CHANGES
-
-* rather than placing arguments in "_", when parsing is stopped via "--"; we now populate an array called "--" by default.
-* camelcase now requires Node 4+.
-* environment variables will now override config files (args, env, config-file, config-object)
-
-
-
-<a name="5.0.0"></a>
-# [5.0.0](https://github.com/yargs/yargs-parser/compare/v4.2.1...v5.0.0) (2017-02-18)
-
-
-### Bug Fixes
-
-* environment variables should take precedence over config file ([#81](https://github.com/yargs/yargs-parser/issues/81)) ([76cee1f](https://github.com/yargs/yargs-parser/commit/76cee1f))
-
-
-### BREAKING CHANGES
-
-* environment variables will now override config files (args, env, config-file, config-object)
-
-
-
-<a name="4.2.1"></a>
-## [4.2.1](https://github.com/yargs/yargs-parser/compare/v4.2.0...v4.2.1) (2017-01-02)
-
-
-### Bug Fixes
-
-* flatten/duplicate regression ([#75](https://github.com/yargs/yargs-parser/issues/75)) ([68d68a0](https://github.com/yargs/yargs-parser/commit/68d68a0))
-
-
-
-<a name="4.2.0"></a>
-# [4.2.0](https://github.com/yargs/yargs-parser/compare/v4.1.0...v4.2.0) (2016-12-01)
-
-
-### Bug Fixes
-
-* inner objects in configs had their keys appended to top-level key when dot-notation was disabled ([#72](https://github.com/yargs/yargs-parser/issues/72)) ([0b1b5f9](https://github.com/yargs/yargs-parser/commit/0b1b5f9))
-
-
-### Features
-
-* allow multiple arrays to be provided, rather than always combining ([#71](https://github.com/yargs/yargs-parser/issues/71)) ([0f0fb2d](https://github.com/yargs/yargs-parser/commit/0f0fb2d))
-
-
-
-<a name="4.1.0"></a>
-# [4.1.0](https://github.com/yargs/yargs-parser/compare/v4.0.2...v4.1.0) (2016-11-07)
-
-
-### Features
-
-* apply coercions to default options ([#65](https://github.com/yargs/yargs-parser/issues/65)) ([c79052b](https://github.com/yargs/yargs-parser/commit/c79052b))
-* handle dot notation boolean options ([#63](https://github.com/yargs/yargs-parser/issues/63)) ([02c3545](https://github.com/yargs/yargs-parser/commit/02c3545))
-
-
-
-<a name="4.0.2"></a>
-## [4.0.2](https://github.com/yargs/yargs-parser/compare/v4.0.1...v4.0.2) (2016-09-30)
-
-
-### Bug Fixes
-
-* whoops, let's make the assign not change the Object key order ([29d069a](https://github.com/yargs/yargs-parser/commit/29d069a))
-
-
-
-<a name="4.0.1"></a>
-## [4.0.1](https://github.com/yargs/yargs-parser/compare/v4.0.0...v4.0.1) (2016-09-30)
-
-
-### Bug Fixes
-
-* lodash.assign was deprecated ([#59](https://github.com/yargs/yargs-parser/issues/59)) ([5e7eb11](https://github.com/yargs/yargs-parser/commit/5e7eb11))
-
-
-
-<a name="4.0.0"></a>
-# [4.0.0](https://github.com/yargs/yargs-parser/compare/v3.2.0...v4.0.0) (2016-09-26)
-
-
-### Bug Fixes
-
-* coerce should be applied to the final objects and arrays created ([#57](https://github.com/yargs/yargs-parser/issues/57)) ([4ca69da](https://github.com/yargs/yargs-parser/commit/4ca69da))
-
-
-### BREAKING CHANGES
-
-* coerce is no longer applied to individual arguments in an implicit array.
-
-
-
-<a name="3.2.0"></a>
-# [3.2.0](https://github.com/yargs/yargs-parser/compare/v3.1.0...v3.2.0) (2016-08-13)
-
-
-### Features
-
-* coerce full array instead of each element ([#51](https://github.com/yargs/yargs-parser/issues/51)) ([cc4dc56](https://github.com/yargs/yargs-parser/commit/cc4dc56))
-
-
-
-<a name="3.1.0"></a>
-# [3.1.0](https://github.com/yargs/yargs-parser/compare/v3.0.0...v3.1.0) (2016-08-09)
-
-
-### Bug Fixes
-
-* address pkgConf parsing bug outlined in [#37](https://github.com/yargs/yargs-parser/issues/37) ([#45](https://github.com/yargs/yargs-parser/issues/45)) ([be76ee6](https://github.com/yargs/yargs-parser/commit/be76ee6))
-* better parsing of negative values ([#44](https://github.com/yargs/yargs-parser/issues/44)) ([2e43692](https://github.com/yargs/yargs-parser/commit/2e43692))
-* check aliases when guessing defaults for arguments fixes [#41](https://github.com/yargs/yargs-parser/issues/41) ([#43](https://github.com/yargs/yargs-parser/issues/43)) ([f3e4616](https://github.com/yargs/yargs-parser/commit/f3e4616))
-
-
-### Features
-
-* added coerce option, for providing specialized argument parsing ([#42](https://github.com/yargs/yargs-parser/issues/42)) ([7b49cd2](https://github.com/yargs/yargs-parser/commit/7b49cd2))
-
-
-
-<a name="3.0.0"></a>
-# [3.0.0](https://github.com/yargs/yargs-parser/compare/v2.4.1...v3.0.0) (2016-08-07)
-
-
-### Bug Fixes
-
-* parsing issue with numeric character in group of options ([#19](https://github.com/yargs/yargs-parser/issues/19)) ([f743236](https://github.com/yargs/yargs-parser/commit/f743236))
-* upgraded lodash.assign ([5d7fdf4](https://github.com/yargs/yargs-parser/commit/5d7fdf4))
-
-### BREAKING CHANGES
-
-* subtle change to how values are parsed in a group of single-character arguments.
-* _first released in 3.1.0, better handling of negative values should be considered a breaking change._
-
-
-
-<a name="2.4.1"></a>
-## [2.4.1](https://github.com/yargs/yargs-parser/compare/v2.4.0...v2.4.1) (2016-07-16)
-
-
-### Bug Fixes
-
-* **count:** do not increment a default value ([#39](https://github.com/yargs/yargs-parser/issues/39)) ([b04a189](https://github.com/yargs/yargs-parser/commit/b04a189))
-
-
-
-<a name="2.4.0"></a>
-# [2.4.0](https://github.com/yargs/yargs-parser/compare/v2.3.0...v2.4.0) (2016-04-11)
-
-
-### Features
-
-* **environment:** Support nested options in environment variables ([#26](https://github.com/yargs/yargs-parser/issues/26)) thanks [@elas7](https://github.com/elas7) \o/ ([020778b](https://github.com/yargs/yargs-parser/commit/020778b))
-
-
-
-<a name="2.3.0"></a>
-# [2.3.0](https://github.com/yargs/yargs-parser/compare/v2.2.0...v2.3.0) (2016-04-09)
-
-
-### Bug Fixes
-
-* **boolean:** fix for boolean options with non boolean defaults (#20) ([2dbe86b](https://github.com/yargs/yargs-parser/commit/2dbe86b)), closes [(#20](https://github.com/(/issues/20)
-* **package:** remove tests from tarball ([0353c0d](https://github.com/yargs/yargs-parser/commit/0353c0d))
-* **parsing:** handle calling short option with an empty string as the next value. ([a867165](https://github.com/yargs/yargs-parser/commit/a867165))
-* boolean flag when next value contains the strings 'true' or 'false'. ([69941a6](https://github.com/yargs/yargs-parser/commit/69941a6))
-* update dependencies; add standard-version bin for next release (#24) ([822d9d5](https://github.com/yargs/yargs-parser/commit/822d9d5))
-
-### Features
-
-* **configuration:** Allow to pass configuration objects to yargs-parser ([0780900](https://github.com/yargs/yargs-parser/commit/0780900))
-* **normalize:** allow normalize to work with arrays ([e0eaa1a](https://github.com/yargs/yargs-parser/commit/e0eaa1a))
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs-parser/LICENSE.txt
+++ /dev/null
@@ -1,14 +0,0 @@
-Copyright (c) 2016, Contributors
-
-Permission to use, copy, modify, and/or distribute this software
-for any purpose with or without fee is hereby granted, provided
-that the above copyright notice and this permission notice
-appear in all copies.
-
-THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
-WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
-OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE
-LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES
-OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
-WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION,
-ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs-parser/README.md
+++ /dev/null
@@ -1,308 +0,0 @@
-# yargs-parser
-
-[![Build Status](https://travis-ci.org/yargs/yargs-parser.png)](https://travis-ci.org/yargs/yargs-parser)
-[![Coverage Status](https://coveralls.io/repos/yargs/yargs-parser/badge.svg?branch=)](https://coveralls.io/r/yargs/yargs-parser?branch=master)
-[![NPM version](https://img.shields.io/npm/v/yargs-parser.svg)](https://www.npmjs.com/package/yargs-parser)
-[![Windows Tests](https://img.shields.io/appveyor/ci/bcoe/yargs-parser/master.svg?label=Windows%20Tests)](https://ci.appveyor.com/project/bcoe/yargs-parser)
-[![Standard Version](https://img.shields.io/badge/release-standard%20version-brightgreen.svg)](https://github.com/conventional-changelog/standard-version)
-
-
-The mighty option parser used by [yargs](https://github.com/yargs/yargs).
-
-visit the [yargs website](http://yargs.js.org/) for more examples, and thorough usage instructions.
-
-<img width="250" src="https://raw.githubusercontent.com/yargs/yargs-parser/master/yargs-logo.png">
-
-## Example
-
-```sh
-npm i yargs-parser --save
-```
-
-```js
-var argv = require('yargs-parser')(process.argv.slice(2))
-console.log(argv)
-```
-
-```sh
-node example.js --foo=33 --bar hello
-{ _: [], foo: 33, bar: 'hello' }
-```
-
-_or parse a string!_
-
-```js
-var argv = require('./')('--foo=99 --bar=33')
-console.log(argv)
-```
-
-```sh
-{ _: [], foo: 99, bar: 33 }
-```
-
-Convert an array of mixed types before passing to `yargs-parser`:
-
-```js
-var parse = require('yargs-parser')
-parse(['-f', 11, '--zoom', 55].join(' '))   // <-- array to string
-parse(['-f', 11, '--zoom', 55].map(String)) // <-- array of strings
-```
-
-## API
-
-### require('yargs-parser')(args, opts={})
-
-Parses command line arguments returning a simple mapping of keys and values.
-
-**expects:**
-
-* `args`: a string or array of strings representing the options to parse.
-* `opts`: provide a set of hints indicating how `args` should be parsed:
-  * `opts.alias`: an object representing the set of aliases for a key: `{alias: {foo: ['f']}}`.
-  * `opts.array`: indicate that keys should be parsed as an array: `{array: ['foo', 'bar']}`.
-  * `opts.boolean`: arguments should be parsed as booleans: `{boolean: ['x', 'y']}`.
-  * `opts.config`: indicate a key that represents a path to a configuration file (this file will be loaded and parsed).
-  * `opts.coerce`: provide a custom synchronous function that returns a coerced value from the argument provided
-    (or throws an error), e.g. `{coerce: {foo: function (arg) {return modifiedArg}}}`.
-  * `opts.count`: indicate a key that should be used as a counter, e.g., `-vvv` = `{v: 3}`.
-  * `opts.default`: provide default values for keys: `{default: {x: 33, y: 'hello world!'}}`.
-  * `opts.envPrefix`: environment variables (`process.env`) with the prefix provided should be parsed.
-  * `opts.narg`: specify that a key requires `n` arguments: `{narg: {x: 2}}`.
-  * `opts.normalize`: `path.normalize()` will be applied to values set to this key.
-  * `opts.string`: keys should be treated as strings (even if they resemble a number `-x 33`).
-  * `opts.configuration`: provide configuration options to the yargs-parser (see: [configuration](#configuration)).
-  * `opts.number`: keys should be treated as numbers.
-  * `opts['--']`: arguments after the end-of-options flag `--` will be set to the `argv.['--']` array instead of being set to the `argv._` array.
-
-**returns:**
-
-* `obj`: an object representing the parsed value of `args`
-  * `key/value`: key value pairs for each argument and their aliases.
-  * `_`: an array representing the positional arguments.
-  * [optional] `--`:  an array with arguments after the end-of-options flag `--`.
-
-### require('yargs-parser').detailed(args, opts={})
-
-Parses a command line string, returning detailed information required by the
-yargs engine.
-
-**expects:**
-
-* `args`: a string or array of strings representing options to parse.
-* `opts`: provide a set of hints indicating how `args`, inputs are identical to `require('yargs-parser')(args, opts={})`.
-
-**returns:**
-
-* `argv`: an object representing the parsed value of `args`
-  * `key/value`: key value pairs for each argument and their aliases.
-  * `_`: an array representing the positional arguments.
-* `error`: populated with an error object if an exception occurred during parsing.
-* `aliases`: the inferred list of aliases built by combining lists in `opts.alias`.
-* `newAliases`: any new aliases added via camel-case expansion.
-* `configuration`: the configuration loaded from the `yargs` stanza in package.json.
-
-<a name="configuration"></a>
-
-### Configuration
-
-The yargs-parser applies several automated transformations on the keys provided
-in `args`. These features can be turned on and off using the `configuration` field
-of `opts`.
-
-```js
-var parsed = parser(['--no-dice'], {
-  configuration: {
-    'boolean-negation': false
-  }
-})
-```
-
-### short option groups
-
-* default: `true`.
-* key: `short-option-groups`.
-
-Should a group of short-options be treated as boolean flags?
-
-```sh
-node example.js -abc
-{ _: [], a: true, b: true, c: true }
-```
-
-_if disabled:_
-
-```sh
-node example.js -abc
-{ _: [], abc: true }
-```
-
-### camel-case expansion
-
-* default: `true`.
-* key: `camel-case-expansion`.
-
-Should hyphenated arguments be expanded into camel-case aliases?
-
-```sh
-node example.js --foo-bar
-{ _: [], 'foo-bar': true, fooBar: true }
-```
-
-_if disabled:_
-
-```sh
-node example.js --foo-bar
-{ _: [], 'foo-bar': true }
-```
-
-### dot-notation
-
-* default: `true`
-* key: `dot-notation`
-
-Should keys that contain `.` be treated as objects?
-
-```sh
-node example.js --foo.bar
-{ _: [], foo: { bar: true } }
-```
-
-_if disabled:_
-
-```sh
-node example.js --foo.bar
-{ _: [], "foo.bar": true }
-```
-
-### parse numbers
-
-* default: `true`
-* key: `parse-numbers`
-
-Should keys that look like numbers be treated as such?
-
-```sh
-node example.js --foo=99.3
-{ _: [], foo: 99.3 }
-```
-
-_if disabled:_
-
-```sh
-node example.js --foo=99.3
-{ _: [], foo: "99.3" }
-```
-
-### boolean negation
-
-* default: `true`
-* key: `boolean-negation`
-
-Should variables prefixed with `--no` be treated as negations?
-
-```sh
-node example.js --no-foo
-{ _: [], foo: false }
-```
-
-_if disabled:_
-
-```sh
-node example.js --no-foo
-{ _: [], "no-foo": true }
-```
-
-### combine arrays
-
-* default: `false`
-* key: `combine-arrays`
-
-Should arrays be combined when provided by both command line arguments and
-a configuration file.
-
-### duplicate arguments array
-
-* default: `true`
-* key: `duplicate-arguments-array`
-
-Should arguments be coerced into an array when duplicated:
-
-```sh
-node example.js -x 1 -x 2
-{ _: [], x: [1, 2] }
-```
-
-_if disabled:_
-
-```sh
-node example.js -x 1 -x 2
-{ _: [], x: 2 }
-```
-
-### flatten duplicate arrays
-
-* default: `true`
-* key: `flatten-duplicate-arrays`
-
-Should array arguments be coerced into a single array when duplicated:
-
-```sh
-node example.js -x 1 2 -x 3 4
-{ _: [], x: [1, 2, 3, 4] }
-```
-
-_if disabled:_
-
-```sh
-node example.js -x 1 2 -x 3 4
-{ _: [], x: [[1, 2], [3, 4]] }
-```
-
-### negation prefix
-
-* default: `no-`
-* key: `negation-prefix`
-
-The prefix to use for negated boolean variables.
-
-```sh
-node example.js --no-foo
-{ _: [], foo: false }
-```
-
-_if set to `quux`:_
-
-```sh
-node example.js --quuxfoo
-{ _: [], foo: false }
-```
-
-### populate --
-
-* default: `false`.
-* key: `populate--`
-
-Should unparsed flags be stored in `--` or `_`.
-
-_If disabled:_
-
-```sh
-node example.js a -b -- x y
-{ _: [ 'a', 'x', 'y' ], b: true }
-```
-
-_If enabled:_
-
-```sh
-node example.js a -b -- x y
-{ _: [ 'a' ], '--': [ 'x', 'y' ], b: true }
-```
-
-## Special Thanks
-
-The yargs project evolves from optimist and minimist. It owes its
-existence to a lot of James Halliday's hard work. Thanks [substack](https://github.com/substack) **beep** **boop** \o/
-
-## License
-
-ISC
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs-parser/index.js
+++ /dev/null
@@ -1,811 +0,0 @@
-var camelCase = require('camelcase')
-var path = require('path')
-var tokenizeArgString = require('./lib/tokenize-arg-string')
-var util = require('util')
-
-function parse (args, opts) {
-  if (!opts) opts = {}
-  // allow a string argument to be passed in rather
-  // than an argv array.
-  args = tokenizeArgString(args)
-  // aliases might have transitive relationships, normalize this.
-  var aliases = combineAliases(opts.alias || {})
-  var configuration = assign({
-    'short-option-groups': true,
-    'camel-case-expansion': true,
-    'dot-notation': true,
-    'parse-numbers': true,
-    'boolean-negation': true,
-    'negation-prefix': 'no-',
-    'duplicate-arguments-array': true,
-    'flatten-duplicate-arrays': true,
-    'populate--': false,
-    'combine-arrays': false
-  }, opts.configuration)
-  var defaults = opts.default || {}
-  var configObjects = opts.configObjects || []
-  var envPrefix = opts.envPrefix
-  var notFlagsOption = configuration['populate--']
-  var notFlagsArgv = notFlagsOption ? '--' : '_'
-  var newAliases = {}
-  // allow a i18n handler to be passed in, default to a fake one (util.format).
-  var __ = opts.__ || function (str) {
-    return util.format.apply(util, Array.prototype.slice.call(arguments))
-  }
-  var error = null
-  var flags = {
-    aliases: {},
-    arrays: {},
-    bools: {},
-    strings: {},
-    numbers: {},
-    counts: {},
-    normalize: {},
-    configs: {},
-    defaulted: {},
-    nargs: {},
-    coercions: {}
-  }
-  var negative = /^-[0-9]+(\.[0-9]+)?/
-  var negatedBoolean = new RegExp('^--' + configuration['negation-prefix'] + '(.+)')
-
-  ;[].concat(opts.array).filter(Boolean).forEach(function (key) {
-    flags.arrays[key] = true
-  })
-
-  ;[].concat(opts.boolean).filter(Boolean).forEach(function (key) {
-    flags.bools[key] = true
-  })
-
-  ;[].concat(opts.string).filter(Boolean).forEach(function (key) {
-    flags.strings[key] = true
-  })
-
-  ;[].concat(opts.number).filter(Boolean).forEach(function (key) {
-    flags.numbers[key] = true
-  })
-
-  ;[].concat(opts.count).filter(Boolean).forEach(function (key) {
-    flags.counts[key] = true
-  })
-
-  ;[].concat(opts.normalize).filter(Boolean).forEach(function (key) {
-    flags.normalize[key] = true
-  })
-
-  Object.keys(opts.narg || {}).forEach(function (k) {
-    flags.nargs[k] = opts.narg[k]
-  })
-
-  Object.keys(opts.coerce || {}).forEach(function (k) {
-    flags.coercions[k] = opts.coerce[k]
-  })
-
-  if (Array.isArray(opts.config) || typeof opts.config === 'string') {
-    ;[].concat(opts.config).filter(Boolean).forEach(function (key) {
-      flags.configs[key] = true
-    })
-  } else {
-    Object.keys(opts.config || {}).forEach(function (k) {
-      flags.configs[k] = opts.config[k]
-    })
-  }
-
-  // create a lookup table that takes into account all
-  // combinations of aliases: {f: ['foo'], foo: ['f']}
-  extendAliases(opts.key, aliases, opts.default, flags.arrays)
-
-  // apply default values to all aliases.
-  Object.keys(defaults).forEach(function (key) {
-    (flags.aliases[key] || []).forEach(function (alias) {
-      defaults[alias] = defaults[key]
-    })
-  })
-
-  var argv = { _: [] }
-
-  Object.keys(flags.bools).forEach(function (key) {
-    setArg(key, !(key in defaults) ? false : defaults[key])
-    setDefaulted(key)
-  })
-
-  var notFlags = []
-  if (args.indexOf('--') !== -1) {
-    notFlags = args.slice(args.indexOf('--') + 1)
-    args = args.slice(0, args.indexOf('--'))
-  }
-
-  for (var i = 0; i < args.length; i++) {
-    var arg = args[i]
-    var broken
-    var key
-    var letters
-    var m
-    var next
-    var value
-
-    // -- seperated by =
-    if (arg.match(/^--.+=/) || (
-      !configuration['short-option-groups'] && arg.match(/^-.+=/)
-    )) {
-      // Using [\s\S] instead of . because js doesn't support the
-      // 'dotall' regex modifier. See:
-      // http://stackoverflow.com/a/1068308/13216
-      m = arg.match(/^--?([^=]+)=([\s\S]*)$/)
-
-      // nargs format = '--f=monkey washing cat'
-      if (checkAllAliases(m[1], flags.nargs)) {
-        args.splice(i + 1, 0, m[2])
-        i = eatNargs(i, m[1], args)
-      // arrays format = '--f=a b c'
-      } else if (checkAllAliases(m[1], flags.arrays) && args.length > i + 1) {
-        args.splice(i + 1, 0, m[2])
-        i = eatArray(i, m[1], args)
-      } else {
-        setArg(m[1], m[2])
-      }
-    } else if (arg.match(negatedBoolean) && configuration['boolean-negation']) {
-      key = arg.match(negatedBoolean)[1]
-      setArg(key, false)
-
-    // -- seperated by space.
-    } else if (arg.match(/^--.+/) || (
-      !configuration['short-option-groups'] && arg.match(/^-.+/)
-    )) {
-      key = arg.match(/^--?(.+)/)[1]
-
-      // nargs format = '--foo a b c'
-      if (checkAllAliases(key, flags.nargs)) {
-        i = eatNargs(i, key, args)
-      // array format = '--foo a b c'
-      } else if (checkAllAliases(key, flags.arrays) && args.length > i + 1) {
-        i = eatArray(i, key, args)
-      } else {
-        next = args[i + 1]
-
-        if (next !== undefined && (!next.match(/^-/) ||
-          next.match(negative)) &&
-          !checkAllAliases(key, flags.bools) &&
-          !checkAllAliases(key, flags.counts)) {
-          setArg(key, next)
-          i++
-        } else if (/^(true|false)$/.test(next)) {
-          setArg(key, next)
-          i++
-        } else {
-          setArg(key, defaultForType(guessType(key, flags)))
-        }
-      }
-
-    // dot-notation flag seperated by '='.
-    } else if (arg.match(/^-.\..+=/)) {
-      m = arg.match(/^-([^=]+)=([\s\S]*)$/)
-      setArg(m[1], m[2])
-
-    // dot-notation flag seperated by space.
-    } else if (arg.match(/^-.\..+/)) {
-      next = args[i + 1]
-      key = arg.match(/^-(.\..+)/)[1]
-
-      if (next !== undefined && !next.match(/^-/) &&
-        !checkAllAliases(key, flags.bools) &&
-        !checkAllAliases(key, flags.counts)) {
-        setArg(key, next)
-        i++
-      } else {
-        setArg(key, defaultForType(guessType(key, flags)))
-      }
-    } else if (arg.match(/^-[^-]+/) && !arg.match(negative)) {
-      letters = arg.slice(1, -1).split('')
-      broken = false
-
-      for (var j = 0; j < letters.length; j++) {
-        next = arg.slice(j + 2)
-
-        if (letters[j + 1] && letters[j + 1] === '=') {
-          value = arg.slice(j + 3)
-          key = letters[j]
-
-          // nargs format = '-f=monkey washing cat'
-          if (checkAllAliases(key, flags.nargs)) {
-            args.splice(i + 1, 0, value)
-            i = eatNargs(i, key, args)
-          // array format = '-f=a b c'
-          } else if (checkAllAliases(key, flags.arrays) && args.length > i + 1) {
-            args.splice(i + 1, 0, value)
-            i = eatArray(i, key, args)
-          } else {
-            setArg(key, value)
-          }
-
-          broken = true
-          break
-        }
-
-        if (next === '-') {
-          setArg(letters[j], next)
-          continue
-        }
-
-        // current letter is an alphabetic character and next value is a number
-        if (/[A-Za-z]/.test(letters[j]) &&
-          /^-?\d+(\.\d*)?(e-?\d+)?$/.test(next)) {
-          setArg(letters[j], next)
-          broken = true
-          break
-        }
-
-        if (letters[j + 1] && letters[j + 1].match(/\W/)) {
-          setArg(letters[j], next)
-          broken = true
-          break
-        } else {
-          setArg(letters[j], defaultForType(guessType(letters[j], flags)))
-        }
-      }
-
-      key = arg.slice(-1)[0]
-
-      if (!broken && key !== '-') {
-        // nargs format = '-f a b c'
-        if (checkAllAliases(key, flags.nargs)) {
-          i = eatNargs(i, key, args)
-        // array format = '-f a b c'
-        } else if (checkAllAliases(key, flags.arrays) && args.length > i + 1) {
-          i = eatArray(i, key, args)
-        } else {
-          next = args[i + 1]
-
-          if (next !== undefined && (!/^(-|--)[^-]/.test(next) ||
-            next.match(negative)) &&
-            !checkAllAliases(key, flags.bools) &&
-            !checkAllAliases(key, flags.counts)) {
-            setArg(key, next)
-            i++
-          } else if (/^(true|false)$/.test(next)) {
-            setArg(key, next)
-            i++
-          } else {
-            setArg(key, defaultForType(guessType(key, flags)))
-          }
-        }
-      }
-    } else {
-      argv._.push(maybeCoerceNumber('_', arg))
-    }
-  }
-
-  // order of precedence:
-  // 1. command line arg
-  // 2. value from env var
-  // 3. value from config file
-  // 4. value from config objects
-  // 5. configured default value
-  applyEnvVars(argv, true) // special case: check env vars that point to config file
-  applyEnvVars(argv, false)
-  setConfig(argv)
-  setConfigObjects()
-  applyDefaultsAndAliases(argv, flags.aliases, defaults)
-  applyCoercions(argv)
-
-  // for any counts either not in args or without an explicit default, set to 0
-  Object.keys(flags.counts).forEach(function (key) {
-    if (!hasKey(argv, key.split('.'))) setArg(key, 0)
-  })
-
-  // '--' defaults to undefined.
-  if (notFlagsOption && notFlags.length) argv[notFlagsArgv] = []
-  notFlags.forEach(function (key) {
-    argv[notFlagsArgv].push(key)
-  })
-
-  // how many arguments should we consume, based
-  // on the nargs option?
-  function eatNargs (i, key, args) {
-    var ii
-    const toEat = checkAllAliases(key, flags.nargs)
-
-    // nargs will not consume flag arguments, e.g., -abc, --foo,
-    // and terminates when one is observed.
-    var available = 0
-    for (ii = i + 1; ii < args.length; ii++) {
-      if (!args[ii].match(/^-[^0-9]/)) available++
-      else break
-    }
-
-    if (available < toEat) error = Error(__('Not enough arguments following: %s', key))
-
-    const consumed = Math.min(available, toEat)
-    for (ii = i + 1; ii < (consumed + i + 1); ii++) {
-      setArg(key, args[ii])
-    }
-
-    return (i + consumed)
-  }
-
-  // if an option is an array, eat all non-hyphenated arguments
-  // following it... YUM!
-  // e.g., --foo apple banana cat becomes ["apple", "banana", "cat"]
-  function eatArray (i, key, args) {
-    var start = i + 1
-    var argsToSet = []
-    var multipleArrayFlag = i > 0
-    for (var ii = i + 1; ii < args.length; ii++) {
-      if (/^-/.test(args[ii]) && !negative.test(args[ii])) {
-        if (ii === start) {
-          setArg(key, defaultForType('array'))
-        }
-        multipleArrayFlag = true
-        break
-      }
-      i = ii
-      argsToSet.push(args[ii])
-    }
-    if (multipleArrayFlag) {
-      setArg(key, argsToSet.map(function (arg) {
-        return processValue(key, arg)
-      }))
-    } else {
-      argsToSet.forEach(function (arg) {
-        setArg(key, arg)
-      })
-    }
-
-    return i
-  }
-
-  function setArg (key, val) {
-    unsetDefaulted(key)
-
-    if (/-/.test(key) && configuration['camel-case-expansion']) {
-      addNewAlias(key, camelCase(key))
-    }
-
-    var value = processValue(key, val)
-
-    var splitKey = key.split('.')
-    setKey(argv, splitKey, value)
-
-    // handle populating aliases of the full key
-    if (flags.aliases[key]) {
-      flags.aliases[key].forEach(function (x) {
-        x = x.split('.')
-        setKey(argv, x, value)
-      })
-    }
-
-    // handle populating aliases of the first element of the dot-notation key
-    if (splitKey.length > 1 && configuration['dot-notation']) {
-      ;(flags.aliases[splitKey[0]] || []).forEach(function (x) {
-        x = x.split('.')
-
-        // expand alias with nested objects in key
-        var a = [].concat(splitKey)
-        a.shift() // nuke the old key.
-        x = x.concat(a)
-
-        setKey(argv, x, value)
-      })
-    }
-
-    // Set normalize getter and setter when key is in 'normalize' but isn't an array
-    if (checkAllAliases(key, flags.normalize) && !checkAllAliases(key, flags.arrays)) {
-      var keys = [key].concat(flags.aliases[key] || [])
-      keys.forEach(function (key) {
-        argv.__defineSetter__(key, function (v) {
-          val = path.normalize(v)
-        })
-
-        argv.__defineGetter__(key, function () {
-          return typeof val === 'string' ? path.normalize(val) : val
-        })
-      })
-    }
-  }
-
-  function addNewAlias (key, alias) {
-    if (!(flags.aliases[key] && flags.aliases[key].length)) {
-      flags.aliases[key] = [alias]
-      newAliases[alias] = true
-    }
-    if (!(flags.aliases[alias] && flags.aliases[alias].length)) {
-      addNewAlias(alias, key)
-    }
-  }
-
-  function processValue (key, val) {
-    // handle parsing boolean arguments --foo=true --bar false.
-    if (checkAllAliases(key, flags.bools) || checkAllAliases(key, flags.counts)) {
-      if (typeof val === 'string') val = val === 'true'
-    }
-
-    var value = maybeCoerceNumber(key, val)
-
-    // increment a count given as arg (either no value or value parsed as boolean)
-    if (checkAllAliases(key, flags.counts) && (isUndefined(value) || typeof value === 'boolean')) {
-      value = increment
-    }
-
-    // Set normalized value when key is in 'normalize' and in 'arrays'
-    if (checkAllAliases(key, flags.normalize) && checkAllAliases(key, flags.arrays)) {
-      if (Array.isArray(val)) value = val.map(path.normalize)
-      else value = path.normalize(val)
-    }
-    return value
-  }
-
-  function maybeCoerceNumber (key, value) {
-    if (!checkAllAliases(key, flags.strings) && !checkAllAliases(key, flags.coercions)) {
-      const shouldCoerceNumber = isNumber(value) && configuration['parse-numbers'] && (
-        Number.isSafeInteger(Math.floor(value))
-      )
-      if (shouldCoerceNumber || (!isUndefined(value) && checkAllAliases(key, flags.numbers))) value = Number(value)
-    }
-    return value
-  }
-
-  // set args from config.json file, this should be
-  // applied last so that defaults can be applied.
-  function setConfig (argv) {
-    var configLookup = {}
-
-    // expand defaults/aliases, in-case any happen to reference
-    // the config.json file.
-    applyDefaultsAndAliases(configLookup, flags.aliases, defaults)
-
-    Object.keys(flags.configs).forEach(function (configKey) {
-      var configPath = argv[configKey] || configLookup[configKey]
-      if (configPath) {
-        try {
-          var config = null
-          var resolvedConfigPath = path.resolve(process.cwd(), configPath)
-
-          if (typeof flags.configs[configKey] === 'function') {
-            try {
-              config = flags.configs[configKey](resolvedConfigPath)
-            } catch (e) {
-              config = e
-            }
-            if (config instanceof Error) {
-              error = config
-              return
-            }
-          } else {
-            config = require(resolvedConfigPath)
-          }
-
-          setConfigObject(config)
-        } catch (ex) {
-          if (argv[configKey]) error = Error(__('Invalid JSON config file: %s', configPath))
-        }
-      }
-    })
-  }
-
-  // set args from config object.
-  // it recursively checks nested objects.
-  function setConfigObject (config, prev) {
-    Object.keys(config).forEach(function (key) {
-      var value = config[key]
-      var fullKey = prev ? prev + '.' + key : key
-
-      // if the value is an inner object and we have dot-notation
-      // enabled, treat inner objects in config the same as
-      // heavily nested dot notations (foo.bar.apple).
-      if (typeof value === 'object' && value !== null && !Array.isArray(value) && configuration['dot-notation']) {
-        // if the value is an object but not an array, check nested object
-        setConfigObject(value, fullKey)
-      } else {
-        // setting arguments via CLI takes precedence over
-        // values within the config file.
-        if (!hasKey(argv, fullKey.split('.')) || (flags.defaulted[fullKey]) || (flags.arrays[fullKey] && configuration['combine-arrays'])) {
-          setArg(fullKey, value)
-        }
-      }
-    })
-  }
-
-  // set all config objects passed in opts
-  function setConfigObjects () {
-    if (typeof configObjects === 'undefined') return
-    configObjects.forEach(function (configObject) {
-      setConfigObject(configObject)
-    })
-  }
-
-  function applyEnvVars (argv, configOnly) {
-    if (typeof envPrefix === 'undefined') return
-
-    var prefix = typeof envPrefix === 'string' ? envPrefix : ''
-    Object.keys(process.env).forEach(function (envVar) {
-      if (prefix === '' || envVar.lastIndexOf(prefix, 0) === 0) {
-        // get array of nested keys and convert them to camel case
-        var keys = envVar.split('__').map(function (key, i) {
-          if (i === 0) {
-            key = key.substring(prefix.length)
-          }
-          return camelCase(key)
-        })
-
-        if (((configOnly && flags.configs[keys.join('.')]) || !configOnly) && (!hasKey(argv, keys) || flags.defaulted[keys.join('.')])) {
-          setArg(keys.join('.'), process.env[envVar])
-        }
-      }
-    })
-  }
-
-  function applyCoercions (argv) {
-    var coerce
-    var applied = {}
-    Object.keys(argv).forEach(function (key) {
-      if (!applied.hasOwnProperty(key)) { // If we haven't already coerced this option via one of its aliases
-        coerce = checkAllAliases(key, flags.coercions)
-        if (typeof coerce === 'function') {
-          try {
-            var value = coerce(argv[key])
-            ;([].concat(flags.aliases[key] || [], key)).forEach(ali => {
-              applied[ali] = argv[ali] = value
-            })
-          } catch (err) {
-            error = err
-          }
-        }
-      }
-    })
-  }
-
-  function applyDefaultsAndAliases (obj, aliases, defaults) {
-    Object.keys(defaults).forEach(function (key) {
-      if (!hasKey(obj, key.split('.'))) {
-        setKey(obj, key.split('.'), defaults[key])
-
-        ;(aliases[key] || []).forEach(function (x) {
-          if (hasKey(obj, x.split('.'))) return
-          setKey(obj, x.split('.'), defaults[key])
-        })
-      }
-    })
-  }
-
-  function hasKey (obj, keys) {
-    var o = obj
-
-    if (!configuration['dot-notation']) keys = [keys.join('.')]
-
-    keys.slice(0, -1).forEach(function (key) {
-      o = (o[key] || {})
-    })
-
-    var key = keys[keys.length - 1]
-
-    if (typeof o !== 'object') return false
-    else return key in o
-  }
-
-  function setKey (obj, keys, value) {
-    var o = obj
-
-    if (!configuration['dot-notation']) keys = [keys.join('.')]
-
-    keys.slice(0, -1).forEach(function (key, index) {
-      if (typeof o === 'object' && o[key] === undefined) {
-        o[key] = {}
-      }
-
-      if (typeof o[key] !== 'object' || Array.isArray(o[key])) {
-        // ensure that o[key] is an array, and that the last item is an empty object.
-        if (Array.isArray(o[key])) {
-          o[key].push({})
-        } else {
-          o[key] = [o[key], {}]
-        }
-
-        // we want to update the empty object at the end of the o[key] array, so set o to that object
-        o = o[key][o[key].length - 1]
-      } else {
-        o = o[key]
-      }
-    })
-
-    var key = keys[keys.length - 1]
-
-    var isTypeArray = checkAllAliases(keys.join('.'), flags.arrays)
-    var isValueArray = Array.isArray(value)
-    var duplicate = configuration['duplicate-arguments-array']
-
-    if (value === increment) {
-      o[key] = increment(o[key])
-    } else if (Array.isArray(o[key])) {
-      if (duplicate && isTypeArray && isValueArray) {
-        o[key] = configuration['flatten-duplicate-arrays'] ? o[key].concat(value) : [o[key]].concat([value])
-      } else if (!duplicate && Boolean(isTypeArray) === Boolean(isValueArray)) {
-        o[key] = value
-      } else {
-        o[key] = o[key].concat([value])
-      }
-    } else if (o[key] === undefined && isTypeArray) {
-      o[key] = isValueArray ? value : [value]
-    } else if (duplicate && !(o[key] === undefined || checkAllAliases(key, flags.bools) || checkAllAliases(keys.join('.'), flags.bools) || checkAllAliases(key, flags.counts))) {
-      o[key] = [ o[key], value ]
-    } else {
-      o[key] = value
-    }
-  }
-
-  // extend the aliases list with inferred aliases.
-  function extendAliases () {
-    Array.prototype.slice.call(arguments).forEach(function (obj) {
-      Object.keys(obj || {}).forEach(function (key) {
-        // short-circuit if we've already added a key
-        // to the aliases array, for example it might
-        // exist in both 'opts.default' and 'opts.key'.
-        if (flags.aliases[key]) return
-
-        flags.aliases[key] = [].concat(aliases[key] || [])
-        // For "--option-name", also set argv.optionName
-        flags.aliases[key].concat(key).forEach(function (x) {
-          if (/-/.test(x) && configuration['camel-case-expansion']) {
-            var c = camelCase(x)
-            if (c !== key && flags.aliases[key].indexOf(c) === -1) {
-              flags.aliases[key].push(c)
-              newAliases[c] = true
-            }
-          }
-        })
-        flags.aliases[key].forEach(function (x) {
-          flags.aliases[x] = [key].concat(flags.aliases[key].filter(function (y) {
-            return x !== y
-          }))
-        })
-      })
-    })
-  }
-
-  // check if a flag is set for any of a key's aliases.
-  function checkAllAliases (key, flag) {
-    var isSet = false
-    var toCheck = [].concat(flags.aliases[key] || [], key)
-
-    toCheck.forEach(function (key) {
-      if (flag[key]) isSet = flag[key]
-    })
-
-    return isSet
-  }
-
-  function setDefaulted (key) {
-    [].concat(flags.aliases[key] || [], key).forEach(function (k) {
-      flags.defaulted[k] = true
-    })
-  }
-
-  function unsetDefaulted (key) {
-    [].concat(flags.aliases[key] || [], key).forEach(function (k) {
-      delete flags.defaulted[k]
-    })
-  }
-
-  // return a default value, given the type of a flag.,
-  // e.g., key of type 'string' will default to '', rather than 'true'.
-  function defaultForType (type) {
-    var def = {
-      boolean: true,
-      string: '',
-      number: undefined,
-      array: []
-    }
-
-    return def[type]
-  }
-
-  // given a flag, enforce a default type.
-  function guessType (key, flags) {
-    var type = 'boolean'
-
-    if (checkAllAliases(key, flags.strings)) type = 'string'
-    else if (checkAllAliases(key, flags.numbers)) type = 'number'
-    else if (checkAllAliases(key, flags.arrays)) type = 'array'
-
-    return type
-  }
-
-  function isNumber (x) {
-    if (typeof x === 'number') return true
-    if (/^0x[0-9a-f]+$/i.test(x)) return true
-    return /^[-+]?(?:\d+(?:\.\d*)?|\.\d+)(e[-+]?\d+)?$/.test(x)
-  }
-
-  function isUndefined (num) {
-    return num === undefined
-  }
-
-  return {
-    argv: argv,
-    error: error,
-    aliases: flags.aliases,
-    newAliases: newAliases,
-    configuration: configuration
-  }
-}
-
-// if any aliases reference each other, we should
-// merge them together.
-function combineAliases (aliases) {
-  var aliasArrays = []
-  var change = true
-  var combined = {}
-
-  // turn alias lookup hash {key: ['alias1', 'alias2']} into
-  // a simple array ['key', 'alias1', 'alias2']
-  Object.keys(aliases).forEach(function (key) {
-    aliasArrays.push(
-      [].concat(aliases[key], key)
-    )
-  })
-
-  // combine arrays until zero changes are
-  // made in an iteration.
-  while (change) {
-    change = false
-    for (var i = 0; i < aliasArrays.length; i++) {
-      for (var ii = i + 1; ii < aliasArrays.length; ii++) {
-        var intersect = aliasArrays[i].filter(function (v) {
-          return aliasArrays[ii].indexOf(v) !== -1
-        })
-
-        if (intersect.length) {
-          aliasArrays[i] = aliasArrays[i].concat(aliasArrays[ii])
-          aliasArrays.splice(ii, 1)
-          change = true
-          break
-        }
-      }
-    }
-  }
-
-  // map arrays back to the hash-lookup (de-dupe while
-  // we're at it).
-  aliasArrays.forEach(function (aliasArray) {
-    aliasArray = aliasArray.filter(function (v, i, self) {
-      return self.indexOf(v) === i
-    })
-    combined[aliasArray.pop()] = aliasArray
-  })
-
-  return combined
-}
-
-function assign (defaults, configuration) {
-  var o = {}
-  configuration = configuration || {}
-
-  Object.keys(defaults).forEach(function (k) {
-    o[k] = defaults[k]
-  })
-  Object.keys(configuration).forEach(function (k) {
-    o[k] = configuration[k]
-  })
-
-  return o
-}
-
-// this function should only be called when a count is given as an arg
-// it is NOT called to set a default value
-// thus we can start the count at 1 instead of 0
-function increment (orig) {
-  return orig !== undefined ? orig + 1 : 1
-}
-
-function Parser (args, opts) {
-  var result = parse(args.slice(), opts)
-
-  return result.argv
-}
-
-// parse arguments and return detailed
-// meta information, aliases, etc.
-Parser.detailed = function (args, opts) {
-  return parse(args.slice(), opts)
-}
-
-module.exports = Parser
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs-parser/lib/tokenize-arg-string.js
+++ /dev/null
@@ -1,40 +0,0 @@
-// take an un-split argv string and tokenize it.
-module.exports = function (argString) {
-  if (Array.isArray(argString)) return argString
-
-  argString = argString.trim()
-
-  var i = 0
-  var prevC = null
-  var c = null
-  var opening = null
-  var args = []
-
-  for (var ii = 0; ii < argString.length; ii++) {
-    prevC = c
-    c = argString.charAt(ii)
-
-    // split on spaces unless we're in quotes.
-    if (c === ' ' && !opening) {
-      if (!(prevC === ' ')) {
-        i++
-      }
-      continue
-    }
-
-    // don't split the string if we're in matching
-    // opening or closing single and double quotes.
-    if (c === opening) {
-      opening = null
-      continue
-    } else if ((c === "'" || c === '"') && !opening) {
-      opening = c
-      continue
-    }
-
-    if (!args[i]) args[i] = ''
-    args[i] += c
-  }
-
-  return args
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/CHANGELOG.md
+++ /dev/null
@@ -1,1147 +0,0 @@
-# Change Log
-
-All notable changes to this project will be documented in this file. See [standard-version](https://github.com/conventional-changelog/standard-version) for commit guidelines.
-
-<a name="11.1.0"></a>
-# [11.1.0](https://github.com/yargs/yargs/compare/v11.0.0...v11.1.0) (2018-03-04)
-
-
-### Bug Fixes
-
-* choose correct config directory when require.main does not exist ([#1056](https://github.com/yargs/yargs/issues/1056)) ([a04678c](https://github.com/yargs/yargs/commit/a04678c))
-
-
-### Features
-
-* allow hidden options to be displayed with --show-hidden ([#1061](https://github.com/yargs/yargs/issues/1061)) ([ea862ae](https://github.com/yargs/yargs/commit/ea862ae))
-* extend *.rc files in addition to json ([#1080](https://github.com/yargs/yargs/issues/1080)) ([11691a6](https://github.com/yargs/yargs/commit/11691a6))
-
-
-
-<a name="11.0.0"></a>
-# [11.0.0](https://github.com/yargs/yargs/compare/v10.1.2...v11.0.0) (2018-01-22)
-
-
-### Bug Fixes
-
-* Set implicit nargs=1 when type=number requiresArg=true ([#1050](https://github.com/yargs/yargs/issues/1050)) ([2b56812](https://github.com/yargs/yargs/commit/2b56812))
-
-
-### Features
-
-* requiresArg is now simply an alias for nargs(1) ([#1054](https://github.com/yargs/yargs/issues/1054)) ([a3ddacc](https://github.com/yargs/yargs/commit/a3ddacc))
-
-
-### BREAKING CHANGES
-
-* requiresArg now has significantly different error output, matching nargs.
-
-
-
-<a name="10.1.2"></a>
-## [10.1.2](https://github.com/yargs/yargs/compare/v10.1.1...v10.1.2) (2018-01-17)
-
-
-### Bug Fixes
-
-* requiresArg should only be enforced if argument exists ([#1043](https://github.com/yargs/yargs/issues/1043)) ([fbf41ae](https://github.com/yargs/yargs/commit/fbf41ae))
-
-
-
-<a name="10.1.1"></a>
-## [10.1.1](https://github.com/yargs/yargs/compare/v10.1.0...v10.1.1) (2018-01-09)
-
-
-### Bug Fixes
-
-* Add `dirname` sanity check on `findUp` ([#1036](https://github.com/yargs/yargs/issues/1036)) ([331d103](https://github.com/yargs/yargs/commit/331d103))
-
-
-
-<a name="10.1.0"></a>
-# [10.1.0](https://github.com/yargs/yargs/compare/v10.0.3...v10.1.0) (2018-01-01)
-
-
-### Bug Fixes
-
-* 'undefined' should be taken to mean no argument was provided ([#1015](https://github.com/yargs/yargs/issues/1015)) ([c679e90](https://github.com/yargs/yargs/commit/c679e90))
-
-
-### Features
-
-* add missing simple chinese locale strings ([#1004](https://github.com/yargs/yargs/issues/1004)) ([3cc24ec](https://github.com/yargs/yargs/commit/3cc24ec))
-* add Norwegian Nynorsk translations ([#1028](https://github.com/yargs/yargs/issues/1028)) ([a5ac213](https://github.com/yargs/yargs/commit/a5ac213))
-* async command handlers ([#1001](https://github.com/yargs/yargs/issues/1001)) ([241124b](https://github.com/yargs/yargs/commit/241124b))
-* middleware ([#881](https://github.com/yargs/yargs/issues/881)) ([77b8dbc](https://github.com/yargs/yargs/commit/77b8dbc))
-
-
-
-<a name="10.0.3"></a>
-## [10.0.3](https://github.com/yargs/yargs/compare/v10.0.2...v10.0.3) (2017-10-21)
-
-
-### Bug Fixes
-
-* parse array rather than string, so that quotes are safe ([#993](https://github.com/yargs/yargs/issues/993)) ([c351685](https://github.com/yargs/yargs/commit/c351685))
-
-
-
-<a name="10.0.2"></a>
-## [10.0.2](https://github.com/yargs/yargs/compare/v10.0.1...v10.0.2) (2017-10-21)
-
-
-### Bug Fixes
-
-* fix tiny spacing issue with usage ([#992](https://github.com/yargs/yargs/issues/992)) ([7871327](https://github.com/yargs/yargs/commit/7871327))
-
-
-
-<a name="10.0.1"></a>
-## [10.0.1](https://github.com/yargs/yargs/compare/v10.0.0...v10.0.1) (2017-10-19)
-
-
-### Bug Fixes
-
-* help strings for nested commands were missing parent commands ([#990](https://github.com/yargs/yargs/issues/990)) ([cd1ca15](https://github.com/yargs/yargs/commit/cd1ca15))
-* use correct completion command in generated completion script ([#988](https://github.com/yargs/yargs/issues/988)) ([3c8ac1d](https://github.com/yargs/yargs/commit/3c8ac1d))
-
-
-
-<a name="10.0.0"></a>
-# [10.0.0](https://github.com/yargs/yargs/compare/v9.1.0...v10.0.0) (2017-10-18)
-
-
-### Bug Fixes
-
-* config and normalize can be disabled with false ([#952](https://github.com/yargs/yargs/issues/952)) ([3bb8771](https://github.com/yargs/yargs/commit/3bb8771))
-* less eager help command execution ([#972](https://github.com/yargs/yargs/issues/972)) ([8c1d7bf](https://github.com/yargs/yargs/commit/8c1d7bf))
-* the positional argument parse was clobbering global flag arguments ([#984](https://github.com/yargs/yargs/issues/984)) ([7e58453](https://github.com/yargs/yargs/commit/7e58453))
-
-
-### Features
-
-* .usage() can now be used to configure a default command ([#975](https://github.com/yargs/yargs/issues/975)) ([7269531](https://github.com/yargs/yargs/commit/7269531))
-* hidden options are now explicitly indicated using "hidden" flag ([#962](https://github.com/yargs/yargs/issues/962)) ([280d0d6](https://github.com/yargs/yargs/commit/280d0d6))
-* introduce .positional() for configuring positional arguments ([#967](https://github.com/yargs/yargs/issues/967)) ([cb16460](https://github.com/yargs/yargs/commit/cb16460))
-* replace $0 with file basename ([#983](https://github.com/yargs/yargs/issues/983)) ([20bb99b](https://github.com/yargs/yargs/commit/20bb99b))
-
-
-### BREAKING CHANGES
-
-* .usage() no longer accepts an options object as the second argument. It can instead be used as an alias for configuring a default command.
-* previously hidden options were simply implied using a falsy description
-* help command now only executes if it's the last positional in argv._
-
-
-
-<a name="9.1.0"></a>
-# [9.1.0](https://github.com/yargs/yargs/compare/v9.0.1...v9.1.0) (2017-09-25)
-
-
-### Bug Fixes
-
-* **command:** Run default cmd even if the only cmd ([#950](https://github.com/yargs/yargs/issues/950)) ([7b22203](https://github.com/yargs/yargs/commit/7b22203))
-
-
-### Features
-
-* multiple usage calls are now collected, not replaced ([#958](https://github.com/yargs/yargs/issues/958)) ([74a38b2](https://github.com/yargs/yargs/commit/74a38b2))
-
-
-
-<a name="9.0.1"></a>
-## [9.0.1](https://github.com/yargs/yargs/compare/v9.0.0...v9.0.1) (2017-09-17)
-
-
-### Bug Fixes
-
-* implications fails only displayed once ([#954](https://github.com/yargs/yargs/issues/954)) ([ac8088b](https://github.com/yargs/yargs/commit/ac8088b))
-
-
-
-<a name="9.0.0"></a>
-# [9.0.0](https://github.com/yargs/yargs/compare/v8.0.2...v9.0.0) (2017-09-03)
-
-
-### Bug Fixes
-
-* 'undefined' default value for choices resulted in validation failing ([782b896](https://github.com/yargs/yargs/commit/782b896))
-* address bug with handling of arrays of implications ([c240661](https://github.com/yargs/yargs/commit/c240661))
-* defaulting keys to 'undefined' interfered with conflicting key logic ([a8e0cff](https://github.com/yargs/yargs/commit/a8e0cff))
-* don't bother calling JSON.stringify() on string default values ([#891](https://github.com/yargs/yargs/issues/891)) ([628be21](https://github.com/yargs/yargs/commit/628be21))
-* exclude positional arguments from completion output ([#927](https://github.com/yargs/yargs/issues/927)) ([71c7ec7](https://github.com/yargs/yargs/commit/71c7ec7))
-* strict mode should not fail for hidden options ([#949](https://github.com/yargs/yargs/issues/949)) ([0e0c58d](https://github.com/yargs/yargs/commit/0e0c58d))
-
-
-### Features
-
-* allow implies and conflicts to accept array values ([#922](https://github.com/yargs/yargs/issues/922)) ([abdc7da](https://github.com/yargs/yargs/commit/abdc7da))
-* allow parse with no arguments as alias for yargs.argv ([#944](https://github.com/yargs/yargs/issues/944)) ([a9f03e7](https://github.com/yargs/yargs/commit/a9f03e7))
-* enable .help() and .version() by default ([#912](https://github.com/yargs/yargs/issues/912)) ([1ef44e0](https://github.com/yargs/yargs/commit/1ef44e0))
-* to allow both undefined and nulls, for benefit of TypeScript  ([#945](https://github.com/yargs/yargs/issues/945)) ([792564d](https://github.com/yargs/yargs/commit/792564d))
-
-
-### BREAKING CHANGES
-
-* version() and help() are now enabled by default, and show up in help output; the implicit help command can no longer be enabled/disabled independently from the help command itself (which can now be disabled).
-* parse() now behaves as an alias for .argv, unless a parseCallback is provided.
-
-
-
-<a name="8.0.2"></a>
-## [8.0.2](https://github.com/yargs/yargs/compare/v8.0.1...v8.0.2) (2017-06-12)
-
-
-
-<a name="8.0.1"></a>
-## [8.0.1](https://github.com/yargs/yargs/compare/v8.0.0...v8.0.1) (2017-05-02)
-
-
-
-<a name="8.0.0"></a>
-# [8.0.0](https://github.com/yargs/yargs/compare/v7.1.0...v8.0.0) (2017-05-01)
-
-
-### Bug Fixes
-
-* commands are now applied in order, from left to right ([#857](https://github.com/yargs/yargs/issues/857)) ([baba863](https://github.com/yargs/yargs/commit/baba863))
-* help now takes precedence over command recommendation ([#866](https://github.com/yargs/yargs/issues/866)) ([17e3567](https://github.com/yargs/yargs/commit/17e3567))
-* positional arguments now work if no handler is provided to inner command ([#864](https://github.com/yargs/yargs/issues/864)) ([e28ded3](https://github.com/yargs/yargs/commit/e28ded3))
-
-
-### Chores
-
-* upgrade yargs-parser ([#867](https://github.com/yargs/yargs/issues/867)) ([8f9c6c6](https://github.com/yargs/yargs/commit/8f9c6c6))
-
-
-### Features
-
-* allow extends to inherit from a module ([#865](https://github.com/yargs/yargs/issues/865)) ([89456d9](https://github.com/yargs/yargs/commit/89456d9))
-* allow strict mode to be disabled ([#840](https://github.com/yargs/yargs/issues/840)) ([6f78c05](https://github.com/yargs/yargs/commit/6f78c05))
-
-
-### BREAKING CHANGES
-
-* extends functionality now always loads the JSON provided, rather than reading from a specific key
-* Node 4+ is now required; this will allow us to start updating our dependencies.
-* the first argument to strict() is now used to enable/disable its functionality, rather than controlling whether or not it is global.
-
-
-
-<a name="7.1.0"></a>
-# [7.1.0](https://github.com/yargs/yargs/compare/v7.0.2...v7.1.0) (2017-04-13)
-
-
-### Bug Fixes
-
-* fix demandOption no longer treats 'false' as truthy ([#829](https://github.com/yargs/yargs/issues/829)) ([c748dd2](https://github.com/yargs/yargs/commit/c748dd2))
-* get terminalWidth in non interactive mode no longer causes a validation exception ([#837](https://github.com/yargs/yargs/issues/837)) ([360e301](https://github.com/yargs/yargs/commit/360e301))
-* we shouldn't output help if we've printed a prior help-like message ([#847](https://github.com/yargs/yargs/issues/847)) ([17e89bd](https://github.com/yargs/yargs/commit/17e89bd))
-
-
-### Features
-
-* add support for numeric commands ([#825](https://github.com/yargs/yargs/issues/825)) ([fde0564](https://github.com/yargs/yargs/commit/fde0564))
-
-
-
-<a name="7.0.2"></a>
-## [7.0.2](https://github.com/yargs/yargs/compare/v7.0.1...v7.0.2) (2017-03-10)
-
-
-### Bug Fixes
-
-* populating placeholder arguments broke validation ([b3eb2fe](https://github.com/yargs/yargs/commit/b3eb2fe))
-
-
-
-<a name="7.0.1"></a>
-## [7.0.1](https://github.com/yargs/yargs/compare/v7.0.0...v7.0.1) (2017-03-03)
-
-
-### Bug Fixes
-
-* --help with default command should print top-level help ([#810](https://github.com/yargs/yargs/issues/810)) ([9c03fa4](https://github.com/yargs/yargs/commit/9c03fa4))
-
-
-
-<a name="7.0.0"></a>
-# [7.0.0](https://github.com/yargs/yargs/compare/v6.6.0...v7.0.0) (2017-02-26)
-
-
-### Bug Fixes
-
-* address min/max validation message regression ([#750](https://github.com/yargs/yargs/issues/750)) ([2e5ce0f](https://github.com/yargs/yargs/commit/2e5ce0f))
-* address positional argument strict() bug introduced in [#766](https://github.com/yargs/yargs/issues/766) ([#784](https://github.com/yargs/yargs/issues/784)) ([a8528e6](https://github.com/yargs/yargs/commit/a8528e6))
-* console.warn() rather than throwing errors when api signatures are incorrect ([#804](https://github.com/yargs/yargs/issues/804)) ([a607061](https://github.com/yargs/yargs/commit/a607061))
-* context should override parsed argv ([#786](https://github.com/yargs/yargs/issues/786)) ([0997288](https://github.com/yargs/yargs/commit/0997288))
-* context variables are now recognized in strict() mode ([#796](https://github.com/yargs/yargs/issues/796)) ([48575cd](https://github.com/yargs/yargs/commit/48575cd))
-* errors were not bubbling appropriately from sub-commands to top-level ([#802](https://github.com/yargs/yargs/issues/802)) ([8a992f5](https://github.com/yargs/yargs/commit/8a992f5))
-* positional arguments of sub-commands threw strict() exception ([#805](https://github.com/yargs/yargs/issues/805)) ([f3f074b](https://github.com/yargs/yargs/commit/f3f074b))
-* pull in yargs-parser with modified env precedence ([#787](https://github.com/yargs/yargs/issues/787)) ([e0fbbe5](https://github.com/yargs/yargs/commit/e0fbbe5))
-* running parse() multiple times on the same yargs instance caused exception if help() enabled ([#790](https://github.com/yargs/yargs/issues/790)) ([07e39b7](https://github.com/yargs/yargs/commit/07e39b7))
-* use path.resolve() to support node 0.10 ([#797](https://github.com/yargs/yargs/issues/797)) ([49a93fc](https://github.com/yargs/yargs/commit/49a93fc))
-
-
-### Features
-
-* add conflicts and implies shorthands. ([#753](https://github.com/yargs/yargs/issues/753)) ([bd1472b](https://github.com/yargs/yargs/commit/bd1472b))
-* add traditional Chinese translation ([#780](https://github.com/yargs/yargs/issues/780)) ([6ab6a95](https://github.com/yargs/yargs/commit/6ab6a95))
-* allow provided config object to extend other configs ([#779](https://github.com/yargs/yargs/issues/779)) ([3280dd0](https://github.com/yargs/yargs/commit/3280dd0))
-* function argument validation ([#773](https://github.com/yargs/yargs/issues/773)) ([22ed9bb](https://github.com/yargs/yargs/commit/22ed9bb))
-* if only one column is provided for examples, allow it to take up the entire line ([#749](https://github.com/yargs/yargs/issues/749)) ([7931652](https://github.com/yargs/yargs/commit/7931652))
-* introduce custom yargs error object ([#765](https://github.com/yargs/yargs/issues/765)) ([8308efa](https://github.com/yargs/yargs/commit/8308efa))
-* introduces support for default commands, using the '*' identifier ([#785](https://github.com/yargs/yargs/issues/785)) ([d78a0f5](https://github.com/yargs/yargs/commit/d78a0f5))
-* rethink how options are inherited by commands ([#766](https://github.com/yargs/yargs/issues/766)) ([ab1fa4b](https://github.com/yargs/yargs/commit/ab1fa4b))
-
-
-### BREAKING CHANGES
-
-* `extends` key in config file is now used for extending other config files
-* environment variables now take precedence over config files.
-* context now takes precedence over argv and defaults
-* the arguments passed to functions are now validated, there's a good chance this will throw exceptions for a few folks who are using the API in an unexpected way.
-* by default options, and many of yargs' parsing helpers will now default to being applied globally; such that they are no-longer reset before being passed into commands.
-* yargs will no longer aggressively suppress errors, allowing errors that are not generated internally to bubble.
-
-
-
-<a name="6.6.0"></a>
-# [6.6.0](https://github.com/yargs/yargs/compare/v6.5.0...v6.6.0) (2016-12-29)
-
-
-### Bug Fixes
-
-* [object Object] was accidentally being populated on options object ([#736](https://github.com/yargs/yargs/issues/736)) ([f755e27](https://github.com/yargs/yargs/commit/f755e27))
-* do not use cwd when resolving package.json for yargs parsing config ([#726](https://github.com/yargs/yargs/issues/726)) ([9bdaab7](https://github.com/yargs/yargs/commit/9bdaab7))
-
-
-### Features
-
-* implement conflicts() for defining mutually exclusive arguments; thanks [@madcampos](https://github.com/madcampos)! ([#741](https://github.com/yargs/yargs/issues/741)) ([5883779](https://github.com/yargs/yargs/commit/5883779))
-* split demand() into demandCommand()/demandOption() ([#740](https://github.com/yargs/yargs/issues/740)) ([66573c8](https://github.com/yargs/yargs/commit/66573c8))
-* support for positional argument aliases ([#727](https://github.com/yargs/yargs/issues/727)) ([27e1a57](https://github.com/yargs/yargs/commit/27e1a57))
-
-
-
-<a name="6.5.0"></a>
-# [6.5.0](https://github.com/yargs/yargs/compare/v6.4.0...v6.5.0) (2016-12-01)
-
-
-### Bug Fixes
-
-* still freeze/unfreeze if parse() is called in isolation ([#717](https://github.com/yargs/yargs/issues/717)) ([30a9492](https://github.com/yargs/yargs/commit/30a9492))
-
-
-### Features
-
-* pull in yargs-parser introducing additional settings ([#688](https://github.com/yargs/yargs/issues/688)), and fixing [#716](https://github.com/yargs/yargs/issues/716) ([#722](https://github.com/yargs/yargs/issues/722)) ([702995a](https://github.com/yargs/yargs/commit/702995a))
-
-
-
-<a name="6.4.0"></a>
-# [6.4.0](https://github.com/yargs/yargs/compare/v6.3.0...v6.4.0) (2016-11-13)
-
-
-### Bug Fixes
-
-* **locales:** correct some Russian translations ([#691](https://github.com/yargs/yargs/issues/691)) ([a980671](https://github.com/yargs/yargs/commit/a980671))
-
-
-### Features
-
-* **locales:** Added Belarusian translation ([#690](https://github.com/yargs/yargs/issues/690)) ([68dac1f](https://github.com/yargs/yargs/commit/68dac1f))
-* **locales:** Create nl.json ([#687](https://github.com/yargs/yargs/issues/687)) ([46ce1bb](https://github.com/yargs/yargs/commit/46ce1bb))
-* update to yargs-parser that addresses [#598](https://github.com/yargs/yargs/issues/598), [#617](https://github.com/yargs/yargs/issues/617) ([#700](https://github.com/yargs/yargs/issues/700)) ([54cb31d](https://github.com/yargs/yargs/commit/54cb31d))
-* yargs is now passed as the third-argument to fail handler ([#613](https://github.com/yargs/yargs/issues/613)) ([21b74f9](https://github.com/yargs/yargs/commit/21b74f9))
-
-
-### Performance Improvements
-
-* normalizing package data is an expensive operation ([#705](https://github.com/yargs/yargs/issues/705)) ([49cf533](https://github.com/yargs/yargs/commit/49cf533))
-
-
-
-<a name="6.3.0"></a>
-# [6.3.0](https://github.com/yargs/yargs/compare/v6.2.0...v6.3.0) (2016-10-19)
-
-
-### Bug Fixes
-
-* **command:** subcommands via commandDir() now supported for parse(msg, cb) ([#678](https://github.com/yargs/yargs/issues/678)) ([6b85cc6](https://github.com/yargs/yargs/commit/6b85cc6))
-
-
-### Features
-
-* **locales:** Add Thai locale file ([#679](https://github.com/yargs/yargs/issues/679)) ([c05e36b](https://github.com/yargs/yargs/commit/c05e36b))
-
-
-
-<a name="6.2.0"></a>
-# [6.2.0](https://github.com/yargs/yargs/compare/v6.1.1...v6.2.0) (2016-10-16)
-
-
-### Bug Fixes
-
-* stop applying parser to context object ([#675](https://github.com/yargs/yargs/issues/675)) ([3fe9b8f](https://github.com/yargs/yargs/commit/3fe9b8f))
-
-
-### Features
-
-* add new pt_BR translations ([#674](https://github.com/yargs/yargs/issues/674)) ([5615a82](https://github.com/yargs/yargs/commit/5615a82))
-* Italian translations for 'did you mean' and 'aliases' ([#673](https://github.com/yargs/yargs/issues/673)) ([81984e6](https://github.com/yargs/yargs/commit/81984e6))
-
-
-
-<a name="6.1.1"></a>
-## [6.1.1](https://github.com/yargs/yargs/compare/v6.1.0...v6.1.1) (2016-10-15)
-
-
-### Bug Fixes
-
-* freeze was not resetting configObjects to initial state; addressed performance issue raised by [@nexdrew](https://github.com/nexdrew). ([#670](https://github.com/yargs/yargs/issues/670)) ([ae4bcd4](https://github.com/yargs/yargs/commit/ae4bcd4))
-
-
-
-<a name="6.1.0"></a>
-# [6.1.0](https://github.com/yargs/yargs/compare/v6.0.0...v6.1.0) (2016-10-15)
-
-
-### Bug Fixes
-
-* **locales:** change some translations ([#667](https://github.com/yargs/yargs/issues/667)) ([aa966c5](https://github.com/yargs/yargs/commit/aa966c5))
-* **locales:** conform hi locale to y18n.__n expectations ([#666](https://github.com/yargs/yargs/issues/666)) ([22adb18](https://github.com/yargs/yargs/commit/22adb18))
-
-
-### Features
-
-* initial support for command aliases ([#647](https://github.com/yargs/yargs/issues/647)) ([127a040](https://github.com/yargs/yargs/commit/127a040))
-* **command:** add camelcase commands to argv ([#658](https://github.com/yargs/yargs/issues/658)) ([b1cabae](https://github.com/yargs/yargs/commit/b1cabae))
-* **locales:** add Hindi translations ([9290912](https://github.com/yargs/yargs/commit/9290912))
-* **locales:** add Hungarian translations  ([be92327](https://github.com/yargs/yargs/commit/be92327))
-* **locales:** Japanese translations for 'did you mean' and 'aliases'  ([#651](https://github.com/yargs/yargs/issues/651)) ([5eb78fc](https://github.com/yargs/yargs/commit/5eb78fc))
-* **locales:** Polish translations for 'did you mean' and 'aliases' ([#650](https://github.com/yargs/yargs/issues/650)) ([c951c0e](https://github.com/yargs/yargs/commit/c951c0e))
-* reworking yargs API to make it easier to run in headless environments, e.g., Slack ([#646](https://github.com/yargs/yargs/issues/646)) ([f284c29](https://github.com/yargs/yargs/commit/f284c29))
-* Turkish translations for 'did you mean' and 'aliases' ([#660](https://github.com/yargs/yargs/issues/660)) ([072fd45](https://github.com/yargs/yargs/commit/072fd45))
-
-
-
-<a name="6.0.0"></a>
-# [6.0.0](https://github.com/yargs/yargs/compare/v5.0.0...v6.0.0) (2016-09-30)
-
-
-### Bug Fixes
-
-* changed parsing of the command string to ignore extra spaces ([#600](https://github.com/yargs/yargs/issues/600)) ([e8e5a72](https://github.com/yargs/yargs/commit/e8e5a72))
-* drop lodash.assign ([#641](https://github.com/yargs/yargs/issues/641)) ([ad3146f](https://github.com/yargs/yargs/commit/ad3146f))
-* for args that have skipValidation set to `true`, check if the parsed arg is `true` ([#619](https://github.com/yargs/yargs/issues/619)) ([658a34c](https://github.com/yargs/yargs/commit/658a34c))
-* upgrade standard, and fix appveyor config so that it works with newest standard ([#607](https://github.com/yargs/yargs/issues/607)) ([c301f42](https://github.com/yargs/yargs/commit/c301f42))
-
-
-### Chores
-
-* upgrade yargs-parser ([#633](https://github.com/yargs/yargs/issues/633)) ([cc1224e](https://github.com/yargs/yargs/commit/cc1224e))
-
-
-### Features
-
-* make opts object optional for .option() ([#624](https://github.com/yargs/yargs/issues/624)) ([4f29de6](https://github.com/yargs/yargs/commit/4f29de6))
-
-
-### Performance Improvements
-
-* defer windowWidth() to improve perf for non-help usage ([#610](https://github.com/yargs/yargs/issues/610)) ([cbc3636](https://github.com/yargs/yargs/commit/cbc3636))
-
-
-### BREAKING CHANGES
-
-* coerce is now applied as a final step after other parsing is complete
-
-
-
-<a name="5.0.0"></a>
-# [5.0.0](https://github.com/yargs/yargs/compare/v4.8.1...v5.0.0) (2016-08-14)
-
-
-### Bug Fixes
-
-* **default:** Remove undocumented alias of default() ([#469](https://github.com/yargs/yargs/issues/469)) ([b8591b2](https://github.com/yargs/yargs/commit/b8591b2))
-* remove deprecated zh.json ([#578](https://github.com/yargs/yargs/issues/578)) ([317c62c](https://github.com/yargs/yargs/commit/317c62c))
-
-
-### Features
-
-* .help() API can now enable implicit help command ([#574](https://github.com/yargs/yargs/issues/574)) ([7645019](https://github.com/yargs/yargs/commit/7645019))
-* **command:** builder function no longer needs to return the yargs instance ([#549](https://github.com/yargs/yargs/issues/549)) ([eaa2873](https://github.com/yargs/yargs/commit/eaa2873))
-* add coerce api ([#586](https://github.com/yargs/yargs/issues/586)) ([1d53ccb](https://github.com/yargs/yargs/commit/1d53ccb))
-* adds recommendCommands() for command suggestions ([#580](https://github.com/yargs/yargs/issues/580)) ([59474dc](https://github.com/yargs/yargs/commit/59474dc))
-* apply .env() globally ([#553](https://github.com/yargs/yargs/issues/553)) ([be65728](https://github.com/yargs/yargs/commit/be65728))
-* apply default builder to command() and apply fail() handlers globally ([#583](https://github.com/yargs/yargs/issues/583)) ([0aaa68b](https://github.com/yargs/yargs/commit/0aaa68b))
-* update yargs-parser to version 3.1.0 ([#581](https://github.com/yargs/yargs/issues/581)) ([882a127](https://github.com/yargs/yargs/commit/882a127))
-
-
-### Performance Improvements
-
-* defer requiring most external libs until needed ([#584](https://github.com/yargs/yargs/issues/584)) ([f9b0ed4](https://github.com/yargs/yargs/commit/f9b0ed4))
-
-
-### BREAKING CHANGES
-
-* fail is now applied globally.
-* we now default to an empty builder function when command is executed with no builder.
-* yargs-parser now better handles negative integer values, at the cost of handling numeric option names, e.g., -1 hello
-* default: removed undocumented `defaults` alias for `default`.
-* introduces a default `help` command which outputs help, as an alternative to a help flag.
-* interpret demand() numbers as relative to executing command ([#582](https://github.com/yargs/yargs/issues/582)) ([927810c](https://github.com/yargs/yargs/commit/927810c))
-
-
-
-<a name="4.8.1"></a>
-## [4.8.1](https://github.com/yargs/yargs/compare/v4.8.0...v4.8.1) (2016-07-16)
-
-
-### Bug Fixes
-
-* **commandDir:** make dir relative to caller instead of require.main.filename ([#548](https://github.com/yargs/yargs/issues/548)) ([3c2e479](https://github.com/yargs/yargs/commit/3c2e479))
-* add config lookup for .implies() ([#556](https://github.com/yargs/yargs/issues/556)) ([8d7585c](https://github.com/yargs/yargs/commit/8d7585c))
-* cache pkg lookups by path to avoid returning the wrong one ([#552](https://github.com/yargs/yargs/issues/552)) ([fea7e0b](https://github.com/yargs/yargs/commit/fea7e0b))
-* positional arguments were not being handled appropriately by parse() ([#559](https://github.com/yargs/yargs/issues/559)) ([063a866](https://github.com/yargs/yargs/commit/063a866))
-* pull in [@nexdrew](https://github.com/nexdrew)'s fixes to yargs-parser ([#560](https://github.com/yargs/yargs/issues/560)) ([c77c080](https://github.com/yargs/yargs/commit/c77c080)), closes [#560](https://github.com/yargs/yargs/issues/560)
-
-
-
-<a name="4.8.0"></a>
-# [4.8.0](https://github.com/yargs/yargs/compare/v4.7.1...v4.8.0) (2016-07-09)
-
-
-### Bug Fixes
-
-* drop unused camelcase dependency fixes [#516](https://github.com/yargs/yargs/issues/516) ([#525](https://github.com/yargs/yargs/issues/525)) ([365fb9a](https://github.com/yargs/yargs/commit/365fb9a)), closes [#516](https://github.com/yargs/yargs/issues/516) [#525](https://github.com/yargs/yargs/issues/525)
-* fake a tty in tests, so that we can use the new set-blocking ([#512](https://github.com/yargs/yargs/issues/512)) ([a54c742](https://github.com/yargs/yargs/commit/a54c742))
-* ignore invalid package.json during read-pkg-up ([#546](https://github.com/yargs/yargs/issues/546)) ([e058c87](https://github.com/yargs/yargs/commit/e058c87))
-* keep both zh and zh_CN until yargs[@5](https://github.com/5).x ([0f8faa7](https://github.com/yargs/yargs/commit/0f8faa7))
-* lazy-load package.json and cache. get rid of pkg-conf dependency. ([#544](https://github.com/yargs/yargs/issues/544)) ([2609b2e](https://github.com/yargs/yargs/commit/2609b2e))
-* we now respect the order of _ when applying commands ([#537](https://github.com/yargs/yargs/issues/537)) ([ed86b78](https://github.com/yargs/yargs/commit/ed86b78))
-
-
-### Features
-
-* add .commandDir(dir) to API to apply all command modules from a relative directory ([#494](https://github.com/yargs/yargs/issues/494)) ([b299dff](https://github.com/yargs/yargs/commit/b299dff))
-* **command:** derive missing command string from module filename ([#527](https://github.com/yargs/yargs/issues/527)) ([20d4b8a](https://github.com/yargs/yargs/commit/20d4b8a))
-* builder is now optional for a command module ([#545](https://github.com/yargs/yargs/issues/545)) ([8d6ad6e](https://github.com/yargs/yargs/commit/8d6ad6e))
-
-
-
-<a name="4.7.1"></a>
-## [4.7.1](https://github.com/yargs/yargs/compare/v4.7.0...v4.7.1) (2016-05-15)
-
-
-### Bug Fixes
-
-* switch to using `const` rather than `var` ([#499](https://github.com/yargs/yargs/pull/499))
-* make stdout flush on newer versions of Node.js ([#501](https://github.com/yargs/yargs/issues/501)) ([9f8c6f4](https://github.com/yargs/yargs/commit/9f8c6f4))
-
-
-
-<a name="4.7.0"></a>
-# [4.7.0](https://github.com/yargs/yargs/compare/v4.6.0...v4.7.0) (2016-05-02)
-
-
-### Bug Fixes
-
-* **pkgConf:** fix aliases issues in .pkgConf() ([#478](https://github.com/yargs/yargs/issues/478))([b900502](https://github.com/yargs/yargs/commit/b900502))
-
-
-### Features
-
-* **completion:** allow to get completions for any string, not just process.argv ([#470](https://github.com/yargs/yargs/issues/470))([74fcfbc](https://github.com/yargs/yargs/commit/74fcfbc))
-* **configuration:** Allow to directly pass a configuration object to .config() ([#480](https://github.com/yargs/yargs/issues/480))([e0a7e05](https://github.com/yargs/yargs/commit/e0a7e05))
-* **validation:** Add .skipValidation() method ([#471](https://github.com/yargs/yargs/issues/471))([d72badb](https://github.com/yargs/yargs/commit/d72badb))
-
-
-
-<a name="4.6.0"></a>
-# [4.6.0](https://github.com/yargs/yargs/compare/v4.5.0...v4.6.0) (2016-04-11)
-
-
-### Bug Fixes
-
-* **my brand!:** I agree with [@osher](https://github.com/osher) lightweight isn't a huge selling point of ours any longer, see [#468](https://github.com/yargs/yargs/issues/468) ([c46d7e1](https://github.com/yargs/yargs/commit/c46d7e1))
-
-### Features
-
-* switch to standard-version for release management ([f70f801](https://github.com/yargs/yargs/commit/f70f801))
-* upgrade to version of yargs-parser that introduces some slick new features, great work [@elas7](https://github.com/elas7). update cliui, replace win-spawn, replace badge. ([#475](https://github.com/yargs/yargs/issues/475)) ([f915dd4](https://github.com/yargs/yargs/commit/f915dd4))
-
-
-
-<a name="4.5.0"></a>
-# [4.5.0](https://github.com/yargs/yargs/compare/v4.4.0...v4.5.0) (2016-04-05)
-
-
-### Bug Fixes
-
-* **windows:** handle $0 better on Windows platforms ([eb6e03f](https://github.com/yargs/yargs/commit/eb6e03f))
-
-### Features
-
-* **commands:** implemented variadic positional arguments ([51d926e](https://github.com/yargs/yargs/commit/51d926e))
-* **completion:** completion now better handles aliases, and avoids duplicating keys. ([86416c8](https://github.com/yargs/yargs/commit/86416c8))
-* **config:** If invoking .config() without parameters, set a default option ([0413dd1](https://github.com/yargs/yargs/commit/0413dd1))
-* **conventional-changelog:** switching to using conventional-changelog for generating the changelog ([a2b5a2a](https://github.com/yargs/yargs/commit/a2b5a2a))
-
-
-
-### v4.4.0 (2016/04/03 21:10 +07:00)
-
-- [#454](https://github.com/yargs/yargs/pull/454) fix demand() when second argument is an array (@elas7)
-- [#452](https://github.com/yargs/yargs/pull/452) fix code example for `.help()` docs (@maxrimue)
-- [#450](https://github.com/yargs/yargs/pull/450) fix for bash completion trailing space edge-case (@elas7)
-- [#448](https://github.com/yargs/yargs/pull/448) allow a method to be passed to `showHelp`, rather than a log-level (@osher)
-- [#446](https://github.com/yargs/yargs/pull/446) update yargs-parser, y18n, nyc, cliui, pkg-conf (@bcoe)
-- [#436](https://github.com/yargs/yargs/pull/436) the rebase method is only used by tests, do not export it in two places (@elas7)
-- [#428](https://github.com/yargs/yargs/pull/428) initial support for subcommands (@nexdrew)
-
-### v4.3.2 (2016/3/20 15:07 +07:00)
-
-- [#445](https://github.com/yargs/yargs/pull/445) strict mode was failing if no commands were registered (@nexdrew)
-- [#443](https://github.com/yargs/yargs/pull/443) adds Italian translation \o/ (@madrisan)
-- [#441](https://github.com/yargs/yargs/pull/441) remove duplicate keys from array options configuration (@elas7)
-- [#437](https://github.com/yargs/yargs/pull/437) standardize tests for .command() (@lrlna)
-
-### v4.3.0 (2016/3/12 14:19 +07:00)
-
-- [#432](https://github.com/yargs/yargs/pull/432) non-singleton version of yargs (@bcoe)
-- [#422, #425, #420] translations for number (@zkat, @rilut, @maxrimue, @watilde)
-- [#414](https://github.com/yargs/yargs/pull/414) all command options can be defined in module now (@nexdrew)
-
-### v4.2.0 (2016/2/22 11:02 +07:00)
-
-- [#395](https://github.com/yargs/yargs/pull/395) do not reset groups if they contain
-  global keys (@novemberborn)
-- [#393](https://github.com/yargs/yargs/pull/393) use sane default for usage strings (@nexdrew)
-- [#392](https://github.com/yargs/yargs/pull/392) resetting wrap() was causing layout issues
-  with commands (@nexdrew)
-- [#391](https://github.com/yargs/yargs/pull/391) commands were being added multiple times (@nexdrew)
-
-### v4.0.0 (2016/2/14 1:27 +07:00)
-
-- [#384](https://github.com/bcoe/yargs/pull/384) add new number type to yargs (@lrlna, @maxrimue)
-- [#382](https://github.com/bcoe/yargs/pull/382) pass error as extra parameter to fail (@gajus)
-- [#378](https://github.com/bcoe/yargs/pull/378) introduces the pkgConf feature, which tells
-  yargs to load default argument values from a key on a project's package.json (@bcoe)
-- [#376](https://github.com/bcoe/yargs/pull/376) **breaking change**, make help() method signature
-   more consistent with other commands (@maxrimue)
-- [#368](https://github.com/bcoe/yargs/pull/368) **breaking change**, overhaul to command handling API:
-  introducing named positional arguments, commands as modules, introduces the concept of global options (options that don't reset). (@nexdrew, @bcoe).
-- [#364](https://github.com/bcoe/yargs/pull/364) add the slick new yargs website to the package.json (@iarna).
-- [#357](https://github.com/bcoe/yargs/pull/357) .strict() now requires that a valid command is provided (@lrlna)
-- [#356](https://github.com/bcoe/yargs/pull/356) pull the parsing bits of yargs into the separate module yargs-parser. Various parsing options can now be turned on and off using configuration (@bcoe).
-- [#330](https://github.com/bcoe/yargs/pull/330) **breaking change**, fix inconsistencies with `.version()` API. (@maxrimue).
-
-### v3.32.0 (2016/1/14 10:13 +07:00)
-
-- [#344](https://github.com/bcoe/yargs/pull/344) yargs now has a code of conduct and contributor guidelines (@bcoe)
-- [#341](https://github.com/bcoe/yargs/issues/341) Fix edge-case with camel-case arguments (@davibe)
-- [#331](https://github.com/bcoe/yargs/pull/331) Handle parsing a raw argument string (@kellyselden)
-- [#325](https://github.com/bcoe/yargs/pull/325) Tweaks to make tests pass again on Windows (@isaacs)
-- [#321](https://github.com/bcoe/yargs/pull/321) Custom config parsing function (@bcoe)
-
-### v3.31.0 (2015/12/03 10:15 +07:00)
-
-- [#239](https://github.com/bcoe/yargs/pull/239) Pass argv to commands (@bcoe)
-- [#308](https://github.com/bcoe/yargs/pull/308) Yargs now handles environment variables (@nexdrew)
-- [#302](https://github.com/bcoe/yargs/pull/302) Add Indonesian translation (@rilut)
-- [#300](https://github.com/bcoe/yargs/pull/300) Add Turkish translation (@feyzo)
-- [#298](https://github.com/bcoe/yargs/pull/298) Add Norwegian Bokmål translation (@sindresorhus)
-- [#297](https://github.com/bcoe/yargs/pull/297) Fix for layout of cjk characters (@disjukr)
-- [#296](https://github.com/bcoe/yargs/pull/296) Add Korean translation (@disjukr)
-
-### v3.30.0 (2015/11/13 16:29 +07:00)
-
-- [#293](https://github.com/bcoe/yargs/pull/293) Polish language support (@kamilogorek)
-- [#291](https://github.com/bcoe/yargs/pull/291) fix edge-cases with `.alias()` (@bcoe)
-- [#289](https://github.com/bcoe/yargs/pull/289) group options in custom groups (@bcoe)
-
-### v3.29.0 (2015/10/16 21:51 +07:00)
-
-- [#282](https://github.com/bcoe/yargs/pull/282) completions now accept promises (@LinusU)
-- [#281](https://github.com/bcoe/yargs/pull/281) fix parsing issues with dot notation (@bcoe)
-
-### v3.28.0 (2015/10/16 1:55 +07:00)
-
-- [#277](https://github.com/bcoe/yargs/pull/277) adds support for ansi escape codes (@bcoe)
-
-### v3.27.0 (2015/10/08 1:55 +00:00)
-
-- [#271](https://github.com/bcoe/yargs/pull/273) skips validation for help or version flags with exitProcess(false) (@tepez)
-- [#273](https://github.com/bcoe/yargs/pull/273) implements single output for errors with exitProcess(false) (@nexdrew)
-- [#269](https://github.com/bcoe/yargs/pull/269) verifies single output for errors with exitProcess(false) (@tepez)
-- [#268](https://github.com/bcoe/yargs/pull/268) adds Chinese translation (@qiu8310)
-- [#266](https://github.com/bcoe/yargs/pull/266) adds case for -- after -- in parser test (@geophree)
-
-### v3.26.0 (2015/09/25 2:14 +00:00)
-
-- [#263](https://github.com/bcoe/yargs/pull/263) document count() and option() object keys (@nexdrew)
-- [#259](https://github.com/bcoe/yargs/pull/259) remove util in readme (@38elements)
-- [#258](https://github.com/bcoe/yargs/pull/258) node v4 builds, update deps (@nexdrew)
-- [#257](https://github.com/bcoe/yargs/pull/257) fix spelling errors (@dkoleary88)
-
-### v3.25.0 (2015/09/13 7:38 -07:00)
-
-- [#254](https://github.com/bcoe/yargs/pull/254) adds Japanese translation (@oti)
-- [#253](https://github.com/bcoe/yargs/pull/253) fixes for tests on Windows (@bcoe)
-
-### v3.24.0 (2015/09/04 12:02 +00:00)
-
-- [#248](https://github.com/bcoe/yargs/pull/248) reinstate os-locale, no spawning (@nexdrew)
-- [#249](https://github.com/bcoe/yargs/pull/249) use travis container-based infrastructure (@nexdrew)
-- [#247](https://github.com/bcoe/yargs/pull/247) upgrade standard (@nexdrew)
-
-### v3.23.0 (2015/08/30 23:00 +00:00)
-
-- [#246](https://github.com/bcoe/yargs/pull/246) detect locale based only on environment variables (@bcoe)
-- [#244](https://github.com/bcoe/yargs/pull/244) adds Windows CI testing (@bcoe)
-- [#245](https://github.com/bcoe/yargs/pull/245) adds OSX CI testing (@bcoe, @nexdrew)
-
-### v3.22.0 (2015/08/28 22:26 +00:00)
-- [#242](https://github.com/bcoe/yargs/pull/242) adds detectLocale config option (@bcoe)
-
-### v3.21.1 (2015/08/28 20:58 +00:00)
-- [#240](https://github.com/bcoe/yargs/pull/240) hot-fix for Atom on Windows (@bcoe)
-
-### v3.21.0 (2015/08/21 21:20 +00:00)
-- [#238](https://github.com/bcoe/yargs/pull/238) upgrade camelcase, window-size, chai, mocha (@nexdrew)
-- [#237](https://github.com/bcoe/yargs/pull/237) adds defaultDescription to option() (@nexdrew)
-
-### v3.20.0 (2015/08/20 01:29 +00:00)
-- [#231](https://github.com/bcoe/yargs/pull/231) Merge pull request #231 from bcoe/detect-locale (@sindresorhus)
-- [#235](https://github.com/bcoe/yargs/pull/235) adds german translation to yargs (@maxrimue)
-
-### v3.19.0 (2015/08/14 05:12 +00:00)
-- [#224](https://github.com/bcoe/yargs/pull/224) added Portuguese translation (@codemonkey3045)
-
-### v3.18.1 (2015/08/12 05:53 +00:00)
-
-- [#228](https://github.com/bcoe/yargs/pull/228) notes about embedding yargs in Electron (@etiktin)
-- [#223](https://github.com/bcoe/yargs/pull/223) make booleans work in config files (@sgentle)
-
-### v3.18.0 (2015/08/06 20:05 +00:00)
-- [#222](https://github.com/bcoe/yargs/pull/222) updates fr locale (@nexdrew)
-- [#221](https://github.com/bcoe/yargs/pull/221) adds missing locale strings (@nexdrew)
-- [#220](https://github.com/bcoe/yargs/pull/220) adds es locale (@zkat)
-
-### v3.17.1 (2015/08/02 19:35 +00:00)
-- [#218](https://github.com/bcoe/yargs/pull/218) upgrades nyc (@bcoe)
-
-### v3.17.0 (2015/08/02 18:39 +00:00)
-- [#217](https://github.com/bcoe/yargs/pull/217) sort methods in README.md (@nexdrew)
-- [#215](https://github.com/bcoe/yargs/pull/215) adds fr locale (@LoicMahieu)
-
-### v3.16.0 (2015/07/30 04:35 +00:00)
-- [#210](https://github.com/bcoe/yargs/pull/210) adds i18n support to yargs (@bcoe)
-- [#209](https://github.com/bcoe/yargs/pull/209) adds choices type to yargs (@nexdrew)
-- [#207](https://github.com/bcoe/yargs/pull/207) pretty new shields from shields.io (@SimenB)
-- [#208](https://github.com/bcoe/yargs/pull/208) improvements to README.md (@nexdrew)
-- [#205](https://github.com/bcoe/yargs/pull/205) faster build times on Travis (@ChristianMurphy)
-
-### v3.15.0 (2015/07/06 06:01 +00:00)
-- [#197](https://github.com/bcoe/yargs/pull/197) tweaks to how errors bubble up from parser.js (@bcoe)
-- [#193](https://github.com/bcoe/yargs/pull/193) upgraded nyc, reporting now happens by default (@bcoe)
-
-### v3.14.0 (2015/06/28 02:12 +00:00)
-
-- [#192](https://github.com/bcoe/yargs/pull/192) standard style nits (@bcoe)
-- [#190](https://github.com/bcoe/yargs/pull/190) allow for hidden commands, e.g.,
-  .completion('completion', false) (@tschaub)
-
-### v3.13.0 (2015/06/24 04:12 +00:00)
-
-- [#187](https://github.com/bcoe/yargs/pull/187) completion now behaves differently
-  if it is being run in the context of a command (@tschaub)
-- [#186](https://github.com/bcoe/yargs/pull/186) if no matches are found for a completion
-  default to filename completion (@tschaub)
-
-### v3.12.0 (2015/06/19 03:23 +00:00)
-- [#183](https://github.com/bcoe/yargs/pull/183) don't complete commands if they've already been completed (@tschaub)
-- [#181](https://github.com/bcoe/yargs/pull/181) various fixes for completion. (@bcoe, @tschaub)
-- [#182](https://github.com/bcoe/yargs/pull/182) you can now set a maximum # of of required arguments (@bcoe)
-
-### v3.11.0 (2015/06/15 05:15 +00:00)
-
-- [#173](https://github.com/bcoe/yargs/pull/173) update standard, window-size, chai (@bcoe)
-- [#171](https://github.com/bcoe/yargs/pull/171) a description can now be set
-  when providing a config option. (@5c077yP)
-
-### v3.10.0 (2015/05/29 04:25 +00:00)
-
-- [#165](https://github.com/bcoe/yargs/pull/165) expose yargs.terminalWidth() thanks @ensonic (@bcoe)
-- [#164](https://github.com/bcoe/yargs/pull/164) better array handling thanks @getify (@bcoe)
-
-### v3.9.1 (2015/05/20 05:14 +00:00)
-- [b6662b6](https://github.com/bcoe/yargs/commit/b6662b6774cfeab4876f41ec5e2f67b7698f4e2f) clarify .config() docs (@linclark)
-- [0291360](https://github.com/bcoe/yargs/commit/02913606285ce31ce81d7f12c48d8a3029776ec7) fixed tests, switched to nyc for coverage, fixed security issue, added Lin as collaborator (@bcoe)
-
-### v3.9.0 (2015/05/10 18:32 +00:00)
-- [#157](https://github.com/bcoe/yargs/pull/157) Merge pull request #157 from bcoe/command-yargs. allows handling of command specific arguments. Thanks for the suggestion @ohjames (@bcoe)
-- [#158](https://github.com/bcoe/yargs/pull/158) Merge pull request #158 from kemitchell/spdx-license. Update license format (@kemitchell)
-
-### v3.8.0 (2015/04/24 23:10 +00:00)
-- [#154](https://github.com/bcoe/yargs/pull/154) showHelp's method signature was misleading fixes #153 (@bcoe)
-- [#151](https://github.com/bcoe/yargs/pull/151) refactor yargs' table layout logic to use new helper library (@bcoe)
-- [#150](https://github.com/bcoe/yargs/pull/150) Fix README example in argument requirements (@annonymouse)
-
-### v3.7.2 (2015/04/13 11:52 -07:00)
-
-* [679fbbf](https://github.com/bcoe/yargs/commit/679fbbf55904030ccee8a2635e8e5f46551ab2f0) updated yargs to use the [standard](https://github.com/feross/standard) style guide (agokjr)
-* [22382ee](https://github.com/bcoe/yargs/commit/22382ee9f5b495bc2586c1758cd1091cec3647f9 various bug fixes for $0 (@nylen)
-
-### v3.7.1 (2015/04/10 11:06 -07:00)
-
-* [89e1992](https://github.com/bcoe/yargs/commit/89e1992a004ba73609b5f9ee6890c4060857aba4) detect iojs bin along with node bin. (@bcoe)
-* [755509e](https://github.com/bcoe/yargs/commit/755509ea90041e5f7833bba3b8c5deffe56f0aab) improvements to example documentation in README.md (@rstacruz)
-* [0d2dfc8](https://github.com/bcoe/yargs/commit/0d2dfc822a43418242908ad97ddd5291a1b35dc6) showHelp() no longer requires that .argv has been called (@bcoe)
-
-### v3.7.0 (2015/04/04 02:29 -07:00)
-
-* [56cbe2d](https://github.com/bcoe/yargs/commit/56cbe2ddd33dc176dcbf97ba40559864a9f114e4) make .requiresArg() work with type hints. (@bcoe).
-* [2f5d562](https://github.com/bcoe/yargs/commit/2f5d5624f736741deeedf6a664d57bc4d857bdd0) serialize arrays and objects in usage strings. (@bcoe).
-* [5126304](https://github.com/bcoe/yargs/commit/5126304dd18351fc28f10530616fdd9361e0af98) be more lenient about alias/primary key ordering in chaining API. (@bcoe)
-
-### v3.6.0 (2015/03/21 01:00 +00:00)
-- [4e24e22](https://github.com/bcoe/yargs/commit/4e24e22e6a195e55ab943ede704a0231ac33b99c) support for .js configuration files. (@pirxpilot)
-
-### v3.5.4 (2015/03/12 05:56 +00:00)
-- [c16cc08](https://github.com/bcoe/yargs/commit/c16cc085501155cf7fd853ccdf8584b05ab92b78) message for non-option arguments is now optional, thanks to (@raine)
-
-### v3.5.3 (2015/03/09 06:14 +00:00)
-- [870b428](https://github.com/bcoe/yargs/commit/870b428cf515d560926ca392555b7ad57dba9e3d) completion script was missing in package.json (@bcoe)
-
-### v3.5.2 (2015/03/09 06:11 +00:00)
-- [58a4b24](https://github.com/bcoe/yargs/commit/58a4b2473ebbb326713d522be53e32d3aabb08d2) parse was being called multiple times, resulting in strange behavior (@bcoe)
-
-### v3.5.1 (2015/03/09 04:55 +00:00)
-- [4e588e0](https://github.com/bcoe/yargs/commit/4e588e055afbeb9336533095f051496e3977f515) accidentally left testing logic in (@bcoe)
-
-### v3.5.0 (2015/03/09 04:49 +00:00)
-- [718bacd](https://github.com/bcoe/yargs/commit/718bacd81b9b44f786af76b2afe491fe06274f19) added support for bash completions see #4 (@bcoe)
-- [a192882](https://github.com/bcoe/yargs/commit/a19288270fc431396c42af01125eeb4443664528) downgrade to mocha 2.1.0 until https://github.com/mochajs/mocha/issues/1585 can be sorted out (@bcoe)
-
-### v3.4.7 (2015/03/09 04:09 +00:00)
-- [9845e5c](https://github.com/bcoe/yargs/commit/9845e5c1a9c684ba0be3f0bfb40e7b62ab49d9c8) the Argv singleton was not being updated when manually parsing arguments, fixes #114 (@bcoe)
-
-### v3.4.6 (2015/03/09 04:01 +00:00)
-- [45b4c80](https://github.com/bcoe/yargs/commit/45b4c80b890d02770b0a94f326695a8a566e8fe9) set placeholders for all keys fixes #115 (@bcoe)
-
-### v3.4.5 (2015/03/01 20:31 +00:00)
-- [a758e0b](https://github.com/bcoe/yargs/commit/a758e0b2556184f067cf3d9c4ef886d39817ebd2) fix for count consuming too many arguments (@bcoe)
-
-### v3.4.4 (2015/02/28 04:52 +00:00)
-- [0476af7](https://github.com/bcoe/yargs/commit/0476af757966acf980d998b45108221d4888cfcb) added nargs feature, allowing you to specify the number of arguments after an option (@bcoe)
-- [092477d](https://github.com/bcoe/yargs/commit/092477d7ab3efbf0ba11cede57f7d8cfc70b024f) updated README with full example of v3.0 API (@bcoe)
-
-### v3.3.3 (2015/02/28 04:23 +00:00)
-- [0c4b769](https://github.com/bcoe/yargs/commit/0c4b769516cd8d93a7c4e5e675628ae0049aa9a8) remove string dependency, which conflicted with other libraries see #106 (@bcoe)
-
-### v3.3.2 (2015/02/28 04:11 +00:00)
-- [2a98906](https://github.com/bcoe/yargs/commit/2a9890675821c0e7a12f146ce008b0562cb8ec9a) add $0 to epilog (@schnittstabil)
-
-### v3.3.1 (2015/02/24 03:28 +00:00)
-- [ad485ce](https://github.com/bcoe/yargs/commit/ad485ce748ebdfce25b88ef9d6e83d97a2f68987) fix for applying defaults to camel-case args (@bcoe)
-
-### v3.3.0 (2015/02/24 00:49 +00:00)
-- [8bfe36d](https://github.com/bcoe/yargs/commit/8bfe36d7fb0f93a799ea3f4c756a7467c320f8c0) fix and document restart() command, as a tool for building nested CLIs (@bcoe)
-
-### v3.2.1 (2015/02/22 05:45 +00:00)
-- [49a6d18](https://github.com/bcoe/yargs/commit/49a6d1822a4ef9b1ea6f90cc366be60912628885) you can now provide a function that generates a default value (@bcoe)
-
-### v3.2.0 (2015/02/22 05:24 +00:00)
-- [7a55886](https://github.com/bcoe/yargs/commit/7a55886c9343cf71a20744ca5cdd56d2ea7412d5) improvements to yargs two-column text layout (@bcoe)
-- [b6ab513](https://github.com/bcoe/yargs/commit/b6ab5136a4c3fa6aa496f6b6360382e403183989) Tweak NPM version badge (@nylen)
-
-### v3.1.0 (2015/02/19 19:37 +00:00)
-- [9bd2379](https://github.com/bcoe/yargs/commit/9bd237921cf1b61fd9f32c0e6d23f572fc225861) version now accepts a function, making it easy to load version #s from a package.json (@bcoe)
-
-### v3.0.4 (2015/02/14 01:40 +00:00)
-- [0b7c19b](https://github.com/bcoe/yargs/commit/0b7c19beaecb747267ca4cc10e5cb2a8550bc4b7) various fixes for dot-notation handling (@bcoe)
-
-### v3.0.3 (2015/02/14 00:59 +00:00)
-- [c3f35e9](https://github.com/bcoe/yargs/commit/c3f35e99bd5a0d278073fcadd95e2d778616cc17) make sure dot-notation is applied to aliases (@bcoe)
-
-### 3.0.2 (2015/02/13 16:50 +00:00)
-- [74c8967](https://github.com/bcoe/yargs/commit/74c8967c340c204a0a7edf8a702b6f46c2705435) document epilog shorthand of epilogue. (@bcoe)
-- [670110f](https://github.com/bcoe/yargs/commit/670110fc01bedc4831b6fec6afac54517d5a71bc) any non-truthy value now causes check to fail see #76 (@bcoe)
-- [0d8f791](https://github.com/bcoe/yargs/commit/0d8f791a33c11ced4cd431ea8d3d3a337d456b56) finished implementing my wish-list of fetures for yargs 3.0. see #88 (@bcoe)
-- [5768447](https://github.com/bcoe/yargs/commit/5768447447c4c8e8304f178846206ce86540f063) fix coverage. (@bcoe)
-- [82e793f](https://github.com/bcoe/yargs/commit/82e793f3f61c41259eaacb67f0796aea2cf2aaa0) detect console width and perform word-wrapping. (@bcoe)
-- [67476b3](https://github.com/bcoe/yargs/commit/67476b37eea07fee55f23f35b9e0c7d76682b86d) refactor two-column table layout so that we can use it for examples and usage (@bcoe)
-- [4724cdf](https://github.com/bcoe/yargs/commit/4724cdfcc8e37ae1ca3dcce9d762f476e9ef4bb4) major refactor of index.js, in prep for 3.x release. (@bcoe)
-
-### v2.3.0 (2015/02/08 20:41 +00:00)
-- [d824620](https://github.com/bcoe/yargs/commit/d824620493df4e63664af1fe320764dd1a9244e6) allow for undefined boolean defaults (@ashi009)
-
-### v2.2.0 (2015/02/08 20:07 +00:00)
-- [d6edd98](https://github.com/bcoe/yargs/commit/d6edd9848826e7389ed1393858c45d03961365fd) in-prep for further refactoring, and a 3.x release I've shuffled some things around and gotten test-coverage to 100%. (@bcoe)
-
-### v2.1.2 (2015/02/08 06:05 +00:00)
-- [d640745](https://github.com/bcoe/yargs/commit/d640745a7b9f8d476e0223879d056d18d9c265c4) switch to path.relative (@bcoe)
-- [3bfd41f](https://github.com/bcoe/yargs/commit/3bfd41ff262a041f29d828b88936a79c63cad594) remove mocha.opts. (@bcoe)
-- [47a2f35](https://github.com/bcoe/yargs/commit/47a2f357091db70903a402d6765501c1d63f15fe) document using .string('_') for string ids. see #56 (@bcoe)
-- [#57](https://github.com/bcoe/yargs/pull/57) Merge pull request #57 from eush77/option-readme (@eush77)
-
-### v2.1.1 (2015/02/06 08:08 +00:00)
-- [01c6c61](https://github.com/bcoe/yargs/commit/01c6c61d67b4ebf88f41f0b32a345ec67f0ac17d) fix for #71, 'newAliases' of undefined (@bcoe)
-
-### v2.1.0 (2015/02/06 07:59 +00:00)
-- [6a1a3fa](https://github.com/bcoe/yargs/commit/6a1a3fa731958e26ccd56885f183dd8985cc828f) try to guess argument types, and apply sensible defaults see #73 (@bcoe)
-
-### v2.0.1 (2015/02/06 07:54 +00:00)
-- [96a06b2](https://github.com/bcoe/yargs/commit/96a06b2650ff1d085a52b7328d8bba614c20cc12) Fix for strange behavior with --sort option, see #51 (@bcoe)
-
-### v2.0.0 (2015/02/06 07:45 +00:00)
-- [0250517](https://github.com/bcoe/yargs/commit/0250517c9643e53f431b824e8ccfa54937414011) - [108fb84](https://github.com/bcoe/yargs/commit/108fb8409a3a63dcaf99d917fe4dfcfaa1de236d) fixed bug with boolean parsing, when bools separated by = see #66 (@bcoe)
-- [a465a59](https://github.com/bcoe/yargs/commit/a465a5915f912715738de890982e4f8395958b10) Add `files` field to the package.json (@shinnn)
-- [31043de](https://github.com/bcoe/yargs/commit/31043de7a38a17c4c97711f1099f5fb164334db3) fix for yargs.argv having the same keys added multiple times see #63 (@bcoe)
-- [2d68c5b](https://github.com/bcoe/yargs/commit/2d68c5b91c976431001c4863ce47c9297850f1ad) Disable process.exit calls using .exitProcess(false) (@cianclarke)
-- [45da9ec](https://github.com/bcoe/yargs/commit/45da9ec4c55a7bd394721bc6a1db0dabad7bc52a) Mention .option in README (@eush77)
-
-### v1.3.2 (2014/10/06 21:56 +00:00)
-- [b8d3472](https://github.com/bcoe/yargs/commit/b8d34725482e5821a3cc809c0df71378f282f526) 1.3.2 (@chevex)
-
-### list (2014/08/30 18:41 +00:00)
-- [fbc777f](https://github.com/bcoe/yargs/commit/fbc777f416eeefd37c84e44d27d7dfc7c1925721) Now that yargs is the successor to optimist, I'm changing the README language to be more universal. Pirate speak isn't very accessible to non-native speakers. (@chevex)
-- [a54d068](https://github.com/bcoe/yargs/commit/a54d0682ae2efc2394d407ab171cc8a8bbd135ea) version output will not print extra newline (@boneskull)
-- [1cef5d6](https://github.com/bcoe/yargs/commit/1cef5d62a9d6d61a3948a49574892e01932cc6ae) Added contributors section to package.json (@chrisn)
-- [cc295c0](https://github.com/bcoe/yargs/commit/cc295c0a80a2de267e0155b60d315fc4b6f7c709) Added 'require' and 'required' as synonyms for 'demand' (@chrisn)
-- [d0bf951](https://github.com/bcoe/yargs/commit/d0bf951d949066b6280101ed606593d079ee15c8) Updating minimist. (@chevex)
-- [c15f8e7](https://github.com/bcoe/yargs/commit/c15f8e7f245b261e542cf205ce4f4313630cbdb4) Fix #31 (bad interaction between camelCase options and strict mode) (@nylen)
-- [d991b9b](https://github.com/bcoe/yargs/commit/d991b9be687a68812dee1e3b185ba64b7778b82d) Added .help() and .version() methods (@chrisn)
-- [e8c8aa4](https://github.com/bcoe/yargs/commit/e8c8aa46268379357cb11e9fc34b8c403037724b) Added .showHelpOnFail() method (@chrisn)
-- [e855af4](https://github.com/bcoe/yargs/commit/e855af4a933ea966b5bbdd3c4c6397a4bac1a053) Allow boolean flag with .demand() (@chrisn)
-- [14dbec2](https://github.com/bcoe/yargs/commit/14dbec24fb7380683198e2b20c4deb8423e64bea) Fixes issue #22. Arguments are no longer printed to the console when using .config. (@chevex)
-- [bef74fc](https://github.com/bcoe/yargs/commit/bef74fcddc1544598a804f80d0a3728459f196bf) Informing users that Yargs is the official optimist successor. (@chevex)
-- [#24](https://github.com/bcoe/yargs/pull/24) Merge pull request #24 from chrisn/strict (@chrisn)
-- [889a2b2](https://github.com/bcoe/yargs/commit/889a2b28eb9768801b05163360a470d0fd6c8b79) Added requiresArg option, for options that require values (@chrisn)
-- [eb16369](https://github.com/bcoe/yargs/commit/eb163692262be1fe80b992fd8803d5923c5a9b18) Added .strict() method, to report error if unknown arguments are given (@chrisn)
-- [0471c3f](https://github.com/bcoe/yargs/commit/0471c3fd999e1ad4e6cded88b8aa02013b66d14f) Changed optimist to yargs in usage-options.js example (@chrisn)
-- [5c88f74](https://github.com/bcoe/yargs/commit/5c88f74e3cf031b17c54b4b6606c83e485ff520e) Change optimist to yargs in examples (@chrisn)
-- [66f12c8](https://github.com/bcoe/yargs/commit/66f12c82ba3c943e4de8ca862980e835da8ecb3a) Fix a couple of bad interactions between aliases and defaults (@nylen)
-- [8fa1d80](https://github.com/bcoe/yargs/commit/8fa1d80f14b03eb1f2898863a61f1d1615bceb50) Document second argument of usage(message, opts) (@Gobie)
-- [56e6528](https://github.com/bcoe/yargs/commit/56e6528cf674ff70d63083fb044ff240f608448e) For "--some-option", also set argv.someOption (@nylen)
-- [ed5f6d3](https://github.com/bcoe/yargs/commit/ed5f6d33f57ad1086b11c91b51100f7c6c7fa8ee) Finished porting unit tests to Mocha. (@chevex)
-
-### v1.0.15 (2014/02/05 23:18 +00:00)
-- [e2b1fc0](https://github.com/bcoe/yargs/commit/e2b1fc0c4a59cf532ae9b01b275e1ef57eeb64d2) 1.0.15 update to badges (@chevex)
-
-### v1.0.14 (2014/02/05 23:17 +00:00)
-- [f33bbb0](https://github.com/bcoe/yargs/commit/f33bbb0f00fe18960f849cc8e15a7428a4cd59b8) Revert "Fixed issue which caused .demand function not to work correctly." (@chevex)
-
-### v1.0.13 (2014/02/05 22:13 +00:00)
-- [6509e5e](https://github.com/bcoe/yargs/commit/6509e5e7dee6ef1a1f60eea104be0faa1a045075) Fixed issue which caused .demand function not to work correctly. (@chevex)
-
-### v1.0.12 (2013/12/13 00:09 +00:00)
-- [05eb267](https://github.com/bcoe/yargs/commit/05eb26741c9ce446b33ff006e5d33221f53eaceb) 1.0.12 (@chevex)
-
-### v1.0.11 (2013/12/13 00:07 +00:00)
-- [c1bde46](https://github.com/bcoe/yargs/commit/c1bde46e37318a68b87d17a50c130c861d6ce4a9) 1.0.11 (@chevex)
-
-### v1.0.10 (2013/12/12 23:57 +00:00)
-- [dfebf81](https://github.com/bcoe/yargs/commit/dfebf8164c25c650701528ee581ca483a99dc21c) Fixed formatting in README (@chevex)
-
-### v1.0.9 (2013/12/12 23:47 +00:00)
-- [0b4e34a](https://github.com/bcoe/yargs/commit/0b4e34af5e6d84a9dbb3bb6d02cd87588031c182) Update README.md (@chevex)
-
-### v1.0.8 (2013/12/06 16:36 +00:00)
-- [#1](https://github.com/bcoe/yargs/pull/1) fix error caused by check() see #1 (@martinheidegger)
-
-### v1.0.7 (2013/11/24 18:01 +00:00)
-- [a247d88](https://github.com/bcoe/yargs/commit/a247d88d6e46644cbb7303c18b1bb678fc132d72) Modified Pirate Joe image. (@chevex)
-
-### v1.0.6 (2013/11/23 19:21 +00:00)
-- [d7f69e1](https://github.com/bcoe/yargs/commit/d7f69e1d34bc929736a8bdccdc724583e21b7eab) Updated Pirate Joe image. (@chevex)
-
-### v1.0.5 (2013/11/23 19:09 +00:00)
-- [ece809c](https://github.com/bcoe/yargs/commit/ece809cf317cc659175e1d66d87f3ca68c2760be) Updated readme notice again. (@chevex)
-
-### v1.0.4 (2013/11/23 19:05 +00:00)
-- [9e81e81](https://github.com/bcoe/yargs/commit/9e81e81654028f83ba86ffc3ac772a0476084e5e) Updated README with a notice about yargs being a fork of optimist and what that implies. (@chevex)
-
-### v1.0.3 (2013/11/23 17:43 +00:00)
-- [65e7a78](https://github.com/bcoe/yargs/commit/65e7a782c86764944d63d084416aba9ee6019c5f) Changed some small wording in README.md. (@chevex)
-- [459e20e](https://github.com/bcoe/yargs/commit/459e20e539b366b85128dd281ccd42221e96c7da) Fix a bug in the options function, when string and boolean options weren't applied to aliases. (@shockone)
-
-### v1.0.2 (2013/11/23 09:46 +00:00)
-- [3d80ebe](https://github.com/bcoe/yargs/commit/3d80ebed866d3799224b6f7d596247186a3898a9) 1.0.2 (@chevex)
-
-### v1.0.1 (2013/11/23 09:39 +00:00)
-- [f80ff36](https://github.com/bcoe/yargs/commit/f80ff3642d580d4b68bf9f5a94277481bd027142) Updated image. (@chevex)
-
-### v1.0.0 (2013/11/23 09:33 +00:00)
-- [54e31d5](https://github.com/bcoe/yargs/commit/54e31d505f820b80af13644e460894b320bf25a3) Rebranded from optimist to yargs in the spirit of the fork :D (@chevex)
-- [4ebb6c5](https://github.com/bcoe/yargs/commit/4ebb6c59f44787db7c24c5b8fe2680f01a23f498) Added documentation for demandCount(). (@chevex)
-- [4561ce6](https://github.com/bcoe/yargs/commit/4561ce66dcffa95f49e8b4449b25b94cd68acb25) Simplified the error messages returned by .check(). (@chevex)
-- [661c678](https://github.com/bcoe/yargs/commit/661c67886f479b16254a830b7e1db3be29e6b7a6) Fixed an issue with demand not accepting a zero value. (@chevex)
-- [731dd3c](https://github.com/bcoe/yargs/commit/731dd3c37624790490bd6df4d5f1da8f4348279e) Add .fail(fn) so death isn't the only option. Should fix issue #39. (@chevex)
-- [fa15417](https://github.com/bcoe/yargs/commit/fa15417ff9e70dace0d726627a5818654824c1d8) Added a few missing 'return self' (@chevex)
-- [e655e4d](https://github.com/bcoe/yargs/commit/e655e4d99d1ae1d3695ef755d51c2de08d669761) Fix showing help in certain JS environments. (@chevex)
-- [a746a31](https://github.com/bcoe/yargs/commit/a746a31cd47c87327028e6ea33762d6187ec5c87) Better string representation of default values. (@chevex)
-- [6134619](https://github.com/bcoe/yargs/commit/6134619a7e90b911d5443230b644c5d447c1a68c) Implies: conditional demands (@chevex)
-- [046b93b](https://github.com/bcoe/yargs/commit/046b93b5d40a27367af4cb29726e4d781d934639) Added support for JSON config files. (@chevex)
-- [a677ec0](https://github.com/bcoe/yargs/commit/a677ec0a0ecccd99c75e571d03323f950688da03) Add .example(cmd, desc) feature. (@chevex)
-- [1bd4375](https://github.com/bcoe/yargs/commit/1bd4375e11327ba1687d4bb6e5e9f3c30c1be2af) Added 'defaults' as alias to 'default' so as to avoid usage of a reserved keyword. (@chevex)
-- [6b753c1](https://github.com/bcoe/yargs/commit/6b753c16ca09e723060e70b773b430323b29c45c) add .normalize(args..) support for normalizing paths (@chevex)
-- [33d7d59](https://github.com/bcoe/yargs/commit/33d7d59341d364f03d3a25f0a55cb99004dbbe4b) Customize error messages with demand(key, msg) (@chevex)
-- [647d37f](https://github.com/bcoe/yargs/commit/647d37f164c20f4bafbf67dd9db6cd6e2cd3b49f) Merge branch 'rewrite-duplicate-test' of github.com:isbadawi/node-optimist (@chevex)
-- [9059d1a](https://github.com/bcoe/yargs/commit/9059d1ad5e8aea686c2a01c89a23efdf929fff2e) Pass aliases object to check functions for greater versatility. (@chevex)
-- [623dc26](https://github.com/bcoe/yargs/commit/623dc26c7331abff2465ef8532e3418996d42fe6) Added ability to count boolean options and rolled minimist library back into project. (@chevex)
-- [49f0dce](https://github.com/bcoe/yargs/commit/49f0dcef35de4db544c3966350d36eb5838703f6) Fixed small typo. (@chevex)
-- [79ec980](https://github.com/bcoe/yargs/commit/79ec9806d9ca6eb0014cfa4b6d1849f4f004baf2) Removed dependency on wordwrap module. (@chevex)
-- [ea14630](https://github.com/bcoe/yargs/commit/ea14630feddd69d1de99dd8c0e08948f4c91f00a) Merge branch 'master' of github.com:chbrown/node-optimist (@chevex)
-- [2b75da2](https://github.com/bcoe/yargs/commit/2b75da2624061e0f4f3107d20303c06ec9054906) Merge branch 'master' of github.com:seanzhou1023/node-optimist (@chevex)
-- [d9bda11](https://github.com/bcoe/yargs/commit/d9bda1116e26f3b40e833ca9ca19263afea53565) Merge branch 'patch-1' of github.com:thefourtheye/node-optimist (@chevex)
-- [d6cc606](https://github.com/bcoe/yargs/commit/d6cc6064a4f1bea38a16a4430b8a1334832fbeff) Renamed README. (@chevex)
-- [9498d3f](https://github.com/bcoe/yargs/commit/9498d3f59acfb5e102826503e681623c3a64b178) Renamed readme and added .gitignore. (@chevex)
-- [bbd1fe3](https://github.com/bcoe/yargs/commit/bbd1fe37fefa366dde0fb3dc44d91fe8b28f57f5) Included examples for ```help``` and ```showHelp``` functions and fixed few formatting issues (@thefourtheye)
-- [37fea04](https://github.com/bcoe/yargs/commit/37fea0470a5796a0294c1dcfff68d8041650e622) .alias({}) behaves differently based on mapping direction when generating descriptions (@chbrown)
-- [855b20d](https://github.com/bcoe/yargs/commit/855b20d0be567ca121d06b30bea64001b74f3d6d) Documented function signatures are useful for dynamically typed languages. (@chbrown)
-
-### 0.6.0 (2013/06/25 08:48 +00:00)
-- [d37bfe0](https://github.com/bcoe/yargs/commit/d37bfe05ae6d295a0ab481efe4881222412791f4) all tests passing using minimist (@substack)
-- [76f1352](https://github.com/bcoe/yargs/commit/76f135270399d01f2bbc621e524a5966e5c422fd) all parse tests now passing (@substack)
-- [a7b6754](https://github.com/bcoe/yargs/commit/a7b6754276c38d1565479a5685c3781aeb947816) using minimist, some tests passing (@substack)
-- [6655688](https://github.com/bcoe/yargs/commit/66556882aa731cbbbe16cc4d42c85740a2e98099) Give credit where its due (@DeadAlready)
-- [602a2a9](https://github.com/bcoe/yargs/commit/602a2a92a459f93704794ad51b115bbb08b535ce) v0.5.3 - Remove wordwrap as dependency (@DeadAlready)
-
-### 0.5.2 (2013/05/31 03:46 +00:00)
-- [4497ca5](https://github.com/bcoe/yargs/commit/4497ca55e332760a37b866ec119ded347ca27a87) fixed the whitespace bug without breaking anything else (@substack)
-- [5a3dd1a](https://github.com/bcoe/yargs/commit/5a3dd1a4e0211a38613c6e02f61328e1031953fa) failing test for whitespace arg (@substack)
-
-### 0.5.1 (2013/05/30 07:17 +00:00)
-- [a20228f](https://github.com/bcoe/yargs/commit/a20228f62a454755dd07f628a7c5759113918327) fix parse() to work with functions before it (@substack)
-- [b13bd4c](https://github.com/bcoe/yargs/commit/b13bd4cac856a9821d42fa173bdb58f089365a7d) failing test for parse() with modifiers (@substack)
-
-### 0.5.0 (2013/05/18 21:59 +00:00)
-- [c474a64](https://github.com/bcoe/yargs/commit/c474a649231527915c222156e3b40806d365a87c) fixes for dash (@substack)
-
-### 0.4.0 (2013/04/13 19:03 +00:00)
-- [dafe3e1](https://github.com/bcoe/yargs/commit/dafe3e18d7c6e7c2d68e06559df0e5cbea3adb14) failing short test (@substack)
-
-### 0.3.7 (2013/04/04 04:07 +00:00)
-- [6c7a0ec](https://github.com/bcoe/yargs/commit/6c7a0ec94ce4199a505f0518b4d6635d4e47cc81) Fix for windows. On windows there is no _ in environment. (@hdf)
-
-### 0.3.6 (2013/04/04 04:04 +00:00)
-- [e72346a](https://github.com/bcoe/yargs/commit/e72346a727b7267af5aa008b418db89970873f05) Add support for newlines in -a="" arguments (@danielbeardsley)
-- [71e1fb5](https://github.com/bcoe/yargs/commit/71e1fb55ea9987110a669ac6ec12338cfff3821c) drop 0.4, add 0.8 to travis (@substack)
-
-### 0.3.5 (2012/10/10 11:09 +00:00)
-- [ee692b3](https://github.com/bcoe/yargs/commit/ee692b37554c70a0bb16389a50a26b66745cbbea) Fix parsing booleans (@vojtajina)
-- [5045122](https://github.com/bcoe/yargs/commit/5045122664c3f5b4805addf1be2148d5856f7ce8) set $0 properly in the tests (@substack)
-
-### 0.3.4 (2012/04/30 06:54 +00:00)
-- [f28c0e6](https://github.com/bcoe/yargs/commit/f28c0e62ca94f6e0bb2e6d82fc3d91a55e69b903) bump for string "true" params (@substack)
-- [8f44aeb](https://github.com/bcoe/yargs/commit/8f44aeb74121ddd689580e2bf74ef86a605e9bf2) Fix failing test for aliased booleans. (@coderarity)
-- [b9f7b61](https://github.com/bcoe/yargs/commit/b9f7b613b1e68e11e6c23fbda9e555a517dcc976) Add failing test for short aliased booleans. (@coderarity)
-
-### 0.3.3 (2012/04/30 06:45 +00:00)
-- [541bac8](https://github.com/bcoe/yargs/commit/541bac8dd787a5f1a5d28f6d8deb1627871705e7) Fixes #37.
-
-### 0.3.2 (2012/04/12 20:28 +00:00)
-- [3a0f014](https://github.com/bcoe/yargs/commit/3a0f014c1451280ac1c9caa1f639d31675586eec) travis badge (@substack)
-- [4fb60bf](https://github.com/bcoe/yargs/commit/4fb60bf17845f4ce3293f8ca49c9a1a7c736cfce) Fix boolean aliases. (@coderarity)
-- [f14dda5](https://github.com/bcoe/yargs/commit/f14dda546efc4fe06ace04d36919bfbb7634f79b) Adjusted package.json to use tap (@jfhbrook)
-- [88e5d32](https://github.com/bcoe/yargs/commit/88e5d32295be6e544c8d355ff84e355af38a1c74) test/usage.js no longer hangs (@jfhbrook)
-- [e1e740c](https://github.com/bcoe/yargs/commit/e1e740c27082f3ce84deca2093d9db2ef735d0e5) two tests for combined boolean/alias opts parsing (@jfhbrook)
-
-### 0.3.1 (2011/12/31 08:44 +00:00)
-- [d09b719](https://github.com/bcoe/yargs/commit/d09b71980ef711b6cf3918cd19beec8257e40e82) If "default" is set to false it was not passed on, fixed. (@wolframkriesing)
-
-### 0.3.0 (2011/12/09 06:03 +00:00)
-- [6e74aa7](https://github.com/bcoe/yargs/commit/6e74aa7b46a65773e20c0cb68d2d336d4a0d553d) bump and documented dot notation (@substack)
-
-### 0.2.7 (2011/10/20 02:25 +00:00)
-- [94adee2](https://github.com/bcoe/yargs/commit/94adee20e17b58d0836f80e8b9cdbe9813800916) argv._ can be told 'Hey! argv._! Don't be messing with my args.', and it WILL obey (@colinta)
-- [c46fdd5](https://github.com/bcoe/yargs/commit/c46fdd56a05410ae4a1e724a4820c82e77ff5469) optimistic critter image (@substack)
-- [5c95c73](https://github.com/bcoe/yargs/commit/5c95c73aedf4c7482bd423e10c545e86d7c8a125) alias options() to option() (@substack)
-- [f7692ea](https://github.com/bcoe/yargs/commit/f7692ea8da342850af819367833abb685fde41d8) [fix] Fix for parsing boolean edge case (@indexzero)
-- [d1f92d1](https://github.com/bcoe/yargs/commit/d1f92d1425bd7f356055e78621b30cdf9741a3c2)
-- [b01bda8](https://github.com/bcoe/yargs/commit/b01bda8d86e455bbf74ce497864cb8ab5b9fb847) [fix test] Update to ensure optimist is aware of default booleans. Associated tests included (@indexzero)
-- [aa753e7](https://github.com/bcoe/yargs/commit/aa753e7c54fb3a12f513769a0ff6d54aa0f63943) [dist test] Update devDependencies in package.json. Update test pathing to be more npm and require.paths future-proof (@indexzero)
-- [7bfce2f](https://github.com/bcoe/yargs/commit/7bfce2f3b3c98e6539e7549d35fbabced7e9341e) s/sys/util/ (@substack)
-- [d420a7a](https://github.com/bcoe/yargs/commit/d420a7a9c890d2cdb11acfaf3ea3f43bc3e39f41) update usage output (@substack)
-- [cf86eed](https://github.com/bcoe/yargs/commit/cf86eede2e5fc7495b6ec15e6d137d9ac814f075) some sage readme protips about parsing rules (@substack)
-- [5da9f7a](https://github.com/bcoe/yargs/commit/5da9f7a5c0e1758ec7c5801fb3e94d3f6e970513) documented all the methods finally (@substack)
-- [8ca6879](https://github.com/bcoe/yargs/commit/8ca6879311224b25933642987300f6a29de5c21b) fenced syntax highlighting (@substack)
-- [b72bacf](https://github.com/bcoe/yargs/commit/b72bacf1d02594778c1935405bc8137eb61761dc) right-alignment of wrapped extra params (@substack)
-- [2b980bf](https://github.com/bcoe/yargs/commit/2b980bf2656b4ee8fc5134dc5f56a48855c35198) now with .wrap() (@substack)
-- [d614f63](https://github.com/bcoe/yargs/commit/d614f639654057d1b7e35e3f5a306e88ec2ad1e4) don't show 'Options:' when there aren't any (@substack)
-- [691eda3](https://github.com/bcoe/yargs/commit/691eda354df97b5a86168317abcbcaabdc08a0fb) failing test for multi-aliasing (@substack)
-- [0826c9f](https://github.com/bcoe/yargs/commit/0826c9f462109feab2bc7a99346d22e72bf774b7) "Options:" > "options:" (@substack)
-- [72f7490](https://github.com/bcoe/yargs/commit/72f749025d01b7f295738ed370a669d885fbada0) [minor] Update formatting for `.showHelp()` (@indexzero)
-- [75aecce](https://github.com/bcoe/yargs/commit/75aeccea74329094072f95800e02c275e7d999aa) options works again, too lazy to write a proper test right now (@substack)
-- [f742e54](https://github.com/bcoe/yargs/commit/f742e5439817c662dc3bd8734ddd6467e6018cfd) line_count_options example, which breaks (@substack)
-- [4ca06b8](https://github.com/bcoe/yargs/commit/4ca06b8b4ea99b5d5714b315a2a8576bee6e5537) line count example (@substack)
-- [eeb8423](https://github.com/bcoe/yargs/commit/eeb8423e0a5ecc9dc3eb1e6df9f3f8c1c88f920b) remove self.argv setting in boolean (@substack)
-- [6903412](https://github.com/bcoe/yargs/commit/69034126804660af9cc20ea7f4457b50338ee3d7) removed camel case for now (@substack)
-- [5a0d88b](https://github.com/bcoe/yargs/commit/5a0d88bf23e9fa79635dd034e2a1aa992acc83cd) remove dead longest checking code (@substack)
-- [d782170](https://github.com/bcoe/yargs/commit/d782170babf7284b1aa34f5350df0dd49c373fa8) .help() too (@substack)
-- [622ec17](https://github.com/bcoe/yargs/commit/622ec17379bb5374fdbb190404c82bc600975791) rm old help generator (@substack)
-- [7c8baac](https://github.com/bcoe/yargs/commit/7c8baac4d66195e9f5158503ea9ebfb61153dab7) nub keys (@substack)
-- [8197785](https://github.com/bcoe/yargs/commit/8197785ad4762465084485b041abd722f69bf344) generate help message based on the previous calls, todo: nub (@substack)
-- [3ffbdc3](https://github.com/bcoe/yargs/commit/3ffbdc33c8f5e83d4ea2ac60575ce119570c7ede) stub out new showHelp, better checks (@substack)
-- [d4e21f5](https://github.com/bcoe/yargs/commit/d4e21f56a4830f7de841900d3c79756fb9886184) let .options() take single options too (@substack)
-- [3c4cf29](https://github.com/bcoe/yargs/commit/3c4cf2901a29bac119cca8e983028d8669230ec6) .options() is now heaps simpler (@substack)
-- [89f0d04](https://github.com/bcoe/yargs/commit/89f0d043cbccd302f10ab30c2069e05d2bf817c9) defaults work again, all tests pass (@substack)
-- [dd87333](https://github.com/bcoe/yargs/commit/dd8733365423006a6e4156372ebb55f98323af58) update test error messages, down to 2 failing tests (@substack)
-- [53f7bc6](https://github.com/bcoe/yargs/commit/53f7bc626b9875f2abdfc5dd7a80bde7f14143a3) fix for bools doubling up, passes the parse test again, others fail (@substack)
-- [2213e2d](https://github.com/bcoe/yargs/commit/2213e2ddc7263226fba717fb041dc3fde9bc2ee4) refactored for an argv getter, failing several tests (@substack)
-- [d1e7379](https://github.com/bcoe/yargs/commit/d1e737970f15c6c006bebdd8917706827ff2f0f2) just rescan for now, alias test passes (@substack)
-- [b2f8c99](https://github.com/bcoe/yargs/commit/b2f8c99cc477a8eb0fdf4cf178e1785b63185cfd) failing alias test (@substack)
-- [d0c0174](https://github.com/bcoe/yargs/commit/d0c0174daa144bfb6dc7290fdc448c393c475e15) .alias() (@substack)
-- [d85f431](https://github.com/bcoe/yargs/commit/d85f431ad7d07b058af3f2a57daa51495576c164) [api] Remove `.describe()` in favor of building upon the existing `.usage()` API (@indexzero)
-- [edbd527](https://github.com/bcoe/yargs/commit/edbd5272a8e213e71acd802782135c7f9699913a) [doc api] Add `.describe()`, `.options()`, and `.showHelp()` methods along with example. (@indexzero)
-- [be4902f](https://github.com/bcoe/yargs/commit/be4902ff0961ae8feb9093f2c0a4066463ded2cf) updates for coffee since it now does argv the node way (@substack)
-- [e24cb23](https://github.com/bcoe/yargs/commit/e24cb23798ee64e53b60815e7fda78b87f42390c) more general coffeescript detection (@substack)
-- [78ac753](https://github.com/bcoe/yargs/commit/78ac753e5d0ec32a96d39d893272afe989e42a4d) Don't trigger the CoffeeScript hack when running under node_g. (@papandreou)
-- [bcfe973](https://github.com/bcoe/yargs/commit/bcfe9731d7f90d4632281b8a52e8d76eb0195ae6) .string() but failing test (@substack)
-- [1987aca](https://github.com/bcoe/yargs/commit/1987aca28c7ba4e8796c07bbc547cb984804c826) test hex strings (@substack)
-- [ef36db3](https://github.com/bcoe/yargs/commit/ef36db32259b0b0d62448dc907c760e5554fb7e7) more keywords (@substack)
-- [cc53c56](https://github.com/bcoe/yargs/commit/cc53c56329960bed6ab077a79798e991711ba01d) Added camelCase function that converts --multi-word-option to camel case (so it becomes argv.multiWordOption). (@papandreou)
-- [60b57da](https://github.com/bcoe/yargs/commit/60b57da36797716e5783a633c6d5c79099016d45) fixed boolean bug by rescanning (@substack)
-- [dff6d07](https://github.com/bcoe/yargs/commit/dff6d078d97f8ac503c7d18dcc7b7a8c364c2883) boolean examples (@substack)
-- [0e380b9](https://github.com/bcoe/yargs/commit/0e380b92c4ef4e3c8dac1da18b5c31d85b1d02c9) boolean() with passing test (@substack)
-- [62644d4](https://github.com/bcoe/yargs/commit/62644d4bffbb8d1bbf0c2baf58a1d14a6359ef07) coffee compatibility with node regex for versions too (@substack)
-- [430fafc](https://github.com/bcoe/yargs/commit/430fafcf1683d23774772826581acff84b456827) argv._ fixed by fixing the coffee detection (@substack)
-- [343b8af](https://github.com/bcoe/yargs/commit/343b8afefd98af274ebe21b5a16b3a949ec5429f) whichNodeArgs test fails too (@substack)
-- [63df2f3](https://github.com/bcoe/yargs/commit/63df2f371f31e63d7f1dec2cbf0022a5f08da9d2) replicated mnot's bug in whichNodeEmpty test (@substack)
-- [35473a4](https://github.com/bcoe/yargs/commit/35473a4d93a45e5e7e512af8bb54ebb532997ae1) test for ./bin usage (@substack)
-- [13df151](https://github.com/bcoe/yargs/commit/13df151e44228eed10e5441c7cd163e086c458a4) don't coerce booleans to numbers (@substack)
-- [85f8007](https://github.com/bcoe/yargs/commit/85f8007e93b8be7124feea64b1f1916d8ba1894a) package bump for automatic number conversion (@substack)
-- [8f17014](https://github.com/bcoe/yargs/commit/8f170141cded4ccc0c6d67a849c5bf996aa29643) updated readme and examples with new auto-numberification goodness (@substack)
-- [73dc901](https://github.com/bcoe/yargs/commit/73dc9011ac968e39b55e19e916084a839391b506) auto number conversion works yay (@substack)
-- [bcec56b](https://github.com/bcoe/yargs/commit/bcec56b3d031e018064cbb691539ccc4f28c14ad) failing test for not-implemented auto numification (@substack)
-- [ebd2844](https://github.com/bcoe/yargs/commit/ebd2844d683feeac583df79af0e5124a7a7db04e) odd that eql doesn't check types careflly (@substack)
-- [fd854b0](https://github.com/bcoe/yargs/commit/fd854b02e512ce854b76386d395672a7969c1bc4) package author + keywords (@substack)
-- [656a1d5](https://github.com/bcoe/yargs/commit/656a1d5a1b7c0e49d72e80cb13f20671d56f76c6) updated readme with .default() stuff (@substack)
-- [cd7f8c5](https://github.com/bcoe/yargs/commit/cd7f8c55f0b82b79b690d14c5f806851236998a1) passing tests for new .default() behavior (@substack)
-- [932725e](https://github.com/bcoe/yargs/commit/932725e39ce65bc91a0385a5fab659a5fa976ac2) new default() thing for setting default key/values (@substack)
-- [4e6c7ab](https://github.com/bcoe/yargs/commit/4e6c7aba6374ac9ebc6259ecf91f13af7bce40e3) test for coffee usage (@substack)
-- [d54ffcc](https://github.com/bcoe/yargs/commit/d54ffccf2a5a905f51ed5108f7c647f35d64ae23) new --key value style with passing tests. NOTE: changes existing behavior (@substack)
-- [ed2a2d5](https://github.com/bcoe/yargs/commit/ed2a2d5d828100ebeef6385c0fb88d146a5cfe9b) package bump for summatix's coffee script fix (@substack)
-- [75a975e](https://github.com/bcoe/yargs/commit/75a975eed8430d28e2a79dc9e6d819ad545f4587) Added support for CoffeeScript (@summatix)
-- [56b2b1d](https://github.com/bcoe/yargs/commit/56b2b1de8d11f8a2b91979d8ae2d6db02d8fe64d) test coverage for the falsy check() usage (@substack)
-- [a4843a9](https://github.com/bcoe/yargs/commit/a4843a9f0e69ffb4afdf6a671d89eb6f218be35d) check bug fixed plus a handy string (@substack)
-- [857bd2d](https://github.com/bcoe/yargs/commit/857bd2db933a5aaa9cfecba0ced2dc9b415f8111) tests for demandCount, back up to 100% coverage (@substack)
-- [073b776](https://github.com/bcoe/yargs/commit/073b7768ebd781668ef05c13f9003aceca2f5c35) call demandCount from demand (@substack)
-- [4bd4b7a](https://github.com/bcoe/yargs/commit/4bd4b7a085c8b6ce1d885a0f486cc9865cee2db1) add demandCount to check for the number of arguments in the _ list (@marshall)
-- [b8689ac](https://github.com/bcoe/yargs/commit/b8689ac68dacf248119d242bba39a41cb0adfa07) Rebase checks. That will be its own module eventually. (@substack)
-- [e688370](https://github.com/bcoe/yargs/commit/e688370b576f0aa733c3f46183df69e1b561668e) a $0 like in perl (@substack)
-- [2e5e196](https://github.com/bcoe/yargs/commit/2e5e1960fc19afb21fb3293752316eaa8bcd3609) usage test hacking around process and console (@substack)
-- [fcc3521](https://github.com/bcoe/yargs/commit/fcc352163fbec6a1dfe8caf47a0df39de24fe016) description pun (@substack)
-- [87a1fe2](https://github.com/bcoe/yargs/commit/87a1fe29037ca2ca5fefda85141aaeb13e8ce761) mit/x11 license (@substack)
-- [8d089d2](https://github.com/bcoe/yargs/commit/8d089d24cd687c0bde3640a96c09b78f884900dd) bool example is more consistent and also shows off short option grouping (@substack)
-- [448d747](https://github.com/bcoe/yargs/commit/448d7473ac68e8e03d8befc9457b0d9e21725be0) start of the readme and examples (@substack)
-- [da74dea](https://github.com/bcoe/yargs/commit/da74dea799a9b59dbf022cbb8001bfdb0d52eec9) more tests for long and short captures (@substack)
-- [ab6387e](https://github.com/bcoe/yargs/commit/ab6387e6769ca4af82ca94c4c67c7319f0d9fcfa) silly bug in the tests with s/not/no/, all tests pass now (@substack)
-- [102496a](https://github.com/bcoe/yargs/commit/102496a319e8e06f6550d828fc2f72992c7d9ecc) hack an instance for process.argv onto Argv so the export can be called to create an instance or used for argv, which is the most common case (@substack)
-- [a01caeb](https://github.com/bcoe/yargs/commit/a01caeb532546d19f68f2b2b87f7036cfe1aaedd) divide example (@substack)
-- [443da55](https://github.com/bcoe/yargs/commit/443da55736acbaf8ff8b04d1b9ce19ab016ddda2) start of the lib with a package.json (@substack)
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/LICENSE
+++ /dev/null
@@ -1,22 +0,0 @@
-Copyright 2010 James Halliday (mail@substack.net)
-Modified work Copyright 2014 Contributors (ben@npmjs.com)
-
-This project is free software released under the MIT/X11 license:
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/README.md
+++ /dev/null
@@ -1,119 +0,0 @@
-<p align="center">
-  <img width="250" src="/yargs-logo.png">
-</p>
-<h1 align="center"> Yargs </h1>
-<p align="center">
-  <b >Yargs be a node.js library fer hearties tryin' ter parse optstrings</b>
-</p>
-<br>
-
-[![Build Status][travis-image]][travis-url]
-[![Coverage Status][coveralls-image]][coveralls-url]
-[![NPM version][npm-image]][npm-url]
-[![Windows Tests][windows-image]][windows-url]
-[![js-standard-style][standard-image]][standard-url]
-[![Conventional Commits][conventional-commits-image]][conventional-commits-url]
-[![Slack][slack-image]][slack-url]
-
-## Description :
-Yargs helps you build interactive command line tools, by parsing arguments and generating an elegant user interface. 
-
-It gives you:
-
-* commands and (grouped) options (`my-program.js serve --port=5000`).
-* a dynamically generated help menu based on your arguments.
-
-> <img width="400" src="/screen.png">
-
-* bash-completion shortcuts for commands and options.
-* and [tons more](/docs/api.md).
-
-## Installation
-
-```bash
-npm i yargs --save
-```
-
-## Usage :
-
-### Simple Example
-
-````javascript
-#!/usr/bin/env node
-const argv = require('yargs').argv
-
-if (argv.ships > 3 && argv.distance < 53.5) {
-  console.log('Plunder more riffiwobbles!')
-} else {
-  console.log('Retreat from the xupptumblers!')
-}
-````
-
-```bash
-$ ./plunder.js --ships=4 --distance=22
-Plunder more riffiwobbles!
-
-$ ./plunder.js --ships 12 --distance 98.7
-Retreat from the xupptumblers!
-```
-
-### Complex Example
-
-```javascript
-#!/usr/bin/env node
-require('yargs') // eslint-disable-line
-  .command('serve [port]', 'start the server', (yargs) => {
-    yargs
-      .positional('port', {
-        describe: 'port to bind on',
-        default: 5000
-      })
-  }, (argv) => {
-    if (argv.verbose) console.info(`start server on :${argv.port}`)
-    serve(argv.port)
-  })
-  .option('verbose', {
-    alias: 'v',
-    default: false
-  })
-  .argv
-```
-
-Run the example above with `--help` to see the help for the application.
-
-## Community :
-
-Having problems? want to contribute? join our [community slack](http://devtoolscommunity.herokuapp.com).
-
-## Documentation :
-
-### Table of Contents
-
-* [Yargs' API](/docs/api.md)
-* [Examples](/docs/examples.md)
-* [Parsing Tricks](/docs/tricks.md)
-  * [Stop the Parser](/docs/tricks.md#stop)
-  * [Negating Boolean Arguments](/docs/tricks.md#negate)
-  * [Numbers](/docs/tricks.md#numbers)
-  * [Arrays](/docs/tricks.md#arrays)
-  * [Objects](/docs/tricks.md#objects)
-* [Advanced Topics](/docs/advanced.md)
-  * [Composing Your App Using Commands](/docs/advanced.md#commands)
-  * [Building Configurable CLI Apps](/docs/advanced.md#configuration)
-  * [Customizing Yargs' Parser](/docs/advanced.md#customizing)
-* [Contributing](/contributing.md)
-
-[travis-url]: https://travis-ci.org/yargs/yargs
-[travis-image]: https://img.shields.io/travis/yargs/yargs/master.svg
-[coveralls-url]: https://coveralls.io/github/yargs/yargs
-[coveralls-image]: https://img.shields.io/coveralls/yargs/yargs.svg
-[npm-url]: https://www.npmjs.com/package/yargs
-[npm-image]: https://img.shields.io/npm/v/yargs.svg
-[windows-url]: https://ci.appveyor.com/project/bcoe/yargs-ljwvf
-[windows-image]: https://img.shields.io/appveyor/ci/bcoe/yargs-ljwvf/master.svg?label=Windows%20Tests
-[standard-image]: https://img.shields.io/badge/code%20style-standard-brightgreen.svg
-[standard-url]: http://standardjs.com/
-[conventional-commits-image]: https://img.shields.io/badge/Conventional%20Commits-1.0.0-yellow.svg
-[conventional-commits-url]: https://conventionalcommits.org/
-[slack-image]: http://devtoolscommunity.herokuapp.com/badge.svg
-[slack-url]: http://devtoolscommunity.herokuapp.com
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/completion.sh.hbs
+++ /dev/null
@@ -1,28 +0,0 @@
-###-begin-{{app_name}}-completions-###
-#
-# yargs command completion script
-#
-# Installation: {{app_path}} {{completion_command}} >> ~/.bashrc
-#    or {{app_path}} {{completion_command}} >> ~/.bash_profile on OSX.
-#
-_yargs_completions()
-{
-    local cur_word args type_list
-
-    cur_word="${COMP_WORDS[COMP_CWORD]}"
-    args=("${COMP_WORDS[@]}")
-
-    # ask yargs to generate completions.
-    type_list=$({{app_path}} --get-yargs-completions "${args[@]}")
-
-    COMPREPLY=( $(compgen -W "${type_list}" -- ${cur_word}) )
-
-    # if no match was found, fall back to filename completion
-    if [ ${#COMPREPLY[@]} -eq 0 ]; then
-      COMPREPLY=( $(compgen -f -- "${cur_word}" ) )
-    fi
-
-    return 0
-}
-complete -F _yargs_completions {{app_name}}
-###-end-{{app_name}}-completions-###
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/index.js
+++ /dev/null
@@ -1,32 +0,0 @@
-'use strict'
-// classic singleton yargs API, to use yargs
-// without running as a singleton do:
-// require('yargs/yargs')(process.argv.slice(2))
-const yargs = require('./yargs')
-
-Argv(process.argv.slice(2))
-
-module.exports = Argv
-
-function Argv (processArgs, cwd) {
-  const argv = yargs(processArgs, cwd, require)
-  singletonify(argv)
-  return argv
-}
-
-/*  Hack an instance of Argv with process.argv into Argv
-    so people can do
-    require('yargs')(['--beeble=1','-z','zizzle']).argv
-    to parse a list of args and
-    require('yargs').argv
-    to get a parsed version of process.argv.
-*/
-function singletonify (inst) {
-  Object.keys(inst).forEach((key) => {
-    if (key === 'argv') {
-      Argv.__defineGetter__(key, inst.__lookupGetter__(key))
-    } else {
-      Argv[key] = typeof inst[key] === 'function' ? inst[key].bind(inst) : inst[key]
-    }
-  })
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/apply-extends.js
+++ /dev/null
@@ -1,53 +0,0 @@
-
-'use strict'
-const fs = require('fs')
-const path = require('path')
-const YError = require('./yerror')
-
-let previouslyVisitedConfigs = []
-
-function checkForCircularExtends (cfgPath) {
-  if (previouslyVisitedConfigs.indexOf(cfgPath) > -1) {
-    throw new YError(`Circular extended configurations: '${cfgPath}'.`)
-  }
-}
-
-function getPathToDefaultConfig (cwd, pathToExtend) {
-  return path.resolve(cwd, pathToExtend)
-}
-
-function applyExtends (config, cwd) {
-  let defaultConfig = {}
-
-  if (config.hasOwnProperty('extends')) {
-    if (typeof config.extends !== 'string') return defaultConfig
-    const isPath = /\.json|\..*rc$/.test(config.extends)
-    let pathToDefault = null
-    if (!isPath) {
-      try {
-        pathToDefault = require.resolve(config.extends)
-      } catch (err) {
-        // most likely this simply isn't a module.
-      }
-    } else {
-      pathToDefault = getPathToDefaultConfig(cwd, config.extends)
-    }
-    // maybe the module uses key for some other reason,
-    // err on side of caution.
-    if (!pathToDefault && !isPath) return config
-
-    checkForCircularExtends(pathToDefault)
-
-    previouslyVisitedConfigs.push(pathToDefault)
-
-    defaultConfig = isPath ? JSON.parse(fs.readFileSync(pathToDefault, 'utf8')) : require(config.extends)
-    delete config.extends
-    defaultConfig = applyExtends(defaultConfig, path.dirname(pathToDefault))
-  }
-
-  previouslyVisitedConfigs = []
-
-  return Object.assign({}, defaultConfig, config)
-}
-
-module.exports = applyExtends
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/argsert.js
+++ /dev/null
@@ -1,66 +0,0 @@
-'use strict'
-const command = require('./command')()
-const YError = require('./yerror')
-
-const positionName = ['first', 'second', 'third', 'fourth', 'fifth', 'sixth']
-
-module.exports = function argsert (expected, callerArguments, length) {
-  // TODO: should this eventually raise an exception.
-  try {
-    // preface the argument description with "cmd", so
-    // that we can run it through yargs' command parser.
-    let position = 0
-    let parsed = {demanded: [], optional: []}
-    if (typeof expected === 'object') {
-      length = callerArguments
-      callerArguments = expected
-    } else {
-      parsed = command.parseCommand(`cmd ${expected}`)
-    }
-    const args = [].slice.call(callerArguments)
-
-    while (args.length && args[args.length - 1] === undefined) args.pop()
-    length = length || args.length
-
-    if (length < parsed.demanded.length) {
-      throw new YError(`Not enough arguments provided. Expected ${parsed.demanded.length} but received ${args.length}.`)
-    }
-
-    const totalCommands = parsed.demanded.length + parsed.optional.length
-    if (length > totalCommands) {
-      throw new YError(`Too many arguments provided. Expected max ${totalCommands} but received ${length}.`)
-    }
-
-    parsed.demanded.forEach((demanded) => {
-      const arg = args.shift()
-      const observedType = guessType(arg)
-      const matchingTypes = demanded.cmd.filter(type => type === observedType || type === '*')
-      if (matchingTypes.length === 0) argumentTypeError(observedType, demanded.cmd, position, false)
-      position += 1
-    })
-
-    parsed.optional.forEach((optional) => {
-      if (args.length === 0) return
-      const arg = args.shift()
-      const observedType = guessType(arg)
-      const matchingTypes = optional.cmd.filter(type => type === observedType || type === '*')
-      if (matchingTypes.length === 0) argumentTypeError(observedType, optional.cmd, position, true)
-      position += 1
-    })
-  } catch (err) {
-    console.warn(err.stack)
-  }
-}
-
-function guessType (arg) {
-  if (Array.isArray(arg)) {
-    return 'array'
-  } else if (arg === null) {
-    return 'null'
-  }
-  return typeof arg
-}
-
-function argumentTypeError (observedType, allowedTypes, position, optional) {
-  throw new YError(`Invalid ${positionName[position] || 'manyith'} argument. Expected ${allowedTypes.join(' or ')} but received ${observedType}.`)
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/command.js
+++ /dev/null
@@ -1,426 +0,0 @@
-'use strict'
-
-const inspect = require('util').inspect
-const path = require('path')
-const Parser = require('yargs-parser')
-
-const DEFAULT_MARKER = /(^\*)|(^\$0)/
-
-// handles parsing positional arguments,
-// and populating argv with said positional
-// arguments.
-module.exports = function command (yargs, usage, validation) {
-  const self = {}
-  let handlers = {}
-  let aliasMap = {}
-  let defaultCommand
-  self.addHandler = function addHandler (cmd, description, builder, handler, middlewares) {
-    let aliases = []
-    handler = handler || (() => {})
-    middlewares = middlewares || []
-    if (Array.isArray(cmd)) {
-      aliases = cmd.slice(1)
-      cmd = cmd[0]
-    } else if (typeof cmd === 'object') {
-      let command = (Array.isArray(cmd.command) || typeof cmd.command === 'string') ? cmd.command : moduleName(cmd)
-      if (cmd.aliases) command = [].concat(command).concat(cmd.aliases)
-      self.addHandler(command, extractDesc(cmd), cmd.builder, cmd.handler, cmd.middlewares)
-      return
-    }
-
-    // allow a module to be provided instead of separate builder and handler
-    if (typeof builder === 'object' && builder.builder && typeof builder.handler === 'function') {
-      self.addHandler([cmd].concat(aliases), description, builder.builder, builder.handler, builder.middlewares)
-      return
-    }
-
-    // parse positionals out of cmd string
-    const parsedCommand = self.parseCommand(cmd)
-
-    // remove positional args from aliases only
-    aliases = aliases.map(alias => self.parseCommand(alias).cmd)
-
-    // check for default and filter out '*''
-    let isDefault = false
-    const parsedAliases = [parsedCommand.cmd].concat(aliases).filter((c) => {
-      if (DEFAULT_MARKER.test(c)) {
-        isDefault = true
-        return false
-      }
-      return true
-    })
-
-    // standardize on $0 for default command.
-    if (parsedAliases.length === 0 && isDefault) parsedAliases.push('$0')
-
-    // shift cmd and aliases after filtering out '*'
-    if (isDefault) {
-      parsedCommand.cmd = parsedAliases[0]
-      aliases = parsedAliases.slice(1)
-      cmd = cmd.replace(DEFAULT_MARKER, parsedCommand.cmd)
-    }
-
-    // populate aliasMap
-    aliases.forEach((alias) => {
-      aliasMap[alias] = parsedCommand.cmd
-    })
-
-    if (description !== false) {
-      usage.command(cmd, description, isDefault, aliases)
-    }
-
-    handlers[parsedCommand.cmd] = {
-      original: cmd,
-      description: description,
-      handler,
-      builder: builder || {},
-      middlewares: middlewares || [],
-      demanded: parsedCommand.demanded,
-      optional: parsedCommand.optional
-    }
-
-    if (isDefault) defaultCommand = handlers[parsedCommand.cmd]
-  }
-
-  self.addDirectory = function addDirectory (dir, context, req, callerFile, opts) {
-    opts = opts || {}
-    // disable recursion to support nested directories of subcommands
-    if (typeof opts.recurse !== 'boolean') opts.recurse = false
-    // exclude 'json', 'coffee' from require-directory defaults
-    if (!Array.isArray(opts.extensions)) opts.extensions = ['js']
-    // allow consumer to define their own visitor function
-    const parentVisit = typeof opts.visit === 'function' ? opts.visit : o => o
-    // call addHandler via visitor function
-    opts.visit = function visit (obj, joined, filename) {
-      const visited = parentVisit(obj, joined, filename)
-      // allow consumer to skip modules with their own visitor
-      if (visited) {
-        // check for cyclic reference
-        // each command file path should only be seen once per execution
-        if (~context.files.indexOf(joined)) return visited
-        // keep track of visited files in context.files
-        context.files.push(joined)
-        self.addHandler(visited)
-      }
-      return visited
-    }
-    require('require-directory')({ require: req, filename: callerFile }, dir, opts)
-  }
-
-  // lookup module object from require()d command and derive name
-  // if module was not require()d and no name given, throw error
-  function moduleName (obj) {
-    const mod = require('which-module')(obj)
-    if (!mod) throw new Error(`No command name given for module: ${inspect(obj)}`)
-    return commandFromFilename(mod.filename)
-  }
-
-  // derive command name from filename
-  function commandFromFilename (filename) {
-    return path.basename(filename, path.extname(filename))
-  }
-
-  function extractDesc (obj) {
-    for (let keys = ['describe', 'description', 'desc'], i = 0, l = keys.length, test; i < l; i++) {
-      test = obj[keys[i]]
-      if (typeof test === 'string' || typeof test === 'boolean') return test
-    }
-    return false
-  }
-
-  self.parseCommand = function parseCommand (cmd) {
-    const extraSpacesStrippedCommand = cmd.replace(/\s{2,}/g, ' ')
-    const splitCommand = extraSpacesStrippedCommand.split(/\s+(?![^[]*]|[^<]*>)/)
-    const bregex = /\.*[\][<>]/g
-    const parsedCommand = {
-      cmd: (splitCommand.shift()).replace(bregex, ''),
-      demanded: [],
-      optional: []
-    }
-    splitCommand.forEach((cmd, i) => {
-      let variadic = false
-      cmd = cmd.replace(/\s/g, '')
-      if (/\.+[\]>]/.test(cmd) && i === splitCommand.length - 1) variadic = true
-      if (/^\[/.test(cmd)) {
-        parsedCommand.optional.push({
-          cmd: cmd.replace(bregex, '').split('|'),
-          variadic
-        })
-      } else {
-        parsedCommand.demanded.push({
-          cmd: cmd.replace(bregex, '').split('|'),
-          variadic
-        })
-      }
-    })
-    return parsedCommand
-  }
-
-  self.getCommands = () => Object.keys(handlers).concat(Object.keys(aliasMap))
-
-  self.getCommandHandlers = () => handlers
-
-  self.hasDefaultCommand = () => !!defaultCommand
-
-  self.runCommand = function runCommand (command, yargs, parsed, commandIndex) {
-    let aliases = parsed.aliases
-    const commandHandler = handlers[command] || handlers[aliasMap[command]] || defaultCommand
-    const currentContext = yargs.getContext()
-    let numFiles = currentContext.files.length
-    const parentCommands = currentContext.commands.slice()
-
-    // what does yargs look like after the buidler is run?
-    let innerArgv = parsed.argv
-    let innerYargs = null
-    let positionalMap = {}
-    if (command) {
-      currentContext.commands.push(command)
-      currentContext.fullCommands.push(commandHandler.original)
-    }
-    if (typeof commandHandler.builder === 'function') {
-      // a function can be provided, which builds
-      // up a yargs chain and possibly returns it.
-      innerYargs = commandHandler.builder(yargs.reset(parsed.aliases))
-      // if the builder function did not yet parse argv with reset yargs
-      // and did not explicitly set a usage() string, then apply the
-      // original command string as usage() for consistent behavior with
-      // options object below.
-      if (yargs.parsed === false) {
-        if (shouldUpdateUsage(yargs)) {
-          yargs.getUsageInstance().usage(
-            usageFromParentCommandsCommandHandler(parentCommands, commandHandler),
-            commandHandler.description
-          )
-        }
-        innerArgv = innerYargs ? innerYargs._parseArgs(null, null, true, commandIndex) : yargs._parseArgs(null, null, true, commandIndex)
-      } else {
-        innerArgv = yargs.parsed.argv
-      }
-
-      if (innerYargs && yargs.parsed === false) aliases = innerYargs.parsed.aliases
-      else aliases = yargs.parsed.aliases
-    } else if (typeof commandHandler.builder === 'object') {
-      // as a short hand, an object can instead be provided, specifying
-      // the options that a command takes.
-      innerYargs = yargs.reset(parsed.aliases)
-      if (shouldUpdateUsage(innerYargs)) {
-        innerYargs.getUsageInstance().usage(
-          usageFromParentCommandsCommandHandler(parentCommands, commandHandler),
-          commandHandler.description
-        )
-      }
-      Object.keys(commandHandler.builder).forEach((key) => {
-        innerYargs.option(key, commandHandler.builder[key])
-      })
-      innerArgv = innerYargs._parseArgs(null, null, true, commandIndex)
-      aliases = innerYargs.parsed.aliases
-    }
-
-    if (!yargs._hasOutput()) {
-      positionalMap = populatePositionals(commandHandler, innerArgv, currentContext, yargs)
-    }
-
-    // we apply validation post-hoc, so that custom
-    // checks get passed populated positional arguments.
-    if (!yargs._hasOutput()) yargs._runValidation(innerArgv, aliases, positionalMap, yargs.parsed.error)
-
-    if (commandHandler.handler && !yargs._hasOutput()) {
-      yargs._setHasOutput()
-      if (commandHandler.middlewares.length > 0) {
-        const middlewareArgs = commandHandler.middlewares.reduce(function (initialObj, middleware) {
-          return Object.assign(initialObj, middleware(innerArgv))
-        }, {})
-        Object.assign(innerArgv, middlewareArgs)
-      }
-      const handlerResult = commandHandler.handler(innerArgv)
-      if (handlerResult && typeof handlerResult.then === 'function') {
-        handlerResult.then(
-          null,
-          (error) => yargs.getUsageInstance().fail(null, error)
-        )
-      }
-    }
-
-    if (command) {
-      currentContext.commands.pop()
-      currentContext.fullCommands.pop()
-    }
-    numFiles = currentContext.files.length - numFiles
-    if (numFiles > 0) currentContext.files.splice(numFiles * -1, numFiles)
-
-    return innerArgv
-  }
-
-  function shouldUpdateUsage (yargs) {
-    return !yargs.getUsageInstance().getUsageDisabled() &&
-      yargs.getUsageInstance().getUsage().length === 0
-  }
-
-  function usageFromParentCommandsCommandHandler (parentCommands, commandHandler) {
-    const c = DEFAULT_MARKER.test(commandHandler.original) ? commandHandler.original.replace(DEFAULT_MARKER, '').trim() : commandHandler.original
-    const pc = parentCommands.filter((c) => { return !DEFAULT_MARKER.test(c) })
-    pc.push(c)
-    return `$0 ${pc.join(' ')}`
-  }
-
-  self.runDefaultBuilderOn = function (yargs) {
-    if (shouldUpdateUsage(yargs)) {
-      // build the root-level command string from the default string.
-      const commandString = DEFAULT_MARKER.test(defaultCommand.original)
-        ? defaultCommand.original : defaultCommand.original.replace(/^[^[\]<>]*/, '$0 ')
-      yargs.getUsageInstance().usage(
-        commandString,
-        defaultCommand.description
-      )
-    }
-    const builder = defaultCommand.builder
-    if (typeof builder === 'function') {
-      builder(yargs)
-    } else {
-      Object.keys(builder).forEach((key) => {
-        yargs.option(key, builder[key])
-      })
-    }
-  }
-
-  // transcribe all positional arguments "command <foo> <bar> [apple]"
-  // onto argv.
-  function populatePositionals (commandHandler, argv, context, yargs) {
-    argv._ = argv._.slice(context.commands.length) // nuke the current commands
-    const demanded = commandHandler.demanded.slice(0)
-    const optional = commandHandler.optional.slice(0)
-    const positionalMap = {}
-
-    validation.positionalCount(demanded.length, argv._.length)
-
-    while (demanded.length) {
-      const demand = demanded.shift()
-      populatePositional(demand, argv, positionalMap)
-    }
-
-    while (optional.length) {
-      const maybe = optional.shift()
-      populatePositional(maybe, argv, positionalMap)
-    }
-
-    argv._ = context.commands.concat(argv._)
-
-    postProcessPositionals(argv, positionalMap, self.cmdToParseOptions(commandHandler.original))
-
-    return positionalMap
-  }
-
-  function populatePositional (positional, argv, positionalMap, parseOptions) {
-    const cmd = positional.cmd[0]
-    if (positional.variadic) {
-      positionalMap[cmd] = argv._.splice(0).map(String)
-    } else {
-      if (argv._.length) positionalMap[cmd] = [String(argv._.shift())]
-    }
-  }
-
-  // we run yargs-parser against the positional arguments
-  // applying the same parsing logic used for flags.
-  function postProcessPositionals (argv, positionalMap, parseOptions) {
-    // combine the parsing hints we've inferred from the command
-    // string with explicitly configured parsing hints.
-    const options = Object.assign({}, yargs.getOptions())
-    options.default = Object.assign(parseOptions.default, options.default)
-    options.alias = Object.assign(parseOptions.alias, options.alias)
-    options.array = options.array.concat(parseOptions.array)
-
-    const unparsed = []
-    Object.keys(positionalMap).forEach((key) => {
-      positionalMap[key].map((value) => {
-        unparsed.push(`--${key}`)
-        unparsed.push(value)
-      })
-    })
-
-    // short-circuit parse.
-    if (!unparsed.length) return
-
-    const parsed = Parser.detailed(unparsed, options)
-
-    if (parsed.error) {
-      yargs.getUsageInstance().fail(parsed.error.message, parsed.error)
-    } else {
-      // only copy over positional keys (don't overwrite
-      // flag arguments that were already parsed).
-      const positionalKeys = Object.keys(positionalMap)
-      Object.keys(positionalMap).forEach((key) => {
-        [].push.apply(positionalKeys, parsed.aliases[key])
-      })
-
-      Object.keys(parsed.argv).forEach((key) => {
-        if (positionalKeys.indexOf(key) !== -1) {
-          argv[key] = parsed.argv[key]
-        }
-      })
-    }
-  }
-
-  self.cmdToParseOptions = function (cmdString) {
-    const parseOptions = {
-      array: [],
-      default: {},
-      alias: {},
-      demand: {}
-    }
-
-    const parsed = self.parseCommand(cmdString)
-    parsed.demanded.forEach((d) => {
-      const cmds = d.cmd.slice(0)
-      const cmd = cmds.shift()
-      if (d.variadic) {
-        parseOptions.array.push(cmd)
-        parseOptions.default[cmd] = []
-      }
-      cmds.forEach((c) => {
-        parseOptions.alias[cmd] = c
-      })
-      parseOptions.demand[cmd] = true
-    })
-
-    parsed.optional.forEach((o) => {
-      const cmds = o.cmd.slice(0)
-      const cmd = cmds.shift()
-      if (o.variadic) {
-        parseOptions.array.push(cmd)
-        parseOptions.default[cmd] = []
-      }
-      cmds.forEach((c) => {
-        parseOptions.alias[cmd] = c
-      })
-    })
-
-    return parseOptions
-  }
-
-  self.reset = () => {
-    handlers = {}
-    aliasMap = {}
-    defaultCommand = undefined
-    return self
-  }
-
-  // used by yargs.parse() to freeze
-  // the state of commands such that
-  // we can apply .parse() multiple times
-  // with the same yargs instance.
-  let frozen
-  self.freeze = () => {
-    frozen = {}
-    frozen.handlers = handlers
-    frozen.aliasMap = aliasMap
-    frozen.defaultCommand = defaultCommand
-  }
-  self.unfreeze = () => {
-    handlers = frozen.handlers
-    aliasMap = frozen.aliasMap
-    defaultCommand = frozen.defaultCommand
-    frozen = undefined
-  }
-
-  return self
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/completion.js
+++ /dev/null
@@ -1,105 +0,0 @@
-'use strict'
-const fs = require('fs')
-const path = require('path')
-
-// add bash completions to your
-//  yargs-powered applications.
-module.exports = function completion (yargs, usage, command) {
-  const self = {
-    completionKey: 'get-yargs-completions'
-  }
-
-  // get a list of completion commands.
-  // 'args' is the array of strings from the line to be completed
-  self.getCompletion = function getCompletion (args, done) {
-    const completions = []
-    const current = args.length ? args[args.length - 1] : ''
-    const argv = yargs.parse(args, true)
-    const aliases = yargs.parsed.aliases
-
-    // a custom completion function can be provided
-    // to completion().
-    if (completionFunction) {
-      if (completionFunction.length < 3) {
-        const result = completionFunction(current, argv)
-
-        // promise based completion function.
-        if (typeof result.then === 'function') {
-          return result.then((list) => {
-            process.nextTick(() => { done(list) })
-          }).catch((err) => {
-            process.nextTick(() => { throw err })
-          })
-        }
-
-        // synchronous completion function.
-        return done(result)
-      } else {
-        // asynchronous completion function
-        return completionFunction(current, argv, (completions) => {
-          done(completions)
-        })
-      }
-    }
-
-    const handlers = command.getCommandHandlers()
-    for (let i = 0, ii = args.length; i < ii; ++i) {
-      if (handlers[args[i]] && handlers[args[i]].builder) {
-        const builder = handlers[args[i]].builder
-        if (typeof builder === 'function') {
-          const y = yargs.reset()
-          builder(y)
-          return y.argv
-        }
-      }
-    }
-
-    if (!current.match(/^-/)) {
-      usage.getCommands().forEach((usageCommand) => {
-        const commandName = command.parseCommand(usageCommand[0]).cmd
-        if (args.indexOf(commandName) === -1) {
-          completions.push(commandName)
-        }
-      })
-    }
-
-    if (current.match(/^-/)) {
-      Object.keys(yargs.getOptions().key).forEach((key) => {
-        // If the key and its aliases aren't in 'args', add the key to 'completions'
-        const keyAndAliases = [key].concat(aliases[key] || [])
-        const notInArgs = keyAndAliases.every(val => args.indexOf(`--${val}`) === -1)
-        if (notInArgs) {
-          completions.push(`--${key}`)
-        }
-      })
-    }
-
-    done(completions)
-  }
-
-  // generate the completion script to add to your .bashrc.
-  self.generateCompletionScript = function generateCompletionScript ($0, cmd) {
-    let script = fs.readFileSync(
-      path.resolve(__dirname, '../completion.sh.hbs'),
-      'utf-8'
-    )
-    const name = path.basename($0)
-
-    // add ./to applications not yet installed as bin.
-    if ($0.match(/\.js$/)) $0 = `./${$0}`
-
-    script = script.replace(/{{app_name}}/g, name)
-    script = script.replace(/{{completion_command}}/g, cmd)
-    return script.replace(/{{app_path}}/g, $0)
-  }
-
-  // register a function to perform your own custom
-  // completions., this function can be either
-  // synchrnous or asynchronous.
-  let completionFunction = null
-  self.registerFunction = (fn) => {
-    completionFunction = fn
-  }
-
-  return self
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/levenshtein.js
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
-Copyright (c) 2011 Andrei Mackenzie
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-*/
-
-// levenshtein distance algorithm, pulled from Andrei Mackenzie's MIT licensed.
-// gist, which can be found here: https://gist.github.com/andrei-m/982927
-'use strict'
-// Compute the edit distance between the two given strings
-module.exports = function levenshtein (a, b) {
-  if (a.length === 0) return b.length
-  if (b.length === 0) return a.length
-
-  const matrix = []
-
-  // increment along the first column of each row
-  let i
-  for (i = 0; i <= b.length; i++) {
-    matrix[i] = [i]
-  }
-
-  // increment each column in the first row
-  let j
-  for (j = 0; j <= a.length; j++) {
-    matrix[0][j] = j
-  }
-
-  // Fill in the rest of the matrix
-  for (i = 1; i <= b.length; i++) {
-    for (j = 1; j <= a.length; j++) {
-      if (b.charAt(i - 1) === a.charAt(j - 1)) {
-        matrix[i][j] = matrix[i - 1][j - 1]
-      } else {
-        matrix[i][j] = Math.min(matrix[i - 1][j - 1] + 1, // substitution
-                                Math.min(matrix[i][j - 1] + 1, // insertion
-                                         matrix[i - 1][j] + 1)) // deletion
-      }
-    }
-  }
-
-  return matrix[b.length][a.length]
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/obj-filter.js
+++ /dev/null
@@ -1,11 +0,0 @@
-'use strict'
-module.exports = function objFilter (original, filter) {
-  const obj = {}
-  filter = filter || ((k, v) => true)
-  Object.keys(original || {}).forEach((key) => {
-    if (filter(key, original[key])) {
-      obj[key] = original[key]
-    }
-  })
-  return obj
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/usage.js
+++ /dev/null
@@ -1,531 +0,0 @@
-'use strict'
-// this file handles outputting usage instructions,
-// failures, etc. keeps logging in one place.
-const stringWidth = require('string-width')
-const objFilter = require('./obj-filter')
-const path = require('path')
-const setBlocking = require('set-blocking')
-const YError = require('./yerror')
-
-module.exports = function usage (yargs, y18n) {
-  const __ = y18n.__
-  const self = {}
-
-  // methods for ouputting/building failure message.
-  const fails = []
-  self.failFn = function failFn (f) {
-    fails.push(f)
-  }
-
-  let failMessage = null
-  let showHelpOnFail = true
-  self.showHelpOnFail = function showHelpOnFailFn (enabled, message) {
-    if (typeof enabled === 'string') {
-      message = enabled
-      enabled = true
-    } else if (typeof enabled === 'undefined') {
-      enabled = true
-    }
-    failMessage = message
-    showHelpOnFail = enabled
-    return self
-  }
-
-  let failureOutput = false
-  self.fail = function fail (msg, err) {
-    const logger = yargs._getLoggerInstance()
-
-    if (fails.length) {
-      for (let i = fails.length - 1; i >= 0; --i) {
-        fails[i](msg, err, self)
-      }
-    } else {
-      if (yargs.getExitProcess()) setBlocking(true)
-
-      // don't output failure message more than once
-      if (!failureOutput) {
-        failureOutput = true
-        if (showHelpOnFail) yargs.showHelp('error')
-        if (msg || err) logger.error(msg || err)
-        if (failMessage) {
-          if (msg || err) logger.error('')
-          logger.error(failMessage)
-        }
-      }
-
-      err = err || new YError(msg)
-      if (yargs.getExitProcess()) {
-        return yargs.exit(1)
-      } else if (yargs._hasParseCallback()) {
-        return yargs.exit(1, err)
-      } else {
-        throw err
-      }
-    }
-  }
-
-  // methods for ouputting/building help (usage) message.
-  let usages = []
-  let usageDisabled = false
-  self.usage = (msg, description) => {
-    if (msg === null) {
-      usageDisabled = true
-      usages = []
-      return
-    }
-    usageDisabled = false
-    usages.push([msg, description || ''])
-    return self
-  }
-  self.getUsage = () => {
-    return usages
-  }
-  self.getUsageDisabled = () => {
-    return usageDisabled
-  }
-
-  self.getPositionalGroupName = () => {
-    return __('Positionals:')
-  }
-
-  let examples = []
-  self.example = (cmd, description) => {
-    examples.push([cmd, description || ''])
-  }
-
-  let commands = []
-  self.command = function command (cmd, description, isDefault, aliases) {
-    // the last default wins, so cancel out any previously set default
-    if (isDefault) {
-      commands = commands.map((cmdArray) => {
-        cmdArray[2] = false
-        return cmdArray
-      })
-    }
-    commands.push([cmd, description || '', isDefault, aliases])
-  }
-  self.getCommands = () => commands
-
-  let descriptions = {}
-  self.describe = function describe (key, desc) {
-    if (typeof key === 'object') {
-      Object.keys(key).forEach((k) => {
-        self.describe(k, key[k])
-      })
-    } else {
-      descriptions[key] = desc
-    }
-  }
-  self.getDescriptions = () => descriptions
-
-  let epilog
-  self.epilog = (msg) => {
-    epilog = msg
-  }
-
-  let wrapSet = false
-  let wrap
-  self.wrap = (cols) => {
-    wrapSet = true
-    wrap = cols
-  }
-
-  function getWrap () {
-    if (!wrapSet) {
-      wrap = windowWidth()
-      wrapSet = true
-    }
-
-    return wrap
-  }
-
-  const deferY18nLookupPrefix = '__yargsString__:'
-  self.deferY18nLookup = str => deferY18nLookupPrefix + str
-
-  const defaultGroup = 'Options:'
-  self.help = function help () {
-    normalizeAliases()
-
-    // handle old demanded API
-    const base$0 = path.basename(yargs.$0)
-    const demandedOptions = yargs.getDemandedOptions()
-    const demandedCommands = yargs.getDemandedCommands()
-    const groups = yargs.getGroups()
-    const options = yargs.getOptions()
-
-    let keys = []
-    keys = keys.concat(Object.keys(descriptions))
-    keys = keys.concat(Object.keys(demandedOptions))
-    keys = keys.concat(Object.keys(demandedCommands))
-    keys = keys.concat(Object.keys(options.default))
-    keys = keys.filter(key => {
-      if (options.hiddenOptions.indexOf(key) < 0) {
-        return true
-      } else if (yargs.parsed.argv[options.showHiddenOpt]) {
-        return true
-      }
-    })
-    keys = Object.keys(keys.reduce((acc, key) => {
-      if (key !== '_') acc[key] = true
-      return acc
-    }, {}))
-
-    const theWrap = getWrap()
-    const ui = require('cliui')({
-      width: theWrap,
-      wrap: !!theWrap
-    })
-
-    // the usage string.
-    if (!usageDisabled) {
-      if (usages.length) {
-        // user-defined usage.
-        usages.forEach((usage) => {
-          ui.div(`${usage[0].replace(/\$0/g, base$0)}`)
-          if (usage[1]) {
-            ui.div({text: `${usage[1]}`, padding: [1, 0, 0, 0]})
-          }
-        })
-        ui.div()
-      } else if (commands.length) {
-        let u = null
-        // demonstrate how commands are used.
-        if (demandedCommands._) {
-          u = `${base$0} <${__('command')}>\n`
-        } else {
-          u = `${base$0} [${__('command')}]\n`
-        }
-        ui.div(`${u}`)
-      }
-    }
-
-    // your application's commands, i.e., non-option
-    // arguments populated in '_'.
-    if (commands.length) {
-      ui.div(__('Commands:'))
-
-      const context = yargs.getContext()
-      const parentCommands = context.commands.length ? `${context.commands.join(' ')} ` : ''
-
-      commands.forEach((command) => {
-        const commandString = `${base$0} ${parentCommands}${command[0].replace(/^\$0 ?/, '')}` // drop $0 from default commands.
-        ui.span(
-          {
-            text: commandString,
-            padding: [0, 2, 0, 2],
-            width: maxWidth(commands, theWrap, `${base$0}${parentCommands}`) + 4
-          },
-          {text: command[1]}
-        )
-        const hints = []
-        if (command[2]) hints.push(`[${__('default:').slice(0, -1)}]`) // TODO hacking around i18n here
-        if (command[3] && command[3].length) {
-          hints.push(`[${__('aliases:')} ${command[3].join(', ')}]`)
-        }
-        if (hints.length) {
-          ui.div({text: hints.join(' '), padding: [0, 0, 0, 2], align: 'right'})
-        } else {
-          ui.div()
-        }
-      })
-
-      ui.div()
-    }
-
-    // perform some cleanup on the keys array, making it
-    // only include top-level keys not their aliases.
-    const aliasKeys = (Object.keys(options.alias) || [])
-      .concat(Object.keys(yargs.parsed.newAliases) || [])
-
-    keys = keys.filter(key => !yargs.parsed.newAliases[key] && aliasKeys.every(alias => (options.alias[alias] || []).indexOf(key) === -1))
-
-    // populate 'Options:' group with any keys that have not
-    // explicitly had a group set.
-    if (!groups[defaultGroup]) groups[defaultGroup] = []
-    addUngroupedKeys(keys, options.alias, groups)
-
-    // display 'Options:' table along with any custom tables:
-    Object.keys(groups).forEach((groupName) => {
-      if (!groups[groupName].length) return
-
-      ui.div(__(groupName))
-
-      // if we've grouped the key 'f', but 'f' aliases 'foobar',
-      // normalizedKeys should contain only 'foobar'.
-      const normalizedKeys = groups[groupName].map((key) => {
-        if (~aliasKeys.indexOf(key)) return key
-        for (let i = 0, aliasKey; (aliasKey = aliasKeys[i]) !== undefined; i++) {
-          if (~(options.alias[aliasKey] || []).indexOf(key)) return aliasKey
-        }
-        return key
-      })
-
-      // actually generate the switches string --foo, -f, --bar.
-      const switches = normalizedKeys.reduce((acc, key) => {
-        acc[key] = [ key ].concat(options.alias[key] || [])
-          .map(sw => {
-            // for the special positional group don't
-            // add '--' or '-' prefix.
-            if (groupName === self.getPositionalGroupName()) return sw
-            else return (sw.length > 1 ? '--' : '-') + sw
-          })
-          .join(', ')
-
-        return acc
-      }, {})
-
-      normalizedKeys.forEach((key) => {
-        const kswitch = switches[key]
-        let desc = descriptions[key] || ''
-        let type = null
-
-        if (~desc.lastIndexOf(deferY18nLookupPrefix)) desc = __(desc.substring(deferY18nLookupPrefix.length))
-
-        if (~options.boolean.indexOf(key)) type = `[${__('boolean')}]`
-        if (~options.count.indexOf(key)) type = `[${__('count')}]`
-        if (~options.string.indexOf(key)) type = `[${__('string')}]`
-        if (~options.normalize.indexOf(key)) type = `[${__('string')}]`
-        if (~options.array.indexOf(key)) type = `[${__('array')}]`
-        if (~options.number.indexOf(key)) type = `[${__('number')}]`
-
-        const extra = [
-          type,
-          (key in demandedOptions) ? `[${__('required')}]` : null,
-          options.choices && options.choices[key] ? `[${__('choices:')} ${
-            self.stringifiedValues(options.choices[key])}]` : null,
-          defaultString(options.default[key], options.defaultDescription[key])
-        ].filter(Boolean).join(' ')
-
-        ui.span(
-          {text: kswitch, padding: [0, 2, 0, 2], width: maxWidth(switches, theWrap) + 4},
-          desc
-        )
-
-        if (extra) ui.div({text: extra, padding: [0, 0, 0, 2], align: 'right'})
-        else ui.div()
-      })
-
-      ui.div()
-    })
-
-    // describe some common use-cases for your application.
-    if (examples.length) {
-      ui.div(__('Examples:'))
-
-      examples.forEach((example) => {
-        example[0] = example[0].replace(/\$0/g, base$0)
-      })
-
-      examples.forEach((example) => {
-        if (example[1] === '') {
-          ui.div(
-            {
-              text: example[0],
-              padding: [0, 2, 0, 2]
-            }
-          )
-        } else {
-          ui.div(
-            {
-              text: example[0],
-              padding: [0, 2, 0, 2],
-              width: maxWidth(examples, theWrap) + 4
-            }, {
-              text: example[1]
-            }
-          )
-        }
-      })
-
-      ui.div()
-    }
-
-    // the usage string.
-    if (epilog) {
-      const e = epilog.replace(/\$0/g, base$0)
-      ui.div(`${e}\n`)
-    }
-
-    return ui.toString()
-  }
-
-  // return the maximum width of a string
-  // in the left-hand column of a table.
-  function maxWidth (table, theWrap, modifier) {
-    let width = 0
-
-    // table might be of the form [leftColumn],
-    // or {key: leftColumn}
-    if (!Array.isArray(table)) {
-      table = Object.keys(table).map(key => [table[key]])
-    }
-
-    table.forEach((v) => {
-      width = Math.max(
-        stringWidth(modifier ? `${modifier} ${v[0]}` : v[0]),
-        width
-      )
-    })
-
-    // if we've enabled 'wrap' we should limit
-    // the max-width of the left-column.
-    if (theWrap) width = Math.min(width, parseInt(theWrap * 0.5, 10))
-
-    return width
-  }
-
-  // make sure any options set for aliases,
-  // are copied to the keys being aliased.
-  function normalizeAliases () {
-    // handle old demanded API
-    const demandedOptions = yargs.getDemandedOptions()
-    const options = yargs.getOptions()
-
-    ;(Object.keys(options.alias) || []).forEach((key) => {
-      options.alias[key].forEach((alias) => {
-        // copy descriptions.
-        if (descriptions[alias]) self.describe(key, descriptions[alias])
-        // copy demanded.
-        if (alias in demandedOptions) yargs.demandOption(key, demandedOptions[alias])
-        // type messages.
-        if (~options.boolean.indexOf(alias)) yargs.boolean(key)
-        if (~options.count.indexOf(alias)) yargs.count(key)
-        if (~options.string.indexOf(alias)) yargs.string(key)
-        if (~options.normalize.indexOf(alias)) yargs.normalize(key)
-        if (~options.array.indexOf(alias)) yargs.array(key)
-        if (~options.number.indexOf(alias)) yargs.number(key)
-      })
-    })
-  }
-
-  // given a set of keys, place any keys that are
-  // ungrouped under the 'Options:' grouping.
-  function addUngroupedKeys (keys, aliases, groups) {
-    let groupedKeys = []
-    let toCheck = null
-    Object.keys(groups).forEach((group) => {
-      groupedKeys = groupedKeys.concat(groups[group])
-    })
-
-    keys.forEach((key) => {
-      toCheck = [key].concat(aliases[key])
-      if (!toCheck.some(k => groupedKeys.indexOf(k) !== -1)) {
-        groups[defaultGroup].push(key)
-      }
-    })
-    return groupedKeys
-  }
-
-  self.showHelp = (level) => {
-    const logger = yargs._getLoggerInstance()
-    if (!level) level = 'error'
-    const emit = typeof level === 'function' ? level : logger[level]
-    emit(self.help())
-  }
-
-  self.functionDescription = (fn) => {
-    const description = fn.name ? require('decamelize')(fn.name, '-') : __('generated-value')
-    return ['(', description, ')'].join('')
-  }
-
-  self.stringifiedValues = function stringifiedValues (values, separator) {
-    let string = ''
-    const sep = separator || ', '
-    const array = [].concat(values)
-
-    if (!values || !array.length) return string
-
-    array.forEach((value) => {
-      if (string.length) string += sep
-      string += JSON.stringify(value)
-    })
-
-    return string
-  }
-
-  // format the default-value-string displayed in
-  // the right-hand column.
-  function defaultString (value, defaultDescription) {
-    let string = `[${__('default:')} `
-
-    if (value === undefined && !defaultDescription) return null
-
-    if (defaultDescription) {
-      string += defaultDescription
-    } else {
-      switch (typeof value) {
-        case 'string':
-          string += `"${value}"`
-          break
-        case 'object':
-          string += JSON.stringify(value)
-          break
-        default:
-          string += value
-      }
-    }
-
-    return `${string}]`
-  }
-
-  // guess the width of the console window, max-width 80.
-  function windowWidth () {
-    const maxWidth = 80
-    if (typeof process === 'object' && process.stdout && process.stdout.columns) {
-      return Math.min(maxWidth, process.stdout.columns)
-    } else {
-      return maxWidth
-    }
-  }
-
-  // logic for displaying application version.
-  let version = null
-  self.version = (ver) => {
-    version = ver
-  }
-
-  self.showVersion = () => {
-    const logger = yargs._getLoggerInstance()
-    logger.log(version)
-  }
-
-  self.reset = function reset (localLookup) {
-    // do not reset wrap here
-    // do not reset fails here
-    failMessage = null
-    failureOutput = false
-    usages = []
-    usageDisabled = false
-    epilog = undefined
-    examples = []
-    commands = []
-    descriptions = objFilter(descriptions, (k, v) => !localLookup[k])
-    return self
-  }
-
-  let frozen
-  self.freeze = function freeze () {
-    frozen = {}
-    frozen.failMessage = failMessage
-    frozen.failureOutput = failureOutput
-    frozen.usages = usages
-    frozen.usageDisabled = usageDisabled
-    frozen.epilog = epilog
-    frozen.examples = examples
-    frozen.commands = commands
-    frozen.descriptions = descriptions
-  }
-  self.unfreeze = function unfreeze () {
-    failMessage = frozen.failMessage
-    failureOutput = frozen.failureOutput
-    usages = frozen.usages
-    usageDisabled = frozen.usageDisabled
-    epilog = frozen.epilog
-    examples = frozen.examples
-    commands = frozen.commands
-    descriptions = frozen.descriptions
-    frozen = undefined
-  }
-
-  return self
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/validation.js
+++ /dev/null
@@ -1,341 +0,0 @@
-'use strict'
-const argsert = require('./argsert')
-const objFilter = require('./obj-filter')
-const specialKeys = ['$0', '--', '_']
-
-// validation-type-stuff, missing params,
-// bad implications, custom checks.
-module.exports = function validation (yargs, usage, y18n) {
-  const __ = y18n.__
-  const __n = y18n.__n
-  const self = {}
-
-  // validate appropriate # of non-option
-  // arguments were provided, i.e., '_'.
-  self.nonOptionCount = function nonOptionCount (argv) {
-    const demandedCommands = yargs.getDemandedCommands()
-    // don't count currently executing commands
-    const _s = argv._.length - yargs.getContext().commands.length
-
-    if (demandedCommands._ && (_s < demandedCommands._.min || _s > demandedCommands._.max)) {
-      if (_s < demandedCommands._.min) {
-        if (demandedCommands._.minMsg !== undefined) {
-          usage.fail(
-            // replace $0 with observed, $1 with expected.
-            demandedCommands._.minMsg ? demandedCommands._.minMsg.replace(/\$0/g, _s).replace(/\$1/, demandedCommands._.min) : null
-          )
-        } else {
-          usage.fail(
-            __('Not enough non-option arguments: got %s, need at least %s', _s, demandedCommands._.min)
-          )
-        }
-      } else if (_s > demandedCommands._.max) {
-        if (demandedCommands._.maxMsg !== undefined) {
-          usage.fail(
-            // replace $0 with observed, $1 with expected.
-            demandedCommands._.maxMsg ? demandedCommands._.maxMsg.replace(/\$0/g, _s).replace(/\$1/, demandedCommands._.max) : null
-          )
-        } else {
-          usage.fail(
-          __('Too many non-option arguments: got %s, maximum of %s', _s, demandedCommands._.max)
-          )
-        }
-      }
-    }
-  }
-
-  // validate the appropriate # of <required>
-  // positional arguments were provided:
-  self.positionalCount = function positionalCount (required, observed) {
-    if (observed < required) {
-      usage.fail(
-        __('Not enough non-option arguments: got %s, need at least %s', observed, required)
-      )
-    }
-  }
-
-  // make sure all the required arguments are present.
-  self.requiredArguments = function requiredArguments (argv) {
-    const demandedOptions = yargs.getDemandedOptions()
-    let missing = null
-
-    Object.keys(demandedOptions).forEach((key) => {
-      if (!argv.hasOwnProperty(key) || typeof argv[key] === 'undefined') {
-        missing = missing || {}
-        missing[key] = demandedOptions[key]
-      }
-    })
-
-    if (missing) {
-      const customMsgs = []
-      Object.keys(missing).forEach((key) => {
-        const msg = missing[key]
-        if (msg && customMsgs.indexOf(msg) < 0) {
-          customMsgs.push(msg)
-        }
-      })
-
-      const customMsg = customMsgs.length ? `\n${customMsgs.join('\n')}` : ''
-
-      usage.fail(__n(
-        'Missing required argument: %s',
-        'Missing required arguments: %s',
-        Object.keys(missing).length,
-        Object.keys(missing).join(', ') + customMsg
-      ))
-    }
-  }
-
-  // check for unknown arguments (strict-mode).
-  self.unknownArguments = function unknownArguments (argv, aliases, positionalMap) {
-    const commandKeys = yargs.getCommandInstance().getCommands()
-    const unknown = []
-    const currentContext = yargs.getContext()
-
-    Object.keys(argv).forEach((key) => {
-      if (specialKeys.indexOf(key) === -1 &&
-        !positionalMap.hasOwnProperty(key) &&
-        !yargs._getParseContext().hasOwnProperty(key) &&
-        !aliases.hasOwnProperty(key)
-      ) {
-        unknown.push(key)
-      }
-    })
-
-    if (commandKeys.length > 0) {
-      argv._.slice(currentContext.commands.length).forEach((key) => {
-        if (commandKeys.indexOf(key) === -1) {
-          unknown.push(key)
-        }
-      })
-    }
-
-    if (unknown.length > 0) {
-      usage.fail(__n(
-        'Unknown argument: %s',
-        'Unknown arguments: %s',
-        unknown.length,
-        unknown.join(', ')
-      ))
-    }
-  }
-
-  // validate arguments limited to enumerated choices
-  self.limitedChoices = function limitedChoices (argv) {
-    const options = yargs.getOptions()
-    const invalid = {}
-
-    if (!Object.keys(options.choices).length) return
-
-    Object.keys(argv).forEach((key) => {
-      if (specialKeys.indexOf(key) === -1 &&
-        options.choices.hasOwnProperty(key)) {
-        [].concat(argv[key]).forEach((value) => {
-          // TODO case-insensitive configurability
-          if (options.choices[key].indexOf(value) === -1 &&
-              value !== undefined) {
-            invalid[key] = (invalid[key] || []).concat(value)
-          }
-        })
-      }
-    })
-
-    const invalidKeys = Object.keys(invalid)
-
-    if (!invalidKeys.length) return
-
-    let msg = __('Invalid values:')
-    invalidKeys.forEach((key) => {
-      msg += `\n  ${__(
-        'Argument: %s, Given: %s, Choices: %s',
-        key,
-        usage.stringifiedValues(invalid[key]),
-        usage.stringifiedValues(options.choices[key])
-      )}`
-    })
-    usage.fail(msg)
-  }
-
-  // custom checks, added using the `check` option on yargs.
-  let checks = []
-  self.check = function check (f, global) {
-    checks.push({
-      func: f,
-      global
-    })
-  }
-
-  self.customChecks = function customChecks (argv, aliases) {
-    for (let i = 0, f; (f = checks[i]) !== undefined; i++) {
-      const func = f.func
-      let result = null
-      try {
-        result = func(argv, aliases)
-      } catch (err) {
-        usage.fail(err.message ? err.message : err, err)
-        continue
-      }
-
-      if (!result) {
-        usage.fail(__('Argument check failed: %s', func.toString()))
-      } else if (typeof result === 'string' || result instanceof Error) {
-        usage.fail(result.toString(), result)
-      }
-    }
-  }
-
-  // check implications, argument foo implies => argument bar.
-  let implied = {}
-  self.implies = function implies (key, value) {
-    argsert('<string|object> [array|number|string]', [key, value], arguments.length)
-
-    if (typeof key === 'object') {
-      Object.keys(key).forEach((k) => {
-        self.implies(k, key[k])
-      })
-    } else {
-      yargs.global(key)
-      if (!implied[key]) {
-        implied[key] = []
-      }
-      if (Array.isArray(value)) {
-        value.forEach((i) => self.implies(key, i))
-      } else {
-        implied[key].push(value)
-      }
-    }
-  }
-  self.getImplied = function getImplied () {
-    return implied
-  }
-
-  self.implications = function implications (argv) {
-    const implyFail = []
-
-    Object.keys(implied).forEach((key) => {
-      const origKey = key
-      ;(implied[key] || []).forEach((value) => {
-        let num
-        let key = origKey
-        const origValue = value
-
-        // convert string '1' to number 1
-        num = Number(key)
-        key = isNaN(num) ? key : num
-
-        if (typeof key === 'number') {
-          // check length of argv._
-          key = argv._.length >= key
-        } else if (key.match(/^--no-.+/)) {
-          // check if key doesn't exist
-          key = key.match(/^--no-(.+)/)[1]
-          key = !argv[key]
-        } else {
-          // check if key exists
-          key = argv[key]
-        }
-
-        num = Number(value)
-        value = isNaN(num) ? value : num
-
-        if (typeof value === 'number') {
-          value = argv._.length >= value
-        } else if (value.match(/^--no-.+/)) {
-          value = value.match(/^--no-(.+)/)[1]
-          value = !argv[value]
-        } else {
-          value = argv[value]
-        }
-        if (key && !value) {
-          implyFail.push(` ${origKey} -> ${origValue}`)
-        }
-      })
-    })
-
-    if (implyFail.length) {
-      let msg = `${__('Implications failed:')}\n`
-
-      implyFail.forEach((value) => {
-        msg += (value)
-      })
-
-      usage.fail(msg)
-    }
-  }
-
-  let conflicting = {}
-  self.conflicts = function conflicts (key, value) {
-    argsert('<string|object> [array|string]', [key, value], arguments.length)
-
-    if (typeof key === 'object') {
-      Object.keys(key).forEach((k) => {
-        self.conflicts(k, key[k])
-      })
-    } else {
-      yargs.global(key)
-      if (!conflicting[key]) {
-        conflicting[key] = []
-      }
-      if (Array.isArray(value)) {
-        value.forEach((i) => self.conflicts(key, i))
-      } else {
-        conflicting[key].push(value)
-      }
-    }
-  }
-  self.getConflicting = () => conflicting
-
-  self.conflicting = function conflictingFn (argv) {
-    Object.keys(argv).forEach((key) => {
-      if (conflicting[key]) {
-        conflicting[key].forEach((value) => {
-          // we default keys to 'undefined' that have been configured, we should not
-          // apply conflicting check unless they are a value other than 'undefined'.
-          if (value && argv[key] !== undefined && argv[value] !== undefined) {
-            usage.fail(__(`Arguments ${key} and ${value} are mutually exclusive`))
-          }
-        })
-      }
-    })
-  }
-
-  self.recommendCommands = function recommendCommands (cmd, potentialCommands) {
-    const distance = require('./levenshtein')
-    const threshold = 3 // if it takes more than three edits, let's move on.
-    potentialCommands = potentialCommands.sort((a, b) => b.length - a.length)
-
-    let recommended = null
-    let bestDistance = Infinity
-    for (let i = 0, candidate; (candidate = potentialCommands[i]) !== undefined; i++) {
-      const d = distance(cmd, candidate)
-      if (d <= threshold && d < bestDistance) {
-        bestDistance = d
-        recommended = candidate
-      }
-    }
-    if (recommended) usage.fail(__('Did you mean %s?', recommended))
-  }
-
-  self.reset = function reset (localLookup) {
-    implied = objFilter(implied, (k, v) => !localLookup[k])
-    conflicting = objFilter(conflicting, (k, v) => !localLookup[k])
-    checks = checks.filter(c => c.global)
-    return self
-  }
-
-  let frozen
-  self.freeze = function freeze () {
-    frozen = {}
-    frozen.implied = implied
-    frozen.checks = checks
-    frozen.conflicting = conflicting
-  }
-  self.unfreeze = function unfreeze () {
-    implied = frozen.implied
-    checks = frozen.checks
-    conflicting = frozen.conflicting
-    frozen = undefined
-  }
-
-  return self
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/lib/yerror.js
+++ /dev/null
@@ -1,11 +0,0 @@
-'use strict'
-function YError (msg) {
-  this.name = 'YError'
-  this.message = msg || 'yargs error'
-  Error.captureStackTrace(this, YError)
-}
-
-YError.prototype = Object.create(Error.prototype)
-YError.prototype.constructor = YError
-
-module.exports = YError
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/be.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Каманды:",
-  "Options:": "Опцыі:",
-  "Examples:": "Прыклады:",
-  "boolean": "булевы тып",
-  "count": "падлік",
-  "string": "радковы тып",
-  "number": "лік",
-  "array": "масіў",
-  "required": "неабходна",
-  "default:": "па змаўчанні:",
-  "choices:": "магчымасці:",
-  "aliases:": "аліасы:",
-  "generated-value": "згенераванае значэнне",
-  "Not enough non-option arguments: got %s, need at least %s": "Недастаткова неапцыйных аргументаў: ёсць %s, трэба як мінімум %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Занадта шмат неапцыйных аргументаў: ёсць %s, максімум дапушчальна %s",
-  "Missing argument value: %s": {
-    "one": "Не хапае значэння аргументу: %s",
-    "other": "Не хапае значэнняў аргументаў: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Не хапае неабходнага аргументу: %s",
-    "other": "Не хапае неабходных аргументаў: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Невядомы аргумент: %s",
-    "other": "Невядомыя аргументы: %s"
-  },
-  "Invalid values:": "Несапраўдныя значэння:",
-  "Argument: %s, Given: %s, Choices: %s": "Аргумент: %s, Дадзенае значэнне: %s, Магчымасці: %s",
-  "Argument check failed: %s": "Праверка аргументаў не ўдалася: %s",
-  "Implications failed:": "Дадзены аргумент патрабуе наступны дадатковы аргумент:",
-  "Not enough arguments following: %s": "Недастаткова наступных аргументаў: %s",
-  "Invalid JSON config file: %s": "Несапраўдны файл канфігурацыі JSON: %s",
-  "Path to JSON config file": "Шлях да файла канфігурацыі JSON",
-  "Show help": "Паказаць дапамогу",
-  "Show version number": "Паказаць нумар версіі",
-  "Did you mean %s?": "Вы мелі на ўвазе %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/de.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Kommandos:",
-  "Options:": "Optionen:",
-  "Examples:": "Beispiele:",
-  "boolean": "boolean",
-  "count": "Zähler",
-  "string": "string",
-  "number": "Zahl",
-  "array": "array",
-  "required": "erforderlich",
-  "default:": "Standard:",
-  "choices:": "Möglichkeiten:",
-  "aliases:": "Aliase:",
-  "generated-value": "Generierter-Wert",
-  "Not enough non-option arguments: got %s, need at least %s": "Nicht genügend Argumente ohne Optionen: %s vorhanden, mindestens %s benötigt",
-  "Too many non-option arguments: got %s, maximum of %s": "Zu viele Argumente ohne Optionen: %s vorhanden, maximal %s erlaubt",
-  "Missing argument value: %s": {
-    "one": "Fehlender Argumentwert: %s",
-    "other": "Fehlende Argumentwerte: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Fehlendes Argument: %s",
-    "other": "Fehlende Argumente: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Unbekanntes Argument: %s",
-    "other": "Unbekannte Argumente: %s"
-  },
-  "Invalid values:": "Unzulässige Werte:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Gegeben: %s, Möglichkeiten: %s",
-  "Argument check failed: %s": "Argumente-Check fehlgeschlagen: %s",
-  "Implications failed:": "Implikationen fehlgeschlagen:",
-  "Not enough arguments following: %s": "Nicht genügend Argumente nach: %s",
-  "Invalid JSON config file: %s": "Fehlerhafte JSON-Config Datei: %s",
-  "Path to JSON config file": "Pfad zur JSON-Config Datei",
-  "Show help": "Hilfe anzeigen",
-  "Show version number": "Version anzeigen",
-  "Did you mean %s?": "Meintest du %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/en.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "Commands:",
-  "Options:": "Options:",
-  "Examples:": "Examples:",
-  "boolean": "boolean",
-  "count": "count",
-  "string": "string",
-  "number": "number",
-  "array": "array",
-  "required": "required",
-  "default:": "default:",
-  "choices:": "choices:",
-  "aliases:": "aliases:",
-  "generated-value": "generated-value",
-  "Not enough non-option arguments: got %s, need at least %s": "Not enough non-option arguments: got %s, need at least %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Too many non-option arguments: got %s, maximum of %s",
-  "Missing argument value: %s": {
-    "one": "Missing argument value: %s",
-    "other": "Missing argument values: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Missing required argument: %s",
-    "other": "Missing required arguments: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Unknown argument: %s",
-    "other": "Unknown arguments: %s"
-  },
-  "Invalid values:": "Invalid values:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Given: %s, Choices: %s",
-  "Argument check failed: %s": "Argument check failed: %s",
-  "Implications failed:": "Implications failed:",
-  "Not enough arguments following: %s": "Not enough arguments following: %s",
-  "Invalid JSON config file: %s": "Invalid JSON config file: %s",
-  "Path to JSON config file": "Path to JSON config file",
-  "Show help": "Show help",
-  "Show version number": "Show version number",
-  "Did you mean %s?": "Did you mean %s?",
-  "Arguments %s and %s are mutually exclusive" : "Arguments %s and %s are mutually exclusive",
-  "Positionals:": "Positionals:",
-  "command": "command"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/es.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Comandos:",
-  "Options:": "Opciones:",
-  "Examples:": "Ejemplos:",
-  "boolean": "booleano",
-  "count": "cuenta",
-  "string": "cadena de caracteres",
-  "number": "número",
-  "array": "tabla",
-  "required": "requerido",
-  "default:": "defecto:",
-  "choices:": "selección:",
-  "aliases:": "alias:",
-  "generated-value": "valor-generado",
-  "Not enough non-option arguments: got %s, need at least %s": "Hacen falta argumentos no-opcionales: Número recibido %s, necesita por lo menos %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Demasiados argumentos no-opcionales: Número recibido %s, máximo es %s",
-  "Missing argument value: %s": {
-    "one": "Falta argumento: %s",
-    "other": "Faltan argumentos: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Falta argumento requerido: %s",
-    "other": "Faltan argumentos requeridos: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argumento desconocido: %s",
-    "other": "Argumentos desconocidos: %s"
-  },
-  "Invalid values:": "Valores inválidos:",
-  "Argument: %s, Given: %s, Choices: %s": "Argumento: %s, Recibido: %s, Seleccionados: %s",
-  "Argument check failed: %s": "Verificación de argumento ha fallado: %s",
-  "Implications failed:": "Implicaciones fallidas:",
-  "Not enough arguments following: %s": "No hay suficientes argumentos después de: %s",
-  "Invalid JSON config file: %s": "Archivo de configuración JSON inválido: %s",
-  "Path to JSON config file": "Ruta al archivo de configuración JSON",
-  "Show help": "Muestra ayuda",
-  "Show version number": "Muestra número de versión",
-  "Did you mean %s?": "Quisiste decir %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/fr.json
+++ /dev/null
@@ -1,37 +0,0 @@
-{
-  "Commands:": "Commandes:",
-  "Options:": "Options:",
-  "Examples:": "Exemples:",
-  "boolean": "booléen",
-  "count": "comptage",
-  "string": "chaine de caractère",
-  "number": "nombre",
-  "array": "tableau",
-  "required": "requis",
-  "default:": "défaut:",
-  "choices:": "choix:",
-  "generated-value": "valeur générée",
-  "Not enough non-option arguments: got %s, need at least %s": "Pas assez d'arguments non-option: reçu %s, besoin d'au moins %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Trop d'arguments non-option: reçu %s, maximum %s",
-  "Missing argument value: %s": {
-    "one": "Argument manquant: %s",
-    "other": "Arguments manquants: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Argument requis manquant: %s",
-    "other": "Arguments requis manquants: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argument inconnu: %s",
-    "other": "Arguments inconnus: %s"
-  },
-  "Invalid values:": "Valeurs invalides:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Donné: %s, Choix: %s",
-  "Argument check failed: %s": "Echec de la vérification de l'argument: %s",
-  "Implications failed:": "Implications échouées:",
-  "Not enough arguments following: %s": "Pas assez d'arguments suivant: %s",
-  "Invalid JSON config file: %s": "Fichier de configuration JSON invalide: %s",
-  "Path to JSON config file": "Chemin du fichier de configuration JSON",
-  "Show help": "Affiche de l'aide",
-  "Show version number": "Affiche le numéro de version"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/hi.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "आदेश:",
-  "Options:": "विकल्प:",
-  "Examples:": "उदाहरण:",
-  "boolean": "सत्यता",
-  "count": "संख्या",
-  "string": "वर्णों का तार ",
-  "number": "अंक",
-  "array": "सरणी",
-  "required": "आवश्यक",
-  "default:": "डिफॉल्ट:",
-  "choices:": "विकल्प:",
-  "aliases:": "उपनाम:",
-  "generated-value": "उत्पन्न-मूल्य",
-  "Not enough non-option arguments: got %s, need at least %s": "पर्याप्त गैर-विकल्प तर्क प्राप्त नहीं: %s प्राप्त, कम से कम %s की आवश्यकता है",
-  "Too many non-option arguments: got %s, maximum of %s": "बहुत सारे गैर-विकल्प तर्क: %s प्राप्त, अधिकतम %s मान्य",
-  "Missing argument value: %s": {
-    "one": "कुछ तर्को के मूल्य गुम हैं: %s",
-    "other": "कुछ तर्को के मूल्य गुम हैं: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "आवश्यक तर्क गुम हैं: %s",
-    "other": "आवश्यक तर्क गुम हैं: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "अज्ञात तर्क प्राप्त: %s",
-    "other": "अज्ञात तर्क प्राप्त: %s"
-  },
-  "Invalid values:": "अमान्य मूल्य:",
-  "Argument: %s, Given: %s, Choices: %s": "तर्क: %s, प्राप्त: %s, विकल्प: %s",
-  "Argument check failed: %s": "तर्क जांच विफल: %s",
-  "Implications failed:": "दिए गए तर्क के लिए अतिरिक्त तर्क की अपेक्षा है:",
-  "Not enough arguments following: %s": "निम्नलिखित के बाद पर्याप्त तर्क नहीं प्राप्त: %s",
-  "Invalid JSON config file: %s": "अमान्य JSON config फाइल: %s",
-  "Path to JSON config file": "JSON config फाइल का पथ",
-  "Show help": "सहायता दिखाएँ",
-  "Show version number": "Version संख्या दिखाएँ",
-  "Did you mean %s?": "क्या आपका मतलब है %s?",
-  "Arguments %s and %s are mutually exclusive" : "तर्क %s और %s परस्पर अनन्य हैं",
-  "Positionals:": "स्थानीय:",
-  "command": "आदेश"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/hu.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Parancsok:",
-  "Options:": "Opciók:",
-  "Examples:": "Példák:",
-  "boolean": "boolean",
-  "count": "számláló",
-  "string": "szöveg",
-  "number": "szám",
-  "array": "tömb",
-  "required": "kötelező",
-  "default:": "alapértelmezett:",
-  "choices:": "lehetőségek:",
-  "aliases:": "aliaszok:",
-  "generated-value": "generált-érték",
-  "Not enough non-option arguments: got %s, need at least %s": "Nincs elég nem opcionális argumentum: %s van, legalább %s kell",
-  "Too many non-option arguments: got %s, maximum of %s": "Túl sok nem opciánlis argumentum van: %s van, maximum %s lehet",
-  "Missing argument value: %s": {
-    "one": "Hiányzó argumentum érték: %s",
-    "other": "Hiányzó argumentum értékek: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Hiányzó kötelező argumentum: %s",
-    "other": "Hiányzó kötelező argumentumok: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Ismeretlen argumentum: %s",
-    "other": "Ismeretlen argumentumok: %s"
-  },
-  "Invalid values:": "Érvénytelen érték:",
-  "Argument: %s, Given: %s, Choices: %s": "Argumentum: %s, Megadott: %s, Lehetőségek: %s",
-  "Argument check failed: %s": "Argumentum ellenőrzés sikertelen: %s",
-  "Implications failed:": "Implikációk sikertelenek:",
-  "Not enough arguments following: %s": "Nem elég argumentum követi: %s",
-  "Invalid JSON config file: %s": "Érvénytelen JSON konfigurációs file: %s",
-  "Path to JSON config file": "JSON konfigurációs file helye",
-  "Show help": "Súgo megjelenítése",
-  "Show version number": "Verziószám megjelenítése",
-  "Did you mean %s?": "Erre gondoltál %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/id.json
+++ /dev/null
@@ -1,43 +0,0 @@
-
-{
-  "Commands:": "Perintah:",
-  "Options:": "Pilihan:",
-  "Examples:": "Contoh:",
-  "boolean": "boolean",
-  "count": "jumlah",
-  "number": "nomor",
-  "string": "string",
-  "array": "larik",
-  "required": "diperlukan",
-  "default:": "bawaan:",
-  "aliases:": "istilah lain:",
-  "choices:": "pilihan:",
-  "generated-value": "nilai-yang-dihasilkan",
-  "Not enough non-option arguments: got %s, need at least %s": "Argumen wajib kurang: hanya %s, minimal %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Terlalu banyak argumen wajib: ada %s, maksimal %s",
-  "Missing argument value: %s": {
-    "one": "Kurang argumen: %s",
-    "other": "Kurang argumen: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Kurang argumen wajib: %s",
-    "other": "Kurang argumen wajib: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argumen tak diketahui: %s",
-    "other": "Argumen tak diketahui: %s"
-  },
-  "Invalid values:": "Nilai-nilai tidak valid:",
-  "Argument: %s, Given: %s, Choices: %s": "Argumen: %s, Diberikan: %s, Pilihan: %s",
-  "Argument check failed: %s": "Pemeriksaan argument gagal: %s",
-  "Implications failed:": "Implikasi gagal:",
-  "Not enough arguments following: %s": "Kurang argumen untuk: %s",
-  "Invalid JSON config file: %s": "Berkas konfigurasi JSON tidak valid: %s",
-  "Path to JSON config file": "Alamat berkas konfigurasi JSON",
-  "Show help": "Lihat bantuan",
-  "Show version number": "Lihat nomor versi",
-  "Did you mean %s?": "Maksud Anda: %s?",
-  "Arguments %s and %s are mutually exclusive" : "Argumen %s dan %s saling eksklusif",
-  "Positionals:": "Posisional-posisional:",
-  "command": "perintah"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/it.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Comandi:",
-  "Options:": "Opzioni:",
-  "Examples:": "Esempi:",
-  "boolean": "booleano",
-  "count": "contatore",
-  "string": "stringa",
-  "number": "numero",
-  "array": "vettore",
-  "required": "richiesto",
-  "default:": "predefinito:",
-  "choices:": "scelte:",
-  "aliases:": "alias:",
-  "generated-value": "valore generato",
-  "Not enough non-option arguments: got %s, need at least %s": "Numero insufficiente di argomenti non opzione: inseriti %s, richiesti almeno %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Troppi argomenti non opzione: inseriti %s, massimo possibile %s",
-  "Missing argument value: %s": {
-    "one": "Argomento mancante: %s",
-    "other": "Argomenti mancanti: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Argomento richiesto mancante: %s",
-    "other": "Argomenti richiesti mancanti: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argomento sconosciuto: %s",
-    "other": "Argomenti sconosciuti: %s"
-  },
-  "Invalid values:": "Valori non validi:",
-  "Argument: %s, Given: %s, Choices: %s": "Argomento: %s, Richiesto: %s, Scelte: %s",
-  "Argument check failed: %s": "Controllo dell'argomento fallito: %s",
-  "Implications failed:": "Argomenti impliciti non soddisfatti:",
-  "Not enough arguments following: %s": "Argomenti insufficienti dopo: %s",
-  "Invalid JSON config file: %s": "File di configurazione JSON non valido: %s",
-  "Path to JSON config file": "Percorso del file di configurazione JSON",
-  "Show help": "Mostra la schermata di aiuto",
-  "Show version number": "Mostra il numero di versione",
-  "Did you mean %s?": "Intendi forse %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/ja.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "コマンド:",
-  "Options:": "オプション:",
-  "Examples:": "例:",
-  "boolean": "真偽",
-  "count": "カウント",
-  "string": "文字列",
-  "number": "数値",
-  "array": "配列",
-  "required": "必須",
-  "default:": "デフォルト:",
-  "choices:": "選択してください:",
-  "aliases:": "エイリアス:",
-  "generated-value": "生成された値",
-  "Not enough non-option arguments: got %s, need at least %s": "オプションではない引数が %s 個では不足しています。少なくとも %s 個の引数が必要です:",
-  "Too many non-option arguments: got %s, maximum of %s": "オプションではない引数が %s 個では多すぎます。最大で %s 個までです:",
-  "Missing argument value: %s": {
-    "one": "引数が見つかりません: %s",
-    "other": "引数が見つかりません: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "必須の引数が見つかりません: %s",
-    "other": "必須の引数が見つかりません: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "未知の引数です: %s",
-    "other": "未知の引数です: %s"
-  },
-  "Invalid values:": "不正な値です:",
-  "Argument: %s, Given: %s, Choices: %s": "引数は %s です。指定できるのは %s つです。選択してください: %s",
-  "Argument check failed: %s": "引数のチェックに失敗しました: %s",
-  "Implications failed:": "オプションの組み合わせで不正が生じました:",
-  "Not enough arguments following: %s": "次の引数が不足しています。: %s",
-  "Invalid JSON config file: %s": "JSONの設定ファイルが不正です: %s",
-  "Path to JSON config file": "JSONの設定ファイルまでのpath",
-  "Show help": "ヘルプを表示",
-  "Show version number": "バージョンを表示",
-  "Did you mean %s?": "もしかして %s?",
-  "Arguments %s and %s are mutually exclusive" : "引数 %s と %s は同時に指定できません",
-  "Positionals:": "位置:",
-  "command": "コマンド"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/ko.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "명령:",
-  "Options:": "옵션:",
-  "Examples:": "예시:",
-  "boolean": "여부",
-  "count": "개수",
-  "string": "문자열",
-  "number": "숫자",
-  "array": "배열",
-  "required": "필수",
-  "default:": "기본:",
-  "choices:": "선택:",
-  "aliases:": "별칭:",
-  "generated-value": "생성된 값",
-  "Not enough non-option arguments: got %s, need at least %s": "옵션이 아닌 인자가 충분치 않습니다: %s개를 받았지만, 적어도 %s개는 필요합니다",
-  "Too many non-option arguments: got %s, maximum of %s": "옵션이 아닌 인자가 너무 많습니다: %s개를 받았지만, %s개 이하여야 합니다",
-  "Missing argument value: %s": {
-    "one": "인자값을 받지 못했습니다: %s",
-    "other": "인자값들을 받지 못했습니다: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "필수 인자를 받지 못했습니다: %s",
-    "other": "필수 인자들을 받지 못했습니다: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "알 수 없는 인자입니다: %s",
-    "other": "알 수 없는 인자들입니다: %s"
-  },
-  "Invalid values:": "잘못된 값입니다:",
-  "Argument: %s, Given: %s, Choices: %s": "인자: %s, 입력받은 값: %s, 선택지: %s",
-  "Argument check failed: %s": "유효하지 않은 인자입니다: %s",
-  "Implications failed:": "옵션의 조합이 잘못되었습니다:",
-  "Not enough arguments following: %s": "인자가 충분하게 주어지지 않았습니다: %s",
-  "Invalid JSON config file: %s": "유효하지 않은 JSON 설정파일입니다: %s",
-  "Path to JSON config file": "JSON 설정파일 경로",
-  "Show help": "도움말을 보여줍니다",
-  "Show version number": "버전 넘버를 보여줍니다",
-  "Did you mean %s?": "찾고계신게 %s입니까?",
-  "Arguments %s and %s are mutually exclusive" : "%s와 %s 인자는 같이 사용될 수 없습니다",
-  "Positionals:": "위치:",
-  "command": "명령"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/nb.json
+++ /dev/null
@@ -1,37 +0,0 @@
-{
-  "Commands:": "Kommandoer:",
-  "Options:": "Alternativer:",
-  "Examples:": "Eksempler:",
-  "boolean": "boolsk",
-  "count": "antall",
-  "string": "streng",
-  "number": "nummer",
-  "array": "matrise",
-  "required": "obligatorisk",
-  "default:": "standard:",
-  "choices:": "valg:",
-  "generated-value": "generert-verdi",
-  "Not enough non-option arguments: got %s, need at least %s": "Ikke nok ikke-alternativ argumenter: fikk %s, trenger minst %s",
-  "Too many non-option arguments: got %s, maximum of %s": "For mange ikke-alternativ argumenter: fikk %s, maksimum %s",
-  "Missing argument value: %s": {
-    "one": "Mangler argument verdi: %s",
-    "other": "Mangler argument verdier: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Mangler obligatorisk argument: %s",
-    "other": "Mangler obligatoriske argumenter: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Ukjent argument: %s",
-    "other": "Ukjente argumenter: %s"
-  },
-  "Invalid values:": "Ugyldige verdier:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Gitt: %s, Valg: %s",
-  "Argument check failed: %s": "Argument sjekk mislyktes: %s",
-  "Implications failed:": "Konsekvensene mislyktes:",
-  "Not enough arguments following: %s": "Ikke nok følgende argumenter: %s",
-  "Invalid JSON config file: %s": "Ugyldig JSON konfigurasjonsfil: %s",
-  "Path to JSON config file": "Bane til JSON konfigurasjonsfil",
-  "Show help": "Vis hjelp",
-  "Show version number": "Vis versjonsnummer"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/nl.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "Opdrachten:",
-  "Options:": "Opties:",
-  "Examples:": "Voorbeelden:",
-  "boolean": "boolean",
-  "count": "aantal",
-  "string": "text",
-  "number": "nummer",
-  "array": "lijst",
-  "required": "verplicht",
-  "default:": "standaard:",
-  "choices:": "keuzes:",
-  "aliases:": "aliassen:",
-  "generated-value": "gegenereerde waarde",
-  "Not enough non-option arguments: got %s, need at least %s": "Niet genoeg non-optie argumenten. Gekregen: %s, minstens nodig: %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Te veel non-optie argumenten. Gekregen: %s, maximum: %s",
-  "Missing argument value: %s": {
-    "one": "Missing argument value: %s",
-    "other": "Missing argument values: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Missend verplichte argument: %s",
-    "other": "Missende verplichte argumenten: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Onbekend argument: %s",
-    "other": "Onbekende argumenten: %s"
-  },
-  "Invalid values:": "Ongeldige waardes:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Gegeven: %s, Keuzes: %s",
-  "Argument check failed: %s": "Argument check mislukt: %s",
-  "Implications failed:": "Implicaties mislukt:",
-  "Not enough arguments following: %s": "Niet genoeg argumenten na: %s",
-  "Invalid JSON config file: %s": "Ongeldig JSON configuratiebestand: %s",
-  "Path to JSON config file": "Pad naar JSON configuratiebestand",
-  "Show help": "Toon help",
-  "Show version number": "Toon versie nummer",
-  "Did you mean %s?": "Bedoelde u misschien %s?",
-  "Arguments %s and %s are mutually exclusive": "Argumenten %s en %s zijn onderling uitsluitend",
-  "Positionals:": "Positie-afhankelijke argumenten",
-  "command": "commando"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/nn.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Kommandoar:",
-  "Options:": "Alternativ:",
-  "Examples:": "Døme:",
-  "boolean": "boolsk",
-  "count": "mengd",
-  "string": "streng",
-  "number": "nummer",
-  "array": "matrise",
-  "required": "obligatorisk",
-  "default:": "standard:",
-  "choices:": "val:",
-  "generated-value": "generert-verdi",
-  "Not enough non-option arguments: got %s, need at least %s":
-    "Ikkje nok ikkje-alternativ argument: fekk %s, treng minst %s",
-  "Too many non-option arguments: got %s, maximum of %s":
-    "For mange ikkje-alternativ argument: fekk %s, maksimum %s",
-  "Missing argument value: %s": {
-    "one": "Manglar argumentverdi: %s",
-    "other": "Manglar argumentverdiar: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Manglar obligatorisk argument: %s",
-    "other": "Manglar obligatoriske argument: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Ukjent argument: %s",
-    "other": "Ukjende argument: %s"
-  },
-  "Invalid values:": "Ugyldige verdiar:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Gjeve: %s, Val: %s",
-  "Argument check failed: %s": "Argument sjekk mislukkast: %s",
-  "Implications failed:": "Konsekvensane mislukkast:",
-  "Not enough arguments following: %s": "Ikkje nok fylgande argument: %s",
-  "Invalid JSON config file: %s": "Ugyldig JSON konfigurasjonsfil: %s",
-  "Path to JSON config file": "Bane til JSON konfigurasjonsfil",
-  "Show help": "Vis hjelp",
-  "Show version number": "Vis versjonsnummer"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/pirate.json
+++ /dev/null
@@ -1,12 +0,0 @@
-{
-  "Commands:": "Choose yer command:",
-  "Options:": "Options for me hearties!",
-  "Examples:": "Ex. marks the spot:",
-  "required": "requi-yar-ed",
-  "Missing required argument: %s": {
-    "one": "Ye be havin' to set the followin' argument land lubber: %s",
-    "other": "Ye be havin' to set the followin' arguments land lubber: %s"
-  },
-  "Show help": "Parlay this here code of conduct",
-  "Show version number": "'Tis the version ye be askin' fer"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/pl.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "Polecenia:",
-  "Options:": "Opcje:",
-  "Examples:": "Przykłady:",
-  "boolean": "boolean",
-  "count": "ilość",
-  "string": "ciąg znaków",
-  "number": "liczba",
-  "array": "tablica",
-  "required": "wymagany",
-  "default:": "domyślny:",
-  "choices:": "dostępne:",
-  "aliases:": "aliasy:",
-  "generated-value": "wygenerowana-wartość",
-  "Not enough non-option arguments: got %s, need at least %s": "Niewystarczająca ilość argumentów: otrzymano %s, wymagane co najmniej %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Zbyt duża ilość argumentów: otrzymano %s, wymagane co najwyżej %s",
-  "Missing argument value: %s": {
-    "one": "Brak wartości dla argumentu: %s",
-    "other": "Brak wartości dla argumentów: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Brak wymaganego argumentu: %s",
-    "other": "Brak wymaganych argumentów: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Nieznany argument: %s",
-    "other": "Nieznane argumenty: %s"
-  },
-  "Invalid values:": "Nieprawidłowe wartości:",
-  "Argument: %s, Given: %s, Choices: %s": "Argument: %s, Otrzymano: %s, Dostępne: %s",
-  "Argument check failed: %s": "Weryfikacja argumentów nie powiodła się: %s",
-  "Implications failed:": "Założenia nie zostały spełnione:",
-  "Not enough arguments following: %s": "Niewystarczająca ilość argumentów następujących po: %s",
-  "Invalid JSON config file: %s": "Nieprawidłowy plik konfiguracyjny JSON: %s",
-  "Path to JSON config file": "Ścieżka do pliku konfiguracyjnego JSON",
-  "Show help": "Pokaż pomoc",
-  "Show version number": "Pokaż numer wersji",
-  "Did you mean %s?": "Czy chodziło Ci o %s?",
-  "Arguments %s and %s are mutually exclusive": "Argumenty %s i %s wzajemnie się wykluczają",
-  "Positionals:": "Pozycyjne:",
-  "command": "polecenie"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/pt.json
+++ /dev/null
@@ -1,38 +0,0 @@
-{
-  "Commands:": "Comandos:",
-  "Options:": "Opções:",
-  "Examples:": "Exemplos:",
-  "boolean": "boolean",
-  "count": "contagem",
-  "string": "cadeia de caracteres",
-  "number": "número",
-  "array": "arranjo",
-  "required": "requerido",
-  "default:": "padrão:",
-  "choices:": "escolhas:",
-  "generated-value": "valor-gerado",
-  "Not enough non-option arguments: got %s, need at least %s": "Argumentos insuficientes não opcionais: Argumento %s, necessário pelo menos %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Excesso de argumentos não opcionais: recebido %s, máximo de %s",
-  "Missing argument value: %s": {
-    "one": "Falta valor de argumento: %s",
-    "other": "Falta valores de argumento: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Falta argumento obrigatório: %s",
-    "other": "Faltando argumentos obrigatórios: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argumento desconhecido: %s",
-    "other": "Argumentos desconhecidos: %s"
-  },
-  "Invalid values:": "Valores inválidos:",
-  "Argument: %s, Given: %s, Choices: %s": "Argumento: %s, Dado: %s, Escolhas: %s",
-  "Argument check failed: %s": "Verificação de argumento falhou: %s",
-  "Implications failed:": "Implicações falharam:",
-  "Not enough arguments following: %s": "Insuficientes argumentos a seguir: %s",
-  "Invalid JSON config file: %s": "Arquivo de configuração em JSON esta inválido: %s",
-  "Path to JSON config file": "Caminho para o arquivo de configuração em JSON",
-  "Show help": "Mostra ajuda",
-  "Show version number": "Mostra número de versão",
-  "Arguments %s and %s are mutually exclusive" : "Argumentos %s e %s são mutualmente exclusivos"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/pt_BR.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-  "Commands:": "Comandos:",
-  "Options:": "Opções:",
-  "Examples:": "Exemplos:",
-  "boolean": "booleano",
-  "count": "contagem",
-  "string": "string",
-  "number": "número",
-  "array": "array",
-  "required": "obrigatório",
-  "default:": "padrão:",
-  "choices:": "opções:",
-  "aliases:": "sinônimos:",
-  "generated-value": "valor-gerado",
-  "Not enough non-option arguments: got %s, need at least %s": "Argumentos insuficientes: Argumento %s, necessário pelo menos %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Excesso de argumentos: recebido %s, máximo de %s",
-  "Missing argument value: %s": {
-    "one": "Falta valor de argumento: %s",
-    "other": "Falta valores de argumento: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Falta argumento obrigatório: %s",
-    "other": "Faltando argumentos obrigatórios: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Argumento desconhecido: %s",
-    "other": "Argumentos desconhecidos: %s"
-  },
-  "Invalid values:": "Valores inválidos:",
-  "Argument: %s, Given: %s, Choices: %s": "Argumento: %s, Dado: %s, Opções: %s",
-  "Argument check failed: %s": "Verificação de argumento falhou: %s",
-  "Implications failed:": "Implicações falharam:",
-  "Not enough arguments following: %s": "Argumentos insuficientes a seguir: %s",
-  "Invalid JSON config file: %s": "Arquivo JSON de configuração inválido: %s",
-  "Path to JSON config file": "Caminho para o arquivo JSON de configuração",
-  "Show help": "Exibe ajuda",
-  "Show version number": "Exibe a versão",
-  "Did you mean %s?": "Você quis dizer %s?",
-  "Arguments %s and %s are mutually exclusive" : "Argumentos %s e %s são mutualmente exclusivos",
-  "Positionals:": "Posicionais:",
-  "command": "comando"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/ru.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "Команды:",
-  "Options:": "Опции:",
-  "Examples:": "Примеры:",
-  "boolean": "булевый тип",
-  "count": "подсчет",
-  "string": "строковой тип",
-  "number": "число",
-  "array": "массив",
-  "required": "необходимо",
-  "default:": "по умолчанию:",
-  "choices:": "возможности:",
-  "aliases:": "алиасы:",
-  "generated-value": "генерированное значение",
-  "Not enough non-option arguments: got %s, need at least %s": "Недостаточно неопционных аргументов: есть %s, нужно как минимум %s",
-  "Too many non-option arguments: got %s, maximum of %s": "Слишком много неопционных аргументов: есть %s, максимум допустимо %s",
-  "Missing argument value: %s": {
-    "one": "Не хватает значения аргумента: %s",
-    "other": "Не хватает значений аргументов: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Не хватает необходимого аргумента: %s",
-    "other": "Не хватает необходимых аргументов: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Неизвестный аргумент: %s",
-    "other": "Неизвестные аргументы: %s"
-  },
-  "Invalid values:": "Недействительные значения:",
-  "Argument: %s, Given: %s, Choices: %s": "Аргумент: %s, Данное значение: %s, Возможности: %s",
-  "Argument check failed: %s": "Проверка аргументов не удалась: %s",
-  "Implications failed:": "Данный аргумент требует следующий дополнительный аргумент:",
-  "Not enough arguments following: %s": "Недостаточно следующих аргументов: %s",
-  "Invalid JSON config file: %s": "Недействительный файл конфигурации JSON: %s",
-  "Path to JSON config file": "Путь к файлу конфигурации JSON",
-  "Show help": "Показать помощь",
-  "Show version number": "Показать номер версии",
-  "Did you mean %s?": "Вы имели в виду %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/th.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-  "Commands:": "คอมมาน",
-  "Options:": "ออฟชั่น",
-  "Examples:": "ตัวอย่าง",
-  "boolean": "บูลีน",
-  "count": "นับ",
-  "string": "สตริง",
-  "number": "ตัวเลข",
-  "array": "อาเรย์",
-  "required": "จำเป็น",
-  "default:": "ค่าเริ่มต้น",
-  "choices:": "ตัวเลือก",
-  "aliases:": "เอเลียส",
-  "generated-value": "ค่าที่ถูกสร้างขึ้น",
-  "Not enough non-option arguments: got %s, need at least %s": "ใส่อาร์กิวเมนต์ไม่ครบตามจำนวนที่กำหนด: ใส่ค่ามาจำนวน %s ค่า, แต่ต้องการอย่างน้อย %s ค่า",
-  "Too many non-option arguments: got %s, maximum of %s": "ใส่อาร์กิวเมนต์เกินจำนวนที่กำหนด: ใส่ค่ามาจำนวน %s ค่า, แต่ต้องการมากที่สุด %s ค่า",
-  "Missing argument value: %s": {
-    "one": "ค่าอาร์กิวเมนต์ที่ขาดไป: %s",
-    "other": "ค่าอาร์กิวเมนต์ที่ขาดไป: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "อาร์กิวเมนต์จำเป็นที่ขาดไป: %s",
-    "other": "อาร์กิวเมนต์จำเป็นที่ขาดไป: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "อาร์กิวเมนต์ที่ไม่รู้จัก: %s",
-    "other": "อาร์กิวเมนต์ที่ไม่รู้จัก: %s"
-  },
-  "Invalid values:": "ค่าไม่ถูกต้อง:",
-  "Argument: %s, Given: %s, Choices: %s": "อาร์กิวเมนต์: %s, ได้รับ: %s, ตัวเลือก: %s",
-  "Argument check failed: %s": "ตรวจสอบพบอาร์กิวเมนต์ที่ไม่ถูกต้อง: %s",
-  "Implications failed:": "Implications ไม่สำเร็จ:",
-  "Not enough arguments following: %s": "ใส่อาร์กิวเมนต์ไม่ครบ: %s",
-  "Invalid JSON config file: %s": "ไฟล์คอนฟิค JSON ไม่ถูกต้อง: %s",
-  "Path to JSON config file": "พาทไฟล์คอนฟิค JSON",
-  "Show help": "ขอความช่วยเหลือ",
-  "Show version number": "แสดงตัวเลขเวอร์ชั่น",
-  "Did you mean %s?": "คุณหมายถึง %s?"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/tr.json
+++ /dev/null
@@ -1,41 +0,0 @@
-{
-  "Commands:": "Komutlar:",
-  "Options:": "Seçenekler:",
-  "Examples:": "Örnekler:",
-  "boolean": "boolean",
-  "count": "sayı",
-  "string": "string",
-  "number": "numara",
-  "array": "array",
-  "required": "zorunlu",
-  "default:": "varsayılan:",
-  "choices:": "seçimler:",
-  "aliases:": "takma adlar:",
-  "generated-value": "oluşturulan-değer",
-  "Not enough non-option arguments: got %s, need at least %s": "Seçenek dışı argümanlar yetersiz: %s bulundu, %s gerekli",
-  "Too many non-option arguments: got %s, maximum of %s": "Seçenek dışı argümanlar gereğinden fazla: %s bulundu, azami %s",
-  "Missing argument value: %s": {
-    "one": "Eksik argüman değeri: %s",
-    "other": "Eksik argüman değerleri: %s"
-  },
-  "Missing required argument: %s": {
-    "one": "Eksik zorunlu argüman: %s",
-    "other": "Eksik zorunlu argümanlar: %s"
-  },
-  "Unknown argument: %s": {
-    "one": "Bilinmeyen argüman: %s",
-    "other": "Bilinmeyen argümanlar: %s"
-  },
-  "Invalid values:": "Geçersiz değerler:",
-  "Argument: %s, Given: %s, Choices: %s": "Argüman: %s, Verilen: %s, Seçimler: %s",
-  "Argument check failed: %s": "Argüman kontrolü başarısız oldu: %s",
-  "Implications failed:": "Sonuçlar başarısız oldu:",
-  "Not enough arguments following: %s": "%s için yeterli argüman bulunamadı",
-  "Invalid JSON config file: %s": "Geçersiz JSON yapılandırma dosyası: %s",
-  "Path to JSON config file": "JSON yapılandırma dosya konumu",
-  "Show help": "Yardım detaylarını göster",
-  "Show version number": "Versiyon detaylarını göster",
-  "Did you mean %s?": "Bunu mu demek istediniz: %s?",
-  "Positionals:": "Sıralılar:",
-  "command": "komut"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/zh_CN.json
+++ /dev/null
@@ -1,41 +0,0 @@
-{
-  "Commands:": "命令：",
-  "Options:": "选项：",
-  "Examples:": "示例：",
-  "boolean": "布尔",
-  "count": "计数",
-  "string": "字符串",
-  "number": "数字",
-  "array": "数组",
-  "required": "必需",
-  "default:": "默认值:",
-  "choices:": "可选值:",
-  "generated-value": "生成的值",
-  "Not enough non-option arguments: got %s, need at least %s": "缺少 non-option 参数：传入了 %s 个, 至少需要 %s 个",
-  "Too many non-option arguments: got %s, maximum of %s": "non-option 参数过多：传入了 %s 个, 最大允许 %s 个",
-  "Missing argument value: %s": {
-    "one": "没有给此选项指定值：%s",
-    "other": "没有给这些选项指定值：%s"
-  },
-  "Missing required argument: %s": {
-    "one": "缺少必须的选项：%s",
-    "other": "缺少这些必须的选项：%s"
-  },
-  "Unknown argument: %s": {
-    "one": "无法识别的选项：%s",
-    "other": "无法识别这些选项：%s"
-  },
-  "Invalid values:": "无效的选项值：",
-  "Argument: %s, Given: %s, Choices: %s": "选项名称: %s, 传入的值: %s, 可选的值：%s",
-  "Argument check failed: %s": "选项值验证失败：%s",
-  "Implications failed:": "缺少依赖的选项：",
-  "Not enough arguments following: %s": "没有提供足够的值给此选项：%s",
-  "Invalid JSON config file: %s": "无效的 JSON 配置文件：%s",
-  "Path to JSON config file": "JSON 配置文件的路径",
-  "Show help": "显示帮助信息",
-  "Show version number": "显示版本号",
-  "Did you mean %s?": "是指 %s?",
-  "Arguments %s and %s are mutually exclusive" : "选项 %s 和 %s 是互斥的",
-  "Positionals:": "位置：",
-  "command": "命令"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/locales/zh_TW.json
+++ /dev/null
@@ -1,40 +0,0 @@
-{
-  "Commands:": "命令：",
-  "Options:": "選項：",
-  "Examples:": "例：",
-  "boolean": "布林",
-  "count": "次數",
-  "string": "字串",
-  "number": "數字",
-  "array": "陣列",
-  "required": "必須",
-  "default:": "預設值:",
-  "choices:": "可選值:",
-  "aliases:": "別名:",
-  "generated-value": "生成的值",
-  "Not enough non-option arguments: got %s, need at least %s": "non-option 引數不足：只傳入了 %s 個, 至少要 %s 個",
-  "Too many non-option arguments: got %s, maximum of %s": "non-option 引數過多：傳入了 %s 個, 但最多 %s 個",
-  "Missing argument value: %s": {
-    "one": "此引數無指定值：%s",
-    "other": "這些引數無指定值：%s"
-  },
-  "Missing required argument: %s": {
-    "one": "缺少必須的引數：%s",
-    "other": "缺少這些必須的引數：%s"
-  },
-  "Unknown argument: %s": {
-    "one": "未知的引數：%s",
-    "other": "未知的這些引數：%s"
-  },
-  "Invalid values:": "無效的選項值：",
-  "Argument: %s, Given: %s, Choices: %s": "引數名稱: %s, 傳入的值: %s, 可選的值：%s",
-  "Argument check failed: %s": "引數驗證失敗：%s",
-  "Implications failed:": "缺少依賴的選項：",
-  "Not enough arguments following: %s": "沒有提供足夠的值給此引數：%s",
-  "Invalid JSON config file: %s": "無效的 JSON 設置文件：%s",
-  "Path to JSON config file": "JSON 設置文件的路徑",
-  "Show help": "顯示說明",
-  "Show version number": "顯示版本",
-  "Did you mean %s?": "是指 %s?",
-  "Arguments %s and %s are mutually exclusive" : "引數 %s 和 %s 是互斥的"
-}
deleted file mode 100644
--- a/node_modules/record-node/node_modules/yargs/yargs.js
+++ /dev/null
@@ -1,1185 +0,0 @@
-'use strict'
-const argsert = require('./lib/argsert')
-const fs = require('fs')
-const Command = require('./lib/command')
-const Completion = require('./lib/completion')
-const Parser = require('yargs-parser')
-const path = require('path')
-const Usage = require('./lib/usage')
-const Validation = require('./lib/validation')
-const Y18n = require('y18n')
-const objFilter = require('./lib/obj-filter')
-const setBlocking = require('set-blocking')
-const applyExtends = require('./lib/apply-extends')
-const YError = require('./lib/yerror')
-
-exports = module.exports = Yargs
-function Yargs (processArgs, cwd, parentRequire) {
-  processArgs = processArgs || [] // handle calling yargs().
-
-  const self = {}
-  let command = null
-  let completion = null
-  let groups = {}
-  let output = ''
-  let preservedGroups = {}
-  let usage = null
-  let validation = null
-
-  const y18n = Y18n({
-    directory: path.resolve(__dirname, './locales'),
-    updateFiles: false
-  })
-
-  if (!cwd) cwd = process.cwd()
-
-  self.$0 = process.argv
-    .slice(0, 2)
-    .map((x, i) => {
-      // ignore the node bin, specify this in your
-      // bin file with #!/usr/bin/env node
-      if (i === 0 && /\b(node|iojs)(\.exe)?$/.test(x)) return
-      const b = rebase(cwd, x)
-      return x.match(/^(\/|([a-zA-Z]:)?\\)/) && b.length < x.length ? b : x
-    })
-    .join(' ').trim()
-
-  if (process.env._ !== undefined && process.argv[1] === process.env._) {
-    self.$0 = process.env._.replace(
-      `${path.dirname(process.execPath)}/`, ''
-    )
-  }
-
-  // use context object to keep track of resets, subcommand execution, etc
-  // submodules should modify and check the state of context as necessary
-  const context = { resets: -1, commands: [], fullCommands: [], files: [] }
-  self.getContext = () => context
-
-  // puts yargs back into an initial state. any keys
-  // that have been set to "global" will not be reset
-  // by this action.
-  let options
-  self.resetOptions = self.reset = function resetOptions (aliases) {
-    context.resets++
-    aliases = aliases || {}
-    options = options || {}
-    // put yargs back into an initial state, this
-    // logic is used to build a nested command
-    // hierarchy.
-    const tmpOptions = {}
-    tmpOptions.local = options.local ? options.local : []
-    tmpOptions.configObjects = options.configObjects ? options.configObjects : []
-
-    // if a key has been explicitly set as local,
-    // we should reset it before passing options to command.
-    const localLookup = {}
-    tmpOptions.local.forEach((l) => {
-      localLookup[l] = true
-      ;(aliases[l] || []).forEach((a) => {
-        localLookup[a] = true
-      })
-    })
-
-    // preserve all groups not set to local.
-    preservedGroups = Object.keys(groups).reduce((acc, groupName) => {
-      const keys = groups[groupName].filter(key => !(key in localLookup))
-      if (keys.length > 0) {
-        acc[groupName] = keys
-      }
-      return acc
-    }, {})
-    // groups can now be reset
-    groups = {}
-
-    const arrayOptions = [
-      'array', 'boolean', 'string', 'skipValidation',
-      'count', 'normalize', 'number',
-      'hiddenOptions'
-    ]
-
-    const objectOptions = [
-      'narg', 'key', 'alias', 'default', 'defaultDescription',
-      'config', 'choices', 'demandedOptions', 'demandedCommands', 'coerce'
-    ]
-
-    arrayOptions.forEach((k) => {
-      tmpOptions[k] = (options[k] || []).filter(k => !localLookup[k])
-    })
-
-    objectOptions.forEach((k) => {
-      tmpOptions[k] = objFilter(options[k], (k, v) => !localLookup[k])
-    })
-
-    tmpOptions.envPrefix = options.envPrefix
-    options = tmpOptions
-
-    // if this is the first time being executed, create
-    // instances of all our helpers -- otherwise just reset.
-    usage = usage ? usage.reset(localLookup) : Usage(self, y18n)
-    validation = validation ? validation.reset(localLookup) : Validation(self, usage, y18n)
-    command = command ? command.reset() : Command(self, usage, validation)
-    if (!completion) completion = Completion(self, usage, command)
-
-    completionCommand = null
-    output = ''
-    exitError = null
-    hasOutput = false
-    self.parsed = false
-
-    return self
-  }
-  self.resetOptions()
-
-  // temporary hack: allow "freezing" of reset-able state for parse(msg, cb)
-  let frozen
-  function freeze () {
-    frozen = {}
-    frozen.options = options
-    frozen.configObjects = options.configObjects.slice(0)
-    frozen.exitProcess = exitProcess
-    frozen.groups = groups
-    usage.freeze()
-    validation.freeze()
-    command.freeze()
-    frozen.strict = strict
-    frozen.completionCommand = completionCommand
-    frozen.output = output
-    frozen.exitError = exitError
-    frozen.hasOutput = hasOutput
-    frozen.parsed = self.parsed
-  }
-  function unfreeze () {
-    options = frozen.options
-    options.configObjects = frozen.configObjects
-    exitProcess = frozen.exitProcess
-    groups = frozen.groups
-    output = frozen.output
-    exitError = frozen.exitError
-    hasOutput = frozen.hasOutput
-    self.parsed = frozen.parsed
-    usage.unfreeze()
-    validation.unfreeze()
-    command.unfreeze()
-    strict = frozen.strict
-    completionCommand = frozen.completionCommand
-    parseFn = null
-    parseContext = null
-    frozen = undefined
-  }
-
-  self.boolean = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('boolean', keys)
-    return self
-  }
-
-  self.array = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('array', keys)
-    return self
-  }
-
-  self.number = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('number', keys)
-    return self
-  }
-
-  self.normalize = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('normalize', keys)
-    return self
-  }
-
-  self.count = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('count', keys)
-    return self
-  }
-
-  self.string = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('string', keys)
-    return self
-  }
-
-  self.requiresArg = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintObject(self.nargs, false, 'narg', keys, 1)
-    return self
-  }
-
-  self.skipValidation = function (keys) {
-    argsert('<array|string>', [keys], arguments.length)
-    populateParserHintArray('skipValidation', keys)
-    return self
-  }
-
-  function populateParserHintArray (type, keys, value) {
-    keys = [].concat(keys)
-    keys.forEach((key) => {
-      options[type].push(key)
-    })
-  }
-
-  self.nargs = function (key, value) {
-    argsert('<string|object|array> [number]', [key, value], arguments.length)
-    populateParserHintObject(self.nargs, false, 'narg', key, value)
-    return self
-  }
-
-  self.choices = function (key, value) {
-    argsert('<object|string|array> [string|array]', [key, value], arguments.length)
-    populateParserHintObject(self.choices, true, 'choices', key, value)
-    return self
-  }
-
-  self.alias = function (key, value) {
-    argsert('<object|string|array> [string|array]', [key, value], arguments.length)
-    populateParserHintObject(self.alias, true, 'alias', key, value)
-    return self
-  }
-
-  // TODO: actually deprecate self.defaults.
-  self.default = self.defaults = function (key, value, defaultDescription) {
-    argsert('<object|string|array> [*] [string]', [key, value, defaultDescription], arguments.length)
-    if (defaultDescription) options.defaultDescription[key] = defaultDescription
-    if (typeof value === 'function') {
-      if (!options.defaultDescription[key]) options.defaultDescription[key] = usage.functionDescription(value)
-      value = value.call()
-    }
-    populateParserHintObject(self.default, false, 'default', key, value)
-    return self
-  }
-
-  self.describe = function (key, desc) {
-    argsert('<object|string|array> [string]', [key, desc], arguments.length)
-    populateParserHintObject(self.describe, false, 'key', key, true)
-    usage.describe(key, desc)
-    return self
-  }
-
-  self.demandOption = function (keys, msg) {
-    argsert('<object|string|array> [string]', [keys, msg], arguments.length)
-    populateParserHintObject(self.demandOption, false, 'demandedOptions', keys, msg)
-    return self
-  }
-
-  self.coerce = function (keys, value) {
-    argsert('<object|string|array> [function]', [keys, value], arguments.length)
-    populateParserHintObject(self.coerce, false, 'coerce', keys, value)
-    return self
-  }
-
-  function populateParserHintObject (builder, isArray, type, key, value) {
-    if (Array.isArray(key)) {
-      // an array of keys with one value ['x', 'y', 'z'], function parse () {}
-      const temp = {}
-      key.forEach((k) => {
-        temp[k] = value
-      })
-      builder(temp)
-    } else if (typeof key === 'object') {
-      // an object of key value pairs: {'x': parse () {}, 'y': parse() {}}
-      Object.keys(key).forEach((k) => {
-        builder(k, key[k])
-      })
-    } else {
-      // a single key value pair 'x', parse() {}
-      if (isArray) {
-        options[type][key] = (options[type][key] || []).concat(value)
-      } else {
-        options[type][key] = value
-      }
-    }
-  }
-
-  function deleteFromParserHintObject (optionKey) {
-    // delete from all parsing hints:
-    // boolean, array, key, alias, etc.
-    Object.keys(options).forEach((hintKey) => {
-      const hint = options[hintKey]
-      if (Array.isArray(hint)) {
-        if (~hint.indexOf(optionKey)) hint.splice(hint.indexOf(optionKey), 1)
-      } else if (typeof hint === 'object') {
-        delete hint[optionKey]
-      }
-    })
-    // now delete the description from usage.js.
-    delete usage.getDescriptions()[optionKey]
-  }
-
-  self.config = function config (key, msg, parseFn) {
-    argsert('[object|string] [string|function] [function]', [key, msg, parseFn], arguments.length)
-    // allow a config object to be provided directly.
-    if (typeof key === 'object') {
-      key = applyExtends(key, cwd)
-      options.configObjects = (options.configObjects || []).concat(key)
-      return self
-    }
-
-    // allow for a custom parsing function.
-    if (typeof msg === 'function') {
-      parseFn = msg
-      msg = null
-    }
-
-    key = key || 'config'
-    self.describe(key, msg || usage.deferY18nLookup('Path to JSON config file'))
-    ;(Array.isArray(key) ? key : [key]).forEach((k) => {
-      options.config[k] = parseFn || true
-    })
-
-    return self
-  }
-
-  self.example = function (cmd, description) {
-    argsert('<string> [string]', [cmd, description], arguments.length)
-    usage.example(cmd, description)
-    return self
-  }
-
-  self.command = function (cmd, description, builder, handler, middlewares) {
-    argsert('<string|array|object> [string|boolean] [function|object] [function] [array]', [cmd, description, builder, handler, middlewares], arguments.length)
-    command.addHandler(cmd, description, builder, handler, middlewares)
-    return self
-  }
-
-  self.commandDir = function (dir, opts) {
-    argsert('<string> [object]', [dir, opts], arguments.length)
-    const req = parentRequire || require
-    command.addDirectory(dir, self.getContext(), req, require('get-caller-file')(), opts)
-    return self
-  }
-
-  // TODO: deprecate self.demand in favor of
-  // .demandCommand() .demandOption().
-  self.demand = self.required = self.require = function demand (keys, max, msg) {
-    // you can optionally provide a 'max' key,
-    // which will raise an exception if too many '_'
-    // options are provided.
-    if (Array.isArray(max)) {
-      max.forEach((key) => {
-        self.demandOption(key, msg)
-      })
-      max = Infinity
-    } else if (typeof max !== 'number') {
-      msg = max
-      max = Infinity
-    }
-
-    if (typeof keys === 'number') {
-      self.demandCommand(keys, max, msg, msg)
-    } else if (Array.isArray(keys)) {
-      keys.forEach((key) => {
-        self.demandOption(key, msg)
-      })
-    } else {
-      if (typeof msg === 'string') {
-        self.demandOption(keys, msg)
-      } else if (msg === true || typeof msg === 'undefined') {
-        self.demandOption(keys)
-      }
-    }
-
-    return self
-  }
-
-  self.demandCommand = function demandCommand (min, max, minMsg, maxMsg) {
-    argsert('[number] [number|string] [string|null|undefined] [string|null|undefined]', [min, max, minMsg, maxMsg], arguments.length)
-
-    if (typeof min === 'undefined') min = 1
-
-    if (typeof max !== 'number') {
-      minMsg = max
-      max = Infinity
-    }
-
-    self.global('_', false)
-
-    options.demandedCommands._ = {
-      min,
-      max,
-      minMsg,
-      maxMsg
-    }
-
-    return self
-  }
-
-  self.getDemandedOptions = () => {
-    argsert([], 0)
-    return options.demandedOptions
-  }
-
-  self.getDemandedCommands = () => {
-    argsert([], 0)
-    return options.demandedCommands
-  }
-
-  self.implies = function (key, value) {
-    argsert('<string|object> [number|string|array]', [key, value], arguments.length)
-    validation.implies(key, value)
-    return self
-  }
-
-  self.conflicts = function (key1, key2) {
-    argsert('<string|object> [string|array]', [key1, key2], arguments.length)
-    validation.conflicts(key1, key2)
-    return self
-  }
-
-  self.usage = function (msg, description, builder, handler) {
-    argsert('<string|null|undefined> [string|boolean] [function|object] [function]', [msg, description, builder, handler], arguments.length)
-
-    if (description !== undefined) {
-      // .usage() can be used as an alias for defining
-      // a default command.
-      if ((msg || '').match(/^\$0( |$)/)) {
-        return self.command(msg, description, builder, handler)
-      } else {
-        throw new YError('.usage() description must start with $0 if being used as alias for .command()')
-      }
-    } else {
-      usage.usage(msg)
-      return self
-    }
-  }
-
-  self.epilogue = self.epilog = function (msg) {
-    argsert('<string>', [msg], arguments.length)
-    usage.epilog(msg)
-    return self
-  }
-
-  self.fail = function (f) {
-    argsert('<function>', [f], arguments.length)
-    usage.failFn(f)
-    return self
-  }
-
-  self.check = function (f, _global) {
-    argsert('<function> [boolean]', [f, _global], arguments.length)
-    validation.check(f, _global !== false)
-    return self
-  }
-
-  self.global = function global (globals, global) {
-    argsert('<string|array> [boolean]', [globals, global], arguments.length)
-    globals = [].concat(globals)
-    if (global !== false) {
-      options.local = options.local.filter(l => globals.indexOf(l) === -1)
-    } else {
-      globals.forEach((g) => {
-        if (options.local.indexOf(g) === -1) options.local.push(g)
-      })
-    }
-    return self
-  }
-
-  self.pkgConf = function pkgConf (key, rootPath) {
-    argsert('<string> [string]', [key, rootPath], arguments.length)
-    let conf = null
-    // prefer cwd to require-main-filename in this method
-    // since we're looking for e.g. "nyc" config in nyc consumer
-    // rather than "yargs" config in nyc (where nyc is the main filename)
-    const obj = pkgUp(rootPath || cwd)
-
-    // If an object exists in the key, add it to options.configObjects
-    if (obj[key] && typeof obj[key] === 'object') {
-      conf = applyExtends(obj[key], rootPath || cwd)
-      options.configObjects = (options.configObjects || []).concat(conf)
-    }
-
-    return self
-  }
-
-  const pkgs = {}
-  function pkgUp (rootPath) {
-    const npath = rootPath || '*'
-    if (pkgs[npath]) return pkgs[npath]
-    const findUp = require('find-up')
-
-    let obj = {}
-    try {
-      let startDir = rootPath || require('require-main-filename')(parentRequire || require)
-
-      // When called in an environment that lacks require.main.filename, such as a jest test runner,
-      // startDir is already process.cwd(), and should not be shortened.
-      // Whether or not it is _actually_ a directory (e.g., extensionless bin) is irrelevant, find-up handles it.
-      if (!rootPath && path.extname(startDir)) {
-        startDir = path.dirname(startDir)
-      }
-
-      const pkgJsonPath = findUp.sync('package.json', {
-        cwd: startDir
-      })
-      obj = JSON.parse(fs.readFileSync(pkgJsonPath))
-    } catch (noop) {}
-
-    pkgs[npath] = obj || {}
-    return pkgs[npath]
-  }
-
-  let parseFn = null
-  let parseContext = null
-  self.parse = function parse (args, shortCircuit, _parseFn) {
-    argsert('[string|array] [function|boolean|object] [function]', [args, shortCircuit, _parseFn], arguments.length)
-    if (typeof args === 'undefined') args = processArgs
-
-    // a context object can optionally be provided, this allows
-    // additional information to be passed to a command handler.
-    if (typeof shortCircuit === 'object') {
-      parseContext = shortCircuit
-      shortCircuit = _parseFn
-    }
-
-    // by providing a function as a second argument to
-    // parse you can capture output that would otherwise
-    // default to printing to stdout/stderr.
-    if (typeof shortCircuit === 'function') {
-      parseFn = shortCircuit
-      shortCircuit = null
-    }
-    // completion short-circuits the parsing process,
-    // skipping validation, etc.
-    if (!shortCircuit) processArgs = args
-
-    freeze()
-    if (parseFn) exitProcess = false
-
-    const parsed = self._parseArgs(args, shortCircuit)
-    if (parseFn) parseFn(exitError, parsed, output)
-    unfreeze()
-
-    return parsed
-  }
-
-  self._getParseContext = () => parseContext || {}
-
-  self._hasParseCallback = () => !!parseFn
-
-  self.option = self.options = function option (key, opt) {
-    argsert('<string|object> [object]', [key, opt], arguments.length)
-    if (typeof key === 'object') {
-      Object.keys(key).forEach((k) => {
-        self.options(k, key[k])
-      })
-    } else {
-      if (typeof opt !== 'object') {
-        opt = {}
-      }
-
-      options.key[key] = true // track manually set keys.
-
-      if (opt.alias) self.alias(key, opt.alias)
-
-      const demand = opt.demand || opt.required || opt.require
-
-      // deprecated, use 'demandOption' instead
-      if (demand) {
-        self.demand(key, demand)
-      }
-
-      if (opt.demandOption) {
-        self.demandOption(key, typeof opt.demandOption === 'string' ? opt.demandOption : undefined)
-      }
-
-      if ('conflicts' in opt) {
-        self.conflicts(key, opt.conflicts)
-      }
-
-      if ('default' in opt) {
-        self.default(key, opt.default)
-      }
-
-      if ('implies' in opt) {
-        self.implies(key, opt.implies)
-      }
-
-      if ('nargs' in opt) {
-        self.nargs(key, opt.nargs)
-      }
-
-      if (opt.config) {
-        self.config(key, opt.configParser)
-      }
-
-      if (opt.normalize) {
-        self.normalize(key)
-      }
-
-      if ('choices' in opt) {
-        self.choices(key, opt.choices)
-      }
-
-      if ('coerce' in opt) {
-        self.coerce(key, opt.coerce)
-      }
-
-      if ('group' in opt) {
-        self.group(key, opt.group)
-      }
-
-      if (opt.boolean || opt.type === 'boolean') {
-        self.boolean(key)
-        if (opt.alias) self.boolean(opt.alias)
-      }
-
-      if (opt.array || opt.type === 'array') {
-        self.array(key)
-        if (opt.alias) self.array(opt.alias)
-      }
-
-      if (opt.number || opt.type === 'number') {
-        self.number(key)
-        if (opt.alias) self.number(opt.alias)
-      }
-
-      if (opt.string || opt.type === 'string') {
-        self.string(key)
-        if (opt.alias) self.string(opt.alias)
-      }
-
-      if (opt.count || opt.type === 'count') {
-        self.count(key)
-      }
-
-      if (typeof opt.global === 'boolean') {
-        self.global(key, opt.global)
-      }
-
-      if (opt.defaultDescription) {
-        options.defaultDescription[key] = opt.defaultDescription
-      }
-
-      if (opt.skipValidation) {
-        self.skipValidation(key)
-      }
-
-      const desc = opt.describe || opt.description || opt.desc
-      self.describe(key, desc)
-      if (opt.hidden) {
-        self.hide(key)
-      }
-
-      if (opt.requiresArg) {
-        self.requiresArg(key)
-      }
-    }
-
-    return self
-  }
-  self.getOptions = () => options
-
-  self.positional = function (key, opts) {
-    argsert('<string> <object>', [key, opts], arguments.length)
-    if (context.resets === 0) {
-      throw new YError(".positional() can only be called in a command's builder function")
-    }
-
-    // .positional() only supports a subset of the configuration
-    // options availble to .option().
-    const supportedOpts = ['default', 'implies', 'normalize',
-      'choices', 'conflicts', 'coerce', 'type', 'describe',
-      'desc', 'description', 'alias']
-    opts = objFilter(opts, (k, v) => {
-      let accept = supportedOpts.indexOf(k) !== -1
-      // type can be one of string|number|boolean.
-      if (k === 'type' && ['string', 'number', 'boolean'].indexOf(v) === -1) accept = false
-      return accept
-    })
-
-    // copy over any settings that can be inferred from the command string.
-    const fullCommand = context.fullCommands[context.fullCommands.length - 1]
-    const parseOptions = fullCommand ? command.cmdToParseOptions(fullCommand) : {
-      array: [],
-      alias: {},
-      default: {},
-      demand: {}
-    }
-    Object.keys(parseOptions).forEach((pk) => {
-      if (Array.isArray(parseOptions[pk])) {
-        if (parseOptions[pk].indexOf(key) !== -1) opts[pk] = true
-      } else {
-        if (parseOptions[pk][key] && !(pk in opts)) opts[pk] = parseOptions[pk][key]
-      }
-    })
-    self.group(key, usage.getPositionalGroupName())
-    return self.option(key, opts)
-  }
-
-  self.group = function group (opts, groupName) {
-    argsert('<string|array> <string>', [opts, groupName], arguments.length)
-    const existing = preservedGroups[groupName] || groups[groupName]
-    if (preservedGroups[groupName]) {
-      // we now only need to track this group name in groups.
-      delete preservedGroups[groupName]
-    }
-
-    const seen = {}
-    groups[groupName] = (existing || []).concat(opts).filter((key) => {
-      if (seen[key]) return false
-      return (seen[key] = true)
-    })
-    return self
-  }
-  // combine explicit and preserved groups. explicit groups should be first
-  self.getGroups = () => Object.assign({}, groups, preservedGroups)
-
-  // as long as options.envPrefix is not undefined,
-  // parser will apply env vars matching prefix to argv
-  self.env = function (prefix) {
-    argsert('[string|boolean]', [prefix], arguments.length)
-    if (prefix === false) options.envPrefix = undefined
-    else options.envPrefix = prefix || ''
-    return self
-  }
-
-  self.wrap = function (cols) {
-    argsert('<number|null|undefined>', [cols], arguments.length)
-    usage.wrap(cols)
-    return self
-  }
-
-  let strict = false
-  self.strict = function (enabled) {
-    argsert('[boolean]', [enabled], arguments.length)
-    strict = enabled !== false
-    return self
-  }
-  self.getStrict = () => strict
-
-  self.showHelp = function (level) {
-    argsert('[string|function]', [level], arguments.length)
-    if (!self.parsed) self._parseArgs(processArgs) // run parser, if it has not already been executed.
-    if (command.hasDefaultCommand()) {
-      context.resets++ // override the restriction on top-level positoinals.
-      command.runDefaultBuilderOn(self, true)
-    }
-    usage.showHelp(level)
-    return self
-  }
-
-  let versionOpt = null
-  self.version = function version (opt, msg, ver) {
-    const defaultVersionOpt = 'version'
-    argsert('[boolean|string] [string] [string]', [opt, msg, ver], arguments.length)
-
-    // nuke the key previously configured
-    // to return version #.
-    if (versionOpt) {
-      deleteFromParserHintObject(versionOpt)
-      usage.version(undefined)
-      versionOpt = null
-    }
-
-    if (arguments.length === 0) {
-      ver = guessVersion()
-      opt = defaultVersionOpt
-    } else if (arguments.length === 1) {
-      if (opt === false) { // disable default 'version' key.
-        return self
-      }
-      ver = opt
-      opt = defaultVersionOpt
-    } else if (arguments.length === 2) {
-      ver = msg
-      msg = null
-    }
-
-    versionOpt = typeof opt === 'string' ? opt : defaultVersionOpt
-    msg = msg || usage.deferY18nLookup('Show version number')
-
-    usage.version(ver || undefined)
-    self.boolean(versionOpt)
-    self.describe(versionOpt, msg)
-    return self
-  }
-
-  function guessVersion () {
-    const obj = pkgUp()
-
-    return obj.version || 'unknown'
-  }
-
-  let helpOpt = null
-  self.addHelpOpt = self.help = function addHelpOpt (opt, msg) {
-    const defaultHelpOpt = 'help'
-    argsert('[string|boolean] [string]', [opt, msg], arguments.length)
-
-    // nuke the key previously configured
-    // to return help.
-    if (helpOpt) {
-      deleteFromParserHintObject(helpOpt)
-      helpOpt = null
-    }
-
-    if (arguments.length === 1) {
-      if (opt === false) return self
-    }
-
-    // use arguments, fallback to defaults for opt and msg
-    helpOpt = typeof opt === 'string' ? opt : defaultHelpOpt
-    self.boolean(helpOpt)
-    self.describe(helpOpt, msg || usage.deferY18nLookup('Show help'))
-    return self
-  }
-
-  const defaultShowHiddenOpt = 'show-hidden'
-  options.showHiddenOpt = defaultShowHiddenOpt
-  self.addShowHiddenOpt = self.showHidden = function addShowHiddenOpt (opt, msg) {
-    argsert('[string|boolean] [string]', [opt, msg], arguments.length)
-
-    if (arguments.length === 1) {
-      if (opt === false) return self
-    }
-
-    const showHiddenOpt = typeof opt === 'string' ? opt : defaultShowHiddenOpt
-    self.boolean(showHiddenOpt)
-    self.describe(showHiddenOpt, msg || usage.deferY18nLookup('Show hidden options'))
-    options.showHiddenOpt = showHiddenOpt
-    return self
-  }
-
-  self.hide = function hide (key) {
-    argsert('<string|object>', [key], arguments.length)
-    options.hiddenOptions.push(key)
-    return self
-  }
-
-  self.showHelpOnFail = function showHelpOnFail (enabled, message) {
-    argsert('[boolean|string] [string]', [enabled, message], arguments.length)
-    usage.showHelpOnFail(enabled, message)
-    return self
-  }
-
-  var exitProcess = true
-  self.exitProcess = function (enabled) {
-    argsert('[boolean]', [enabled], arguments.length)
-    if (typeof enabled !== 'boolean') {
-      enabled = true
-    }
-    exitProcess = enabled
-    return self
-  }
-  self.getExitProcess = () => exitProcess
-
-  var completionCommand = null
-  self.completion = function (cmd, desc, fn) {
-    argsert('[string] [string|boolean|function] [function]', [cmd, desc, fn], arguments.length)
-
-    // a function to execute when generating
-    // completions can be provided as the second
-    // or third argument to completion.
-    if (typeof desc === 'function') {
-      fn = desc
-      desc = null
-    }
-
-    // register the completion command.
-    completionCommand = cmd || 'completion'
-    if (!desc && desc !== false) {
-      desc = 'generate bash completion script'
-    }
-    self.command(completionCommand, desc)
-
-    // a function can be provided
-    if (fn) completion.registerFunction(fn)
-
-    return self
-  }
-
-  self.showCompletionScript = function ($0) {
-    argsert('[string]', [$0], arguments.length)
-    $0 = $0 || self.$0
-    _logger.log(completion.generateCompletionScript($0, completionCommand))
-    return self
-  }
-
-  self.getCompletion = function (args, done) {
-    argsert('<array> <function>', [args, done], arguments.length)
-    completion.getCompletion(args, done)
-  }
-
-  self.locale = function (locale) {
-    argsert('[string]', [locale], arguments.length)
-    if (arguments.length === 0) {
-      guessLocale()
-      return y18n.getLocale()
-    }
-    detectLocale = false
-    y18n.setLocale(locale)
-    return self
-  }
-
-  self.updateStrings = self.updateLocale = function (obj) {
-    argsert('<object>', [obj], arguments.length)
-    detectLocale = false
-    y18n.updateLocale(obj)
-    return self
-  }
-
-  let detectLocale = true
-  self.detectLocale = function (detect) {
-    argsert('<boolean>', [detect], arguments.length)
-    detectLocale = detect
-    return self
-  }
-  self.getDetectLocale = () => detectLocale
-
-  var hasOutput = false
-  var exitError = null
-  // maybe exit, always capture
-  // context about why we wanted to exit.
-  self.exit = (code, err) => {
-    hasOutput = true
-    exitError = err
-    if (exitProcess) process.exit(code)
-  }
-
-  // we use a custom logger that buffers output,
-  // so that we can print to non-CLIs, e.g., chat-bots.
-  const _logger = {
-    log () {
-      const args = []
-      for (let i = 0; i < arguments.length; i++) args.push(arguments[i])
-      if (!self._hasParseCallback()) console.log.apply(console, args)
-      hasOutput = true
-      if (output.length) output += '\n'
-      output += args.join(' ')
-    },
-    error () {
-      const args = []
-      for (let i = 0; i < arguments.length; i++) args.push(arguments[i])
-      if (!self._hasParseCallback()) console.error.apply(console, args)
-      hasOutput = true
-      if (output.length) output += '\n'
-      output += args.join(' ')
-    }
-  }
-  self._getLoggerInstance = () => _logger
-  // has yargs output an error our help
-  // message in the current execution context.
-  self._hasOutput = () => hasOutput
-
-  self._setHasOutput = () => {
-    hasOutput = true
-  }
-
-  let recommendCommands
-  self.recommendCommands = function (recommend) {
-    argsert('[boolean]', [recommend], arguments.length)
-    recommendCommands = typeof recommend === 'boolean' ? recommend : true
-    return self
-  }
-
-  self.getUsageInstance = () => usage
-
-  self.getValidationInstance = () => validation
-
-  self.getCommandInstance = () => command
-
-  self.terminalWidth = () => {
-    argsert([], 0)
-    return typeof process.stdout.columns !== 'undefined' ? process.stdout.columns : null
-  }
-
-  Object.defineProperty(self, 'argv', {
-    get: () => self._parseArgs(processArgs),
-    enumerable: true
-  })
-
-  self._parseArgs = function parseArgs (args, shortCircuit, _skipValidation, commandIndex) {
-    let skipValidation = !!_skipValidation
-    args = args || processArgs
-
-    options.__ = y18n.__
-    options.configuration = pkgUp()['yargs'] || {}
-
-    const parsed = Parser.detailed(args, options)
-    let argv = parsed.argv
-    if (parseContext) argv = Object.assign({}, argv, parseContext)
-    const aliases = parsed.aliases
-
-    argv.$0 = self.$0
-    self.parsed = parsed
-
-    try {
-      guessLocale() // guess locale lazily, so that it can be turned off in chain.
-
-      // while building up the argv object, there
-      // are two passes through the parser. If completion
-      // is being performed short-circuit on the first pass.
-      if (shortCircuit) {
-        return argv
-      }
-
-      // if there's a handler associated with a
-      // command defer processing to it.
-      if (helpOpt) {
-        // consider any multi-char helpOpt alias as a valid help command
-        // unless all helpOpt aliases are single-char
-        // note that parsed.aliases is a normalized bidirectional map :)
-        const helpCmds = [helpOpt]
-          .concat(aliases[helpOpt] || [])
-          .filter(k => k.length > 1)
-        // check if help should trigger and strip it from _.
-        if (~helpCmds.indexOf(argv._[argv._.length - 1])) {
-          argv._.pop()
-          argv[helpOpt] = true
-        }
-      }
-      const handlerKeys = command.getCommands()
-      const skipDefaultCommand = argv[helpOpt] && (handlerKeys.length > 1 || handlerKeys[0] !== '$0')
-
-      if (argv._.length) {
-        if (handlerKeys.length) {
-          let firstUnknownCommand
-          for (let i = (commandIndex || 0), cmd; argv._[i] !== undefined; i++) {
-            cmd = String(argv._[i])
-            if (~handlerKeys.indexOf(cmd) && cmd !== completionCommand) {
-              setPlaceholderKeys(argv)
-              // commands are executed using a recursive algorithm that executes
-              // the deepest command first; we keep track of the position in the
-              // argv._ array that is currently being executed.
-              return command.runCommand(cmd, self, parsed, i + 1)
-            } else if (!firstUnknownCommand && cmd !== completionCommand) {
-              firstUnknownCommand = cmd
-              break
-            }
-          }
-
-          // run the default command, if defined
-          if (command.hasDefaultCommand() && !skipDefaultCommand) {
-            setPlaceholderKeys(argv)
-            return command.runCommand(null, self, parsed)
-          }
-
-          // recommend a command if recommendCommands() has
-          // been enabled, and no commands were found to execute
-          if (recommendCommands && firstUnknownCommand && !argv[helpOpt]) {
-            validation.recommendCommands(firstUnknownCommand, handlerKeys)
-          }
-        }
-
-        // generate a completion script for adding to ~/.bashrc.
-        if (completionCommand && ~argv._.indexOf(completionCommand) && !argv[completion.completionKey]) {
-          if (exitProcess) setBlocking(true)
-          self.showCompletionScript()
-          self.exit(0)
-        }
-      } else if (command.hasDefaultCommand() && !skipDefaultCommand) {
-        setPlaceholderKeys(argv)
-        return command.runCommand(null, self, parsed)
-      }
-
-      // we must run completions first, a user might
-      // want to complete the --help or --version option.
-      if (completion.completionKey in argv) {
-        if (exitProcess) setBlocking(true)
-
-        // we allow for asynchronous completions,
-        // e.g., loading in a list of commands from an API.
-        const completionArgs = args.slice(args.indexOf(`--${completion.completionKey}`) + 1)
-        completion.getCompletion(completionArgs, (completions) => {
-          ;(completions || []).forEach((completion) => {
-            _logger.log(completion)
-          })
-
-          self.exit(0)
-        })
-        return setPlaceholderKeys(argv)
-      }
-
-      // Handle 'help' and 'version' options
-      // if we haven't already output help!
-      if (!hasOutput) {
-        Object.keys(argv).forEach((key) => {
-          if (key === helpOpt && argv[key]) {
-            if (exitProcess) setBlocking(true)
-
-            skipValidation = true
-            self.showHelp('log')
-            self.exit(0)
-          } else if (key === versionOpt && argv[key]) {
-            if (exitProcess) setBlocking(true)
-
-            skipValidation = true
-            usage.showVersion()
-            self.exit(0)
-          }
-        })
-      }
-
-      // Check if any of the options to skip validation were provided
-      if (!skipValidation && options.skipValidation.length > 0) {
-        skipValidation = Object.keys(argv).some(key => options.skipValidation.indexOf(key) >= 0 && argv[key] === true)
-      }
-
-      // If the help or version options where used and exitProcess is false,
-      // or if explicitly skipped, we won't run validations.
-      if (!skipValidation) {
-        if (parsed.error) throw new YError(parsed.error.message)
-
-        // if we're executed via bash completion, don't
-        // bother with validation.
-        if (!argv[completion.completionKey]) {
-          self._runValidation(argv, aliases, {}, parsed.error)
-        }
-      }
-    } catch (err) {
-      if (err instanceof YError) usage.fail(err.message, err)
-      else throw err
-    }
-
-    return setPlaceholderKeys(argv)
-  }
-
-  self._runValidation = function runValidation (argv, aliases, positionalMap, parseErrors) {
-    if (parseErrors) throw new YError(parseErrors.message)
-    validation.nonOptionCount(argv)
-    validation.requiredArguments(argv)
-    if (strict) validation.unknownArguments(argv, aliases, positionalMap)
-    validation.customChecks(argv, aliases)
-    validation.limitedChoices(argv)
-    validation.implications(argv)
-    validation.conflicting(argv)
-  }
-
-  function guessLocale () {
-    if (!detectLocale) return
-
-    try {
-      const osLocale = require('os-locale')
-      self.locale(osLocale.sync({ spawn: false }))
-    } catch (err) {
-      // if we explode looking up locale just noop
-      // we'll keep using the default language 'en'.
-    }
-  }
-
-  function setPlaceholderKeys (argv) {
-    Object.keys(options.key).forEach((key) => {
-      // don't set placeholder keys for dot
-      // notation options 'foo.bar'.
-      if (~key.indexOf('.')) return
-      if (typeof argv[key] === 'undefined') argv[key] = undefined
-    })
-    return argv
-  }
-
-  // an app should almost always have --version and --help,
-  // if you *really* want to disable this use .help(false)/.version(false).
-  self.help()
-  self.version()
-
-  return self
-}
-
-// rebase an absolute path to a relative one with respect to a base directory
-// exported for tests
-exports.rebase = rebase
-function rebase (base, dir) {
-  return path.relative(base, dir)
-}
